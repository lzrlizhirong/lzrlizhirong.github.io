<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[ES-5.0.2-学习(8)--分布式文档存储]]></title>
      <url>%2F2017%2F02%2F14%2FES-5-0-2-%E5%AD%A6%E4%B9%A0-8-%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E6%A1%A3%E5%AD%98%E5%82%A8-wait-for-active-shards%E6%96%B0%E5%8F%82%E6%95%B0%E5%88%86%E6%9E%90%2F</url>
      <content type="text"><![CDATA[学完ES分布式集群的工作原理以及一些基本的将数据放入索引然后检索它们的所有方法，我们可以继续学习在分布式系统中，每个分片的文档是被如何索引和查询的。 路由首先，我们需要明白，文档和分片之间是如何匹配的，这就是路由。当你索引一个文档，它被存储在单独一个主分片上。Elasticsearch是如何知道文档属于哪个分片的呢？当你创建一个新文档，它是如何知道是应该存储在分片1还是分片2上的呢？ 进程不能是随机的，因为我们将来要检索文档。事实上，它根据一个简单的算法决定：1shard = hash(routing) % number_of_primary_shards routing值是一个任意字符串，它默认是_id但也可以自定义。这个routing字符串通过哈希函数生成一个数字，然后除以主切片的数量得到一个余数(remainder)，余数的范围永远是0到number_of_primary_shards - 1，这个数字就是特定文档所在的分片。 这也解释了为什么主分片的数量只能在创建索引时定义且不能修改：如果主分片的数量在未来改变了，所有先前的路由值就失效了，文档也就永远找不到了。 所有的文档API（get、index、delete、bulk、update、mget）都接收一个routing参数，它用来自定义文档到分片的映射。自定义路由值可以确保所有相关文档——例如属于同一个人的文档——被保存在同一分片上。 例如，可以这样设置参数：123456POST twitter/tweet?routing=kimchy&#123; &quot;user&quot; : &quot;kimchy&quot;, &quot;post_date&quot; : &quot;2009-11-15T14:12:12&quot;, &quot;message&quot; : &quot;trying out Elasticsearch&quot;&#125; 主分片和复制分片如何交互在文档确认存储到哪个主分片以后，接下来就是主分片将数据复制到复制分片的任务，为了阐述意图，我们假设有三个节点的集群。它包含一个叫做blogs的索引并拥有两个主分片。每个主分片有两个复制分片。相同的分片不会放在同一个节点上，所以我们的集群是这样的：我们能够发送请求给集群中任意一个节点。每个节点都有能力处理任意请求。每个节点都知道任意文档所在的节点，所以也可以将请求转发到需要的节点。下面的例子中，我们将发送所有请求给Node 1，这个节点我们将会称之为请求节点(requesting node)。一般情况下，当我们发送请求，最好的做法是循环通过所有节点请求，这样可以平衡负载。 新建、索引和删除文档新建、索引和删除请求都是写(write)操作，它们必须在主分片上成功完成才能复制到相关的复制分片上。 下面是在主分片和复制分片上成功新建、索引或删除一个文档必要的顺序步骤： 客户端给Node 1发送新建、索引或删除请求。 节点使用文档的_id确定文档属于分片0。它转发请求到Node 3，分片0位于这个节点上。 Node 3在主分片上执行请求，如果成功，它转发请求到相应的位于Node 1和Node 2的复制节点上。当所有的复制节点报告成功，Node 3报告成功到请求的节点，请求的节点再报告给客户端。客户端接收到成功响应的时候，文档的修改已经被应用于主分片和所有的复制分片。你的修改生效了。 有很多可选的请求参数允许你更改这一过程。你可能想牺牲一些安全来提高性能。这些选项很少使用因为Elasticsearch已经足够快。 注意：下面的参数只对ElasticSearch 5.0以下的版本有效，在ElasticSearch 5.0之后貌似使用wait_for_active_shards代替了consistency。所以之前的参数了解即可，实际可以参考：Create Index—Wait For Active Shards。 replication（注意在ElasticSearch 5.0开始被废弃）复制默认的值是sync。这将导致主分片得到复制分片的成功响应后才返回。 如果你设置replication为async，请求在主分片上被执行后就会返回给客户端。它依旧会转发请求给复制节点，但你将不知道复制节点成功与否。 上面的这个选项不建议使用。默认的sync复制允许Elasticsearch强制反馈传输。async复制可能会因为在不等待其它分片就绪的情况下发送过多的请求而使Elasticsearch过载。 consistency（注意在ElasticSearch 5.0开始被废弃）默认主分片在尝试写入时需要规定数量(quorum)或过半的分片（可以是主节点或复制节点）可用。这是防止数据被写入到错的网络分区。规定的数量计算公式如下：1int( (primary + number_of_replicas) / 2 ) + 1 consistency允许的值为one（只有一个主分片），all（所有主分片和复制分片）或者默认的quorum或过半分片。 注意number_of_replicas是在索引中的的设置，用来定义复制分片的数量，而不是现在活动的复制节点的数量。如果你定义了索引有3个复制节点，那规定数量是：1int( (primary + 3 replicas) / 2 ) + 1 = 3 但如果你只有2个节点，那你的活动分片不够规定数量，也就不能索引或删除任何文档。 注意： 新索引默认有1个复制分片，这意味着为了满足quorum的要求需要两个活动的分片。当然，这个默认设置将阻止我们在单一节点集群中进行操作。为了避开这个问题，规定数量只有在number_of_replicas大于一时才生效。 一个疑惑，是不是primary值一直都只会是1？？？ wait_for_active_shards（新参数）在ElasticSearch 5.0中可以用wait_for_active_shards参数表示：等待活动的分片，具体的值和consistency类似，下面用wait_for_active_shards演示一个实际使用的例子。 开始我们先设置一个新的索引：1234567PUT /active&#123; &quot;settings&quot; : &#123; &quot;number_of_shards&quot; : 3, &quot;number_of_replicas&quot; : 3 &#125;&#125; 我们默认先只打开两个节点，等下我们设置wait_for_active_shards值为3，按照上面讲解的我们如果只有两个节点，那么活动的分片最多也就2个，所以是不够的，会等待新的活动节点的到来。（这里我们只能通过少一个节点的方法演示缺少活动分片，因为我们不方便演示出让某个分片处于不活动的状态。）因为我们只有两个节点，所以活动的分片最多也只有两个。下面我们执行文档存储操作，并且添加参数wait_for_active_shards=3：可以发现，确实开始处于等待状态，没有马上返回结果，下面我们参数开启第三个节点，让索引拥有第三个活动分片：可以看到一旦我们的节点开启，文档的存储马上就会返回成功。 教程中关于这部分网上很多朋友不太理解，我们可以通过查看官方文档和实践去证明自己的想法，希望上面的分析大家可以理解一些，还有不对的地方大家可以一起学习。 timeout当分片副本不足时会怎样？Elasticsearch会等待更多的分片出现。默认等待一分钟。如果需要，你可以设置timeout参数让它终止的更早：100表示100毫秒，30s表示30秒。 检索文档文档能够从主分片或任意一个复制分片被检索。下面我们罗列在主分片或复制分片上检索一个文档必要的顺序步骤： 客户端给Node 1发送get请求。 节点使用文档的_id确定文档属于分片0。分片0对应的复制分片在三个节点上都有。此时，它转发请求到Node 2。 Node 2返回文档(document)给Node 1然后返回给客户端。对于读请求，为了平衡负载，请求节点会为每个请求选择不同的分片——它会循环所有分片副本（包括主分片）。 可能的情况是，一个被索引的文档已经存在于主分片上却还没来得及同步到复制分片上。这时复制分片会报告文档未找到，主分片会成功返回文档。一旦索引请求成功返回给用户，文档则在主分片和复制分片都是可用的。 更新文档update API结合了之前提到的读和写的模式。下面我们罗列执行局部更新必要的顺序步骤： 客户端给Node 1发送更新请求。 它转发请求到主分片所在节点Node 3。 Node 3从主分片检索出文档，修改_source字段的JSON，然后在主分片上重建索引。如果有其他进程修改了文档，它以retry_on_conflict设置的次数重复步骤3，都未成功则放弃。 如果Node 3成功更新文档，它同时转发文档的新版本到Node 1和Node 2上的复制节点以重建索引。当所有复制节点报告成功，Node 3返回成功给请求节点，然后返回给客户端。 update API还接受routing、replication（弃）、consistency（弃）和timout参数。基于文档的复制当主分片转发更改给复制分片时，并不是转发更新请求，而是转发整个文档的新版本。记住这些修改转发到复制节点是异步的，它们并不能保证到达的顺序与发送相同。如果Elasticsearch转发的仅仅是修改请求，修改的顺序可能是错误的，那得到的就是个损坏的文档。多文档模式mget和bulk API与单独的文档类似。差别是请求节点知道每个文档所在的分片。它把多文档请求拆成每个分片的对文档请求，然后转发每个参与的节点。 一旦接收到每个节点的应答，然后整理这些响应组合为一个单独的响应，最后返回给客户端。下面我们将罗列通过一个mget请求检索多个文档的顺序步骤： 客户端向Node 1发送mget请求。 Node 1为每个分片构建一个多条数据检索请求，然后转发到这些请求所需的主分片或复制分片上。当所有回复被接收，Node 1构建响应并返回给客户端。 routing 参数可以被docs中的每个文档设置。下面我们将罗列使用一个bulk执行多个create、index、delete和update请求的顺序步骤： 客户端向Node 1发送bulk请求。 Node 1为每个分片构建批量请求，然后转发到这些请求所需的主分片上。 主分片一个接一个的按序执行操作。当一个操作执行完，主分片转发新文档（或者删除部分）给对应的复制节点，然后执行下一个操作。一旦所有复制节点报告所有操作已成功完成，节点就报告success给请求节点，后者(请求节点)整理响应并返回给客户端。 bulk API还可以在最上层使用replication（弃）和consistency（弃）参数，routing参数则在每个请求的元数据中使用。 总结以上就是关于在分布式系统中，每个分片的文档是被如何索引和查询的。虽然版本的更新有一些参数会更新，但是整体的内部实现应该不会有太大的变化，分享一个学习方法，学习的时候把新旧的版本内容通过对比，不仅可以更好理解知识，而且可以加深印象。更何况旧的不会被很快淘汰，学了又何妨！ 出处：http://www.cnblogs.com/wxw16/p/6192549.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ES-5.0.2-学习(7)——分布式集群学习2]]></title>
      <url>%2F2017%2F02%2F13%2FES-5-0-2-%E5%AD%A6%E4%B9%A0-7-%E2%80%94%E2%80%94%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E5%AD%A6%E4%B9%A02%2F</url>
      <content type="text"><![CDATA[前面主要学习了ElasticSearch分布式集群的存储过程中集群、节点和分片的知识（ES-5.0.2-学习(6)——分布式集群学习1），下面主要分享应对故障的一些实践。 应对故障前面说了很多关于复制分片可以应对节点失效，很好保证集群的安全性，下面我们可以尝试杀掉第一个节点的进程，我们的集群变化成如下（所有的操作都是ElasticSearch自动处理）：我们杀掉的节点是一个主节点。一个集群必须要有一个主节点才能使其功能正常，所以集群做的第一件事就是各节点选举了一个新的主节点：Node 2。 主分片1和2在我们杀掉Node 1时已经丢失，我们的索引在丢失主分片时不能正常工作。如果此时我们检查集群健康，我们将看到状态red：不是所有主分片都可用！ 幸运的是丢失的两个主分片的完整拷贝存在于其他节点上，所以新主节点做的第一件事是把这些在Node 2和Node 3上的复制分片升级为主分片，这时集群健康回到yellow状态。这个提升是瞬间完成的，就好像按了一下开关。 为什么集群健康状态是yellow而不是green？我们有三个主分片，但是我们指定了每个主分片对应两个复制分片，当前却只有一个复制分片被分配，这就是集群状态无法达到green的原因，不过不用太担心这个：当我们杀掉Node 2，我们的程序依然可以在没有丢失数据的情况下继续运行，因为Node 3还有每个分片的拷贝。 如果我们重启Node 1，集群将能够重新分配丢失的复制分片，集群状况与上一节的图5：增加number_of_replicas到2 类似。如果Node 1依旧有旧分片的拷贝，它将会尝试再利用它们，它只会从主分片上复制在故障期间有数据变更的那一部分。 故障实践1上面是关于ElasticSearch在遇到故障时候的理论部分，下面我们开始实际操作。 查看目前集群状态我们回顾一下之前的blogs索引，在结束最后的状态：1234567PUT /blogs&#123; &quot;settings&quot; : &#123; &quot;number_of_shards&quot; : 3, (主分片个数) &quot;number_of_replicas&quot; : 2, (每个主分片的复制分片个数) &#125;&#125; 切断节点为了模拟这种情况，在我们自己的电脑上，直接用kill命令即可:12ps -ef | grep elasticsearch #获取到elasticsearch的进程id，例如5891kill 5891 查看集群的状态很正确，就是理论内容所描述中间会存在red的瞬间。等·等·等·可是等了半天，结果一直是red状态的结果，这是为什么呢？注意看提示无法连接到http://localhost:9200，突然意识到，我们关闭的节点正好是9200端口的Node 1节点。所以我们需要修改kibana.yml配置文件的elasticsearch.url项： 再次查看集群的状态终于，可以看到我们想要的结果，ElasticSearch集群正如上面所说的重新选Node 2作为新的主节点：我们还可以注意到集群的健康状况从绿色变成了黄色，这是因为我们设置每个主节点2个复制分片，而现在还有一个复制节点处于不可用状态。 故障实践2回顾之前的一个集群状态，blogs索引只设置一个复制分片的情况下：如果在这种情况下，我们把其中的任何一个节点关闭，会出现什么效果呢？我们分析看，至少我们关闭任何一个节点都能保所有的分片都还能存在。比如我们删除Node 2节点，正常情况下，Node 2中的分片0作为主分片被删除后，主节点会分配Node 1节点下复制分片0重新作为主分片0，而Node 2中的分片1本身是复制分片，直接删除即可，但是ElasticSearch集群，除此之外还会不会有其他操作。那就是，从新在两个节点中把所有的复制分片都置为可用。下面我们看结果：首先我们看到的和我们前面分析的一样，主节点会分配Node 1节点下复制分片0重新作为主分片0，但是也可以看到现在集群的健康状况是黄色，因为存在复制节点处于不可用状态。我们继续等。。。：终于我们可以看到，ElasticSearch集群确实会把所有的复制节点又都置为可用状态，因为节点存在它不拥有的分片，就可以创建这个节点，最大程度的保证高可用性。 实践注意点在测试过程中，ElasticSearch集群确实可以帮助我们重新分配分片的状态，但是需要注意的是，每次一个节点关闭的时候，集群需要一定的时间去管理，如果这时候我们很快的将两个节点关闭，ElasticSearch集群将无法挽救回没有主分片，也没有复制分片的那些数据，所以测试的时候需要知道这一点。 不过这也反映我们在学习分享1中描述的，如果我们的复制节点足够多的话，我们可以保证高可用的能力就却强大，因为允许节点故障的次数更多，而且我们的节点故障以后，运维又可以将节点重启，继续斗争！！！ 总结现在我们对分片如何使Elasticsearch可以水平扩展并保证数据安全有了一个清晰的认识。真正感受到Elasticsearch天生就是分布式的，确实很强大！ 出处：http://www.cnblogs.com/wxw16/p/6188560.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ES-5.0.2-学习(6)——分布式集群学习1]]></title>
      <url>%2F2017%2F02%2F13%2FES-5-0-2-%E5%AD%A6%E4%B9%A0-6-%E2%80%94%E2%80%94%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E5%AD%A6%E4%B9%A01%2F</url>
      <content type="text"><![CDATA[在使用中我们把文档存入ElasticSearch，但是如果能够了解ElasticSearch内部是如何存储的，将会对我们学习ElasticSearch有很清晰的认识。本文中的所使用的ElasticSearch集群环境，可以通过查看 ES-5.0.2-学习(3)——单台服务器部署多个节点 搭建学习。ElasticSearch用于构建高可用和可扩展的系统。扩展的方式可以是购买更好的服务器(纵向扩展(vertical scale or scaling up))或者购买更多的服务器（横向扩展(horizontal scale or scaling out)）。 Elasticsearch虽然能从更强大的硬件中获得更好的性能，但是纵向扩展有它的局限性。真正的扩展应该是横向的，它通过增加节点来均摊负载和增加可靠性。 对于大多数数据库而言，横向扩展意味着你的程序将做非常大的改动才能利用这些新添加的设备。对比来说，Elasticsearch天生就是分布式的：它知道如何管理节点来提供高扩展和高可用。这意味着你的程序不需要关心这些。 下面的例子主要围绕着集群(cluster)、节点(node)和分片(shard)讲解，相信学习以后，对于学习Elasticsearch会有很大收获。 空集群如果我们启动一个单独的节点，它还没有数据和索引，这个集群看起来如下图：只有一个空节点的集群。一个节点(node)就是一个Elasticsearch实例，而一个集群(cluster)由一个或多个节点组成，它们具有相同cluster.name，它们协同工作，分享数据和负载。当加入新的节点或者删除一个节点时，集群就会感知到并平衡数据。 集群中一个节点会被选举为主节点(master)，它将临时管理集群级别的一些变更，例如新建或删除索引、增加或移除节点等。主节点不参与文档级别的变更或搜索，这意味着在流量增长的时候，该主节点不会成为集群的瓶颈。任何节点都可以成为主节点。我们例子中的集群只有一个节点，所以它会充当主节点的角色。 作为用户，我们能够与集群中的任何节点通信，包括主节点。每一个节点都知道文档存在于哪个节点上，它们可以转发请求到相应的节点上。我们访问的节点负责收集各节点返回的数据，最后一起返回给客户端。这一切都由Elasticsearch处理。 集群健康在Elasticsearch集群中可以监控统计很多信息，但是只有一个是最重要的：集群健康(cluster health)。集群健康有三种状态：green、yellow或red，健康状况在后面会有很多体现。1GET /_cluster/health 在一个没有索引的空集群中运行如上查询，将返回这些信息： { “cluster_name”: “elasticsearch”, “status”: “green”, “timed_out”: false, “number_of_nodes”: 1, “number_of_data_nodes”: 1, “active_primary_shards”: 0, “active_shards”: 0, “relocating_shards”: 0, “initializing_shards”: 0, “unassigned_shards”: 0} status： 是我们最感兴趣的字段。status字段提供一个综合的指标来表示集群的的服务状况。三种颜色各自的含义： green：所有主要分片和复制分片都可用。 yellow：所有主要分片可用，但不是所有复制分片都可用。 red：不是所有的主要分片都可用。 添加索引为了将数据添加到Elasticsearch，我们需要索引(index)——一个存储关联数据的地方。实际上，索引只是一个用来指向一个或多个分片(shards)的“逻辑命名空间(logical namespace)”. 一个分片(shard)是一个最小级别“工作单元(worker unit)”,它只是保存了索引中所有数据的一部分。并且先初步知道分片就是一个Lucene实例，它本身就是一个完整的搜索引擎。我们的文档存储在分片中，并且在分片中被索引，但是我们的应用程序不会直接与它们通信，取而代之的是，直接与索引通信。 分片是Elasticsearch在集群中分发数据的关键。把分片想象成数据的容器。文档存储在分片中，然后分片分配到你集群中的节点上。当你的集群扩容或缩小，Elasticsearch将会自动在你的节点间迁移分片，以使集群保持平衡。 分片可以是主分片(primary shard)或者是复制分片(replica shard)。你索引中的每个文档属于一个单独的主分片，所以主分片的数量决定了索引最多能存储多少数据。当索引创建完成的时候，主分片的数量就固定了，但是复制分片的数量可以随时调整。 复制分片只是主分片的一个副本，它可以防止硬件故障导致的数据丢失，同时可以提供读请求，比如搜索或者从别的分片取回文档。 让我们在集群中唯一一个空节点上创建一个叫做blogs的索引。默认情况下，一个索引被分配5个主分片，但是为了演示的目的，我们只分配3个主分片和一个复制分片（每个主分片都有一个复制分片）：1234567PUT /blogs&#123; &quot;settings&quot; : &#123; &quot;number_of_shards&quot; : 3, &quot;number_of_replicas&quot; : 1 &#125;&#125; 我们的集群现在看起来就像上图——三个主分片都被分配到Node 1。如果我们现在检查集群健康(cluster-health)，我们将见到以下信息：123456789101112&#123; &quot;cluster_name&quot;: &quot;elasticsearch&quot;, &quot;status&quot;: &quot;yellow&quot;, &lt;1&gt; &quot;timed_out&quot;: false, &quot;number_of_nodes&quot;: 1, &quot;number_of_data_nodes&quot;: 1, &quot;active_primary_shards&quot;: 3, &quot;active_shards&quot;: 3, &quot;relocating_shards&quot;: 0, &quot;initializing_shards&quot;: 0, &quot;unassigned_shards&quot;: 3 &lt;2&gt;&#125; 集群的状态现在是 yellow 我们的三个复制分片还没有被分配到节点上 下面我们可以看下，在Kibana监控工具中查看具体情况，如下图：集群的健康状态yellow表示所有的主分片(primary shards)启动并且正常运行了——集群已经可以正常处理任何请求——但是复制分片(replica shards)还没有全部可用。事实上所有的三个复制分片现在都是unassigned状态——它们还未被分配给节点。在同一个节点上保存相同的数据副本是没有必要的，如果这个节点故障了，那所有的数据副本也会丢失。 现在我们的集群已经功能完备，但是依旧存在因硬件故障而导致数据丢失的风险。 添加故障转移在单一节点上运行意味着有单点故障的风险——没有数据备份。幸运的是，要防止单点故障，我们唯一需要做的就是启动另一个节点。 具体启动方式可以查看 ES-5.0.2-学习(3)——单台服务器部署多个节点 。 如果我们启动了第二个节点，这个集群看起来就像下图。双节点集群——所有的主分片和复制分片都已分配:第二个节点已经加入集群，三个复制分片(replica shards)也已经被分配了——分别对应三个主分片，这意味着在丢失任意一个节点的情况下依旧可以保证数据的完整性。 文档的索引将首先被存储在主分片中，然后并发复制到对应的复制节点上。这可以确保我们的数据在主节点和复制节点上都可以被检索。 cluster-health 现在的状态是 green，这意味着所有的6个分片（三个主分片和三个复制分片）都已可用：123456789101112&#123; &quot;cluster_name&quot;: &quot;elasticsearch&quot;, &quot;status&quot;: &quot;green&quot;, &quot;timed_out&quot;: false, &quot;number_of_nodes&quot;: 2, &quot;number_of_data_nodes&quot;: 2, &quot;active_primary_shards&quot;: 3, &quot;active_shards&quot;: 6, &quot;relocating_shards&quot;: 0, &quot;initializing_shards&quot;: 0, &quot;unassigned_shards&quot;: 0&#125; 集群的状态是green，我们的集群不仅是功能完备的，而且是高可用的。同样我们可以看下实际的操作结果： 横向扩展随着应用需求的增长，我们该如何扩展？如果我们启动第三个节点，我们的集群会重新组织自己，包含3个节点的集群——分片已经被重新分配以平衡负载：Node 3包含了分别来自Node 1和Node 2的一个分片，这样每个节点就有两个分片，和之前相比少了一个，这意味着每个节点上的分片将获得更多的硬件资源（CPU、RAM、I/O）。 分片本身就是一个完整的搜索引擎，它可以使用单一节点的所有资源。我们拥有6个分片（3个主分片和三个复制分片），最多可以扩展到6个节点，每个节点上有一个分片，每个分片可以100%使用这个节点的资源。 同样我们可以看下实际的操作结果： 继续扩展如果我们要扩展到6个以上的节点，要怎么做？ 主分片的数量在创建索引时已经确定。实际上，这个数量定义了能存储到索引里数据的最大数量（实际的数量取决于你的数据、硬件和应用场景）。然而，主分片或者复制分片都可以处理读请求——搜索或文档检索，所以数据的冗余越多，我们能处理的搜索吞吐量就越大。 复制分片的数量可以在运行中的集群中动态地变更，这允许我们可以根据需求扩大或者缩小规模。让我们把复制分片的数量从原来的1增加到2：1234PUT /blogs/_settings&#123; &quot;number_of_replicas&quot; : 2&#125; 从图中可以看出，blogs索引现在有9个分片：3个主分片和6个复制分片。这意味着我们能够扩展到9个节点，再次变成每个节点一个分片。这样使我们的搜索性能相比原始的三节点集群增加“三倍”。 实际操作也是同样的效果：注意：可以看到上面的“三倍”我们用加了引号，因为在同样数量的节点上增加更多的复制分片并不一定提高性能，因为这样做的话平均每个分片的所占有的硬件资源就减少了（大部分请求都聚集到了分片少的节点，导致一个节点吞吐量太大，反而降低性能），你需要增加硬件来提高吞吐量。所以说添加复制分片和添加节点，在保证成本的情况下，需要有一个平衡点。 不过这些额外的复制节点还是有另外一个好处，使我们有更多的冗余：通过以上对节点的设置，我们能够承受两个节点故障而不丢失数据。 总结对于ES分布式集群如果对节点、分片的处理基本学习完毕，可以感受到ES分布式集群的自动化，对于用户来说几乎完全透明化。但是，一个分布式集群主要看它的高性能、高并发和高可用。上面的内容虽然体现了一些，但是还包括对故障的处理能力，这部分将在 ES-5.0.2-学习(7)——分布式集群学习2 继续和大家分享。 出处：http://www.cnblogs.com/wxw16/p/6188044.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ES-5.0.2-学习(5)--第一个ES例子]]></title>
      <url>%2F2017%2F02%2F10%2FES-5-0-2-%E5%AD%A6%E4%B9%A0-3-%E7%AC%AC%E4%B8%80%E4%B8%AAES%E4%BE%8B%E5%AD%90%2F</url>
      <content type="text"><![CDATA[想要知道ElasticSearch是如何使用的，最快的方式就是通过一个简单的例子，第一个例子将会包括基本概念如索引、搜索、和聚合等，需求是关于公司管理员工的一些业务。 员工文档索引业务首先需要存储员工数据。这将采取一个员工文档的形式：单个文档表示单个员工。在Elasticsearch中存储数据的行为称为索引，但是在索引文档之前，我们需要决定在哪里存储它。在Elasticsearch中，文档属于某个类型，这些类型位于索引中。可以绘制一些（粗略）与传统关系数据库的对比： Relational DB ⇒ Databases ⇒ Tables ⇒ Rows ⇒ Columns Elasticsearch ⇒ Indices ⇒ Types ⇒ Documents ⇒ Fields Elasticsearch集群可以包含多个索引（数据库），这些索引又包含多个类型（表）。这些类型包含多个文档（行），每个文档都有多个字段（列）。你可能已经注意到，在Elasticsearch的上下文中，索引被重载了几个含义。如下： 索引（名词）：正如前面所解释的那样，索引就像传统的关系数据库中的数据库一样。它是存储相关文档的地方。index的复数形式是indices或indexes。 索引（动词）：索引一个文档是将一个文档存储在索引（名词）中，以便它可以检索和查询。它很像插入关键词SQL。此外，如果文档已经存在，新的文档将取代旧的。 倒排索引：关系数据库中增加一个索引，如B-树索引，对特定列为了提高数据检索的速度。Elasticsearch和Lucene提供相同目的的索引称为倒排索引。默认情况下，文档中的每个字段索引（有一个倒排索引）这样的搜索。一个没有倒排索引字段不可搜索 因此我们的员工目录，我们需要处理如下事情： 索引的每个文档，包含每个员工的所有细节。 每个文档都属于employee类型。 类型都包含在megacop索引中。 该索引将驻留我们Elasticsearch集群内。 下面通过命令去索引第一个员工：12345678PUT /megacorp/employee/1&#123; &quot;first_name&quot; : &quot;John&quot;, &quot;last_name&quot; : &quot;Smith&quot;, &quot;age&quot; : 25, &quot;about&quot; : &quot;I love to go rock climbing&quot;, &quot;interests&quot;: [ &quot;sports&quot;, &quot;music&quot; ]&#125; 注意 /megacorp/employee/1 包含的信息: megacorp：索引的名称emplogee：类型的名称1：员工的id 成功执行返回的是一个JSON文本，包含所有关于该员工的信息。 注意： 如果执行过程中失败了，可能存在的原因是elasticsearch默认配置中不允许自动创建索引，所以我们可以先简单在elasticsearch.yml配置文件添加action.auto_create_index：true，允许自动创建索引。 没有必要首先执行任何管理任务，如创建一个索引或指定每个字段所包含的数据类型。我们可以直接索引一个文档。Elasticsearch附带默认的一切，因此所有必要的管理任务都会使用默认值在后台处理。 在目录中添加更多的员工：1234567891011121314151617PUT /megacorp/employee/2&#123; &quot;first_name&quot; : &quot;Jane&quot;, &quot;last_name&quot; : &quot;Smith&quot;, &quot;age&quot; : 32, &quot;about&quot; : &quot;I like to collect rock albums&quot;, &quot;interests&quot;: [ &quot;music&quot; ]&#125;PUT /megacorp/employee/3&#123; &quot;first_name&quot; : &quot;Douglas&quot;, &quot;last_name&quot; : &quot;Fir&quot;, &quot;age&quot; : 35, &quot;about&quot;: &quot;I like to build cabinets&quot;, &quot;interests&quot;: [ &quot;forestry&quot; ]&#125; 检索文档现在我们有一些数据存储在Elasticsearch中，我们可以开始处理这个应用程序的业务需求。第一个要求是检索单个员工数据的能力。这在Elasticsearch中很容易。我们只需执行HTTP GET请求并指定文档的地址——索引，类型和ID。使用这三个信息，我们可以返回原始的JSON文档，并且响应包含有关文档的一些元数据，以及Douglas Fir的原始JSON文档作为_source字段：可以查看：ES-5.0.2-学习(4)–简单搜索 以同样的方式，我们将HTTP动词从PUT更改为GET以便检索文档，我们可以使用DELETE动词删除文档，并使用HEAD动词检查文档是否存在。要用更新的版本替换现有文档，我们只需再次PUT。GET很简单，可以得到要求的文件。尝试一些更高级的东西，我们可以搜索所有员工，请求：1GET /megacorp/employee/_search 你可以看到我们仍在使用索引megacorp和类型employee，但是我们现在使用_search端点，而不是指定文档ID。响应包括我们在hits数组中的所有三个文档。默认情况下，搜索将返回前10个结果。响应不仅告诉我们哪些文档匹配，而且还包括整个文档本身，以便向用户显示搜索结果的所有信息。接下来，让我们尝试搜索在其姓氏中有“Smith”的员工。为此，我们将使用一个轻松的搜索方法，它很容易从命令行使用。此方法通常称为查询字符串搜索，因为我们将搜索作为URL查询字符串参数传递： DSL查询查询字符串搜索对于从命令行进行搜索非常方便，但它有其局限性。Elasticsearch提供了一种丰富，灵活的查询语言，称为查询DSL，它允许我们构建更复杂，更健壮的查询。使用JSON请求正文指定域特定语言（DSL）。我们可以代表所有以前的搜索，像这样：12345678GET /megacorp/employee/_search&#123; &quot;query&quot; : &#123; &quot;match&quot; : &#123; &quot;last_name&quot; : &quot;Smith&quot; &#125; &#125;&#125; 这将返回与上一个查询相同的结果。可以看到一些事情已经改变。例如，我们不再使用查询字符串参数，而是使用请求正文。此请求体是使用JSON构建的，并使用匹配查询。让我们让搜索更复杂一点。我们仍然希望找到所有名字为Smith的员工，但我们只想要30岁以上的员工。我们的查询将稍微改变一点，以容纳一个过滤器，这使我们能够有效地执行结构化搜索：1234567891011121314151617GET /megacorp/employee/_search&#123; &quot;query&quot; : &#123; &quot;bool&quot; : &#123; &quot;must&quot; : &#123; &quot;match&quot; : &#123; &quot;last_name&quot; : &quot;smith&quot; &#125; &#125;, &quot;filter&quot; : &#123; &quot;range&quot; : &#123; &quot;age&quot; : &#123; &quot;gt&quot; : 30 &#125; &#125; &#125; &#125; &#125;&#125; 我们添加了一个过滤器，执行范围搜索，并重复使用与以前相同的匹配查询。现在我们的结果显示只有一个员工刚好是32并被命名为smith： 注意：关于过滤器在Elasticsearch2.0开始有很大的更新，所以有些过滤操作可能会报错。例如：filtered query已经被废弃。 全文搜索（Full-Text Search）到目前为止的搜索很简单：单个名字，按年龄过滤。让我们尝试更高级的全文搜索，传统数据库真正难以胜任的任务。我们将寻找所有喜欢攀岩的员工：12345678GET /megacorp/employee/_search&#123; &quot;query&quot; : &#123; &quot;match&quot; : &#123; &quot;about&quot; : &quot;rock climbing&quot; &#125; &#125;&#125; 您可以看到我们使用与之前相同的匹配查询来搜索关于“攀岩”字段。我们得到两个匹配的文档：默认情况下，Elasticsearch按匹配结果的相关性分值（即每个文档与查询匹配程度）对匹配结果进行排序。第一个和最高分的结果是显而易见的：John·Smith关于字段清楚地说“攀岩”。但为什么Jane·Smith也返回了？她的文档被返回的原因是因为在她的字段中提到了“rock”这个词。因为只有“岩石”被提及，而不是“攀登”，她的分数低于John的。这是Elasticsearch如何在全文字段中进行搜索并返回最相关的结果的一个很好的例子。这种相关性的概念对于Elasticsearch很重要，并且是一个完全与传统关系数据库无关的概念，其中记录匹配或不匹配。 精确字段搜索在字段中查找单个字词是很好的，但有时你想要匹配字词或短语的确切序列。例如，我们可以执行一个查询，该查询将仅匹配包含“rock”和“climbing”的员工记录，并在短语“rock climbing”中显示彼此相邻的单词。为此，我们使用改为match_phrase查询：12345678GET /megacorp/employee/_search&#123; &quot;query&quot; : &#123; &quot;match_phrase&quot; : &#123; &quot;about&quot; : &quot;rock climbing&quot; &#125; &#125;&#125; 仅返回John Smith的文档 高亮搜索结果许多应用程序喜欢从每个搜索结果突出显示文本片段，以便用户可以看到文档与查询匹配的原因。在Elasticsearch中检索突出显示的片段很容易。让我们重新运行我们以前的查询，但添加一个新的highlight参数：12345678910111213GET /megacorp/employee/_search&#123; &quot;query&quot; : &#123; &quot;match_phrase&quot; : &#123; &quot;about&quot; : &quot;rock climbing&quot; &#125; &#125;, &quot;highlight&quot;: &#123; &quot;fields&quot; : &#123; &quot;about&quot; : &#123;&#125; &#125; &#125;&#125; 当我们运行此查询时，将返回与之前相同的返回，但现在我们在响应中得到一个新的部分，称为突出显示。这包含来自about字段的文字片段，其中包含在 HTML标记中包含的匹配单词： 分析最后，我们来到我们的最后一个业务需求：允许管理员在员工目录上运行分析。Elasticsearch具有称为聚合的功能，允许您对数据生成复杂的分析。它类似于GROUP BY中的SQL，但功能更强大。例如，让我们找到我们的员工最喜欢的兴趣：12345678GET /megacorp/employee/_search&#123; &quot;aggs&quot;: &#123; &quot;all_interests&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;interests&quot; &#125; &#125; &#125;&#125; 如果Elasticsearch 5版本以前，将会返回：12345678910111213141516171819202122&#123; ... &quot;hits&quot;: &#123; ... &#125;, &quot;aggregations&quot;: &#123; &quot;all_interests&quot;: &#123; &quot;buckets&quot;: [ &#123; &quot;key&quot;: &quot;music&quot;, &quot;doc_count&quot;: 2 &#125;, &#123; &quot;key&quot;: &quot;forestry&quot;, &quot;doc_count&quot;: 1 &#125;, &#123; &quot;key&quot;: &quot;sports&quot;, &quot;doc_count&quot;: 1 &#125; ] &#125; &#125;&#125; 我们可以看到，两个员工对音乐感兴趣，一个在林业，一个在体育。这些聚合不是预先计算的，它们是从与当前查询匹配的文档即时生成的。然而如果我们使用的是Elasticsearch 5版本以上的话，将会出现如下异常：我们可以查看 Elasticsearch 5.0文档——Fielddata is disabled on text fields by default大概的意思是：Fielddata可以消耗大量的堆空间，特别是在加载高基数文本字段时。一旦fielddata已经加载到堆中，它在该段的生存期内保持。此外，加载fielddata是一个昂贵的过程，可以导致用户体验延迟命中。所以fielddata默认禁用。如果尝试对文本字段上的脚本进行排序，聚合或访问值，就会看到这个异常，具体使用可以参考手册。 总结这个小例子是一个很好的演示了什么是Elasticsearch。它只是很肤浅的介绍了简单的使用，许多功能被省略，以保持简短。但是这也突出了开始构建高级搜索功能是多么容易。 出处：http://www.cnblogs.com/wxw16/p/6185378.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ES-5.0.2-学习(4)--简单搜索]]></title>
      <url>%2F2017%2F02%2F10%2FES-5-0-2-%E5%AD%A6%E4%B9%A0-3-%E7%AE%80%E5%8D%95%E6%90%9C%E7%B4%A2%2F</url>
      <content type="text"><![CDATA[空搜索1GET /_search 注：以下操作均是在kibana中，如图所示hits： total 总数 hits 前10条数据 hits 数组中的每个结果都包含_index、_type和文档的_id字段，被加入到_source字段中这意味着在搜索结果中我们将可以直接使用全部文档。 每个节点都有一个_score字段，这是相关性得分(relevance score)，它衡量了文档与查询的匹配程度。默认的，返回的结果中关联性最大的文档排在首位；这意味着，它是按照_score降序排列的。没有指定任何查询，所以所有文档的相关性是一样的，因此所有结果的_score都是取得一个中间值1。 took：整个搜索请求花费的毫秒数。_shards：节点告诉我们参与查询的分片数（total字段），有多少是成功的（successful），有多少的是失败的（failed）。time_out：告诉我们查询超时与否。一般的，搜索请求不会超时。如果响应速度比完整的结果更重要，你可以定义timeout参数为10或者10ms（10毫秒），或者1s（1秒）1GET /_search?timeout=10ms Elasticsearch将返回在请求超时前收集到的结果。注意： timeout不会停止执行查询，它仅仅告诉你目前顺利返回结果的节点然后关闭连接。在后台，其他分片可能依旧执行查询，尽管结果已经被发送。使用超时是因为对于你的业务需求来说非常重要，而不是因为你想中断执行长时间运行的查询。 多索引和多类别在所有索引的所有类型中搜索：/_search在索引gb的所有类型中搜索：/gb/_search在索引gb和us的所有类型中搜索：/gb,us/_search在以g或u开头的索引的所有类型中搜索：/g*,u*/_search在索引gb的类型user中搜索：/gb/user/_search在索引gb和us的类型为user和tweet中搜索：/gb,us/user,tweet/_search在所有索引的user和tweet中搜索：/_all/user,tweet/_search当你搜索包含单一索引时，Elasticsearch转发搜索请求到这个索引的主分片或每个分片的复制分片上，然后聚集每个分片的结果。搜索包含多个索引也是同样的方式——只不过会有更多的分片被关联。 分页如果你想每页显示5个结果，页码从1到3，那请求如下：123GET /_search?size=5GET /_search?size=5&amp;from=5GET /_search?size=5&amp;from=10 应该当心分页太深或者一次请求太多的结果。结果在返回前会被排序。但是记住一个搜索请求常常涉及多个分片。每个分片生成自己排好序的结果，它们接着需要集中起来排序以确保整体排序正确。现在假设我们请求第1000页——结果10001到10010。工作方式都相同，不同的是每个分片都必须产生顶端的10010个结果。然后请求节点排序这50050个结果并丢弃50040个！ 简易搜索search API有两种表单：一种是“简易版”的查询字符串(query string)将所有参数通过查询字符串定义，另一种版本使用JSON完整的表示请求体(request body)，这种富搜索语言叫做结构化查询语句（DSL）。查询字符串搜索对于在命令行下运行特定情况下查询特别有用。例如这个语句查询所有类型为tweet并在tweet字段中包含elasticsearch字符的文档：1GET /_all/tweet/_search?q=tweet:elasticsearch 下一个语句查找name字段中包含”john”和tweet字段包含”mary”的结果。实际的查询只需要：1+name:john +tweet:mary 但是url编码需要将查询字符串参数变得更加神秘：1GET /_search?q=%2Bname%3Ajohn+%2Btweet%3Amary “+”前缀表示语句匹配条件必须被满足。类似的”-“前缀表示条件必须不被满足。所有条件如果没有+或-表示是可选的——匹配越多，相关的文档就越多。 _all字段返回包含”mary”字符的所有文档的简单搜索：1GET /_search?q=mary 当你索引一个文档，Elasticsearch把所有字符串字段值连接起来放在一个大字符串中，它被索引为一个特殊的字段_all。例如，当索引这个文档：123456&#123; &quot;tweet&quot;: &quot;However did I manage before Elasticsearch?&quot;, &quot;date&quot;: &quot;2014-09-14&quot;, &quot;name&quot;: &quot;Mary Jones&quot;, &quot;user_id&quot;: 1&#125; 这好比我们增加了一个叫做_all的额外字段值：1&quot;However did I manage before Elasticsearch? 2014-09-14 Mary Jones 1&quot; 若没有指定字段，查询字符串搜索（即q=xxx）使用_all字段搜索。 更复杂的语句下一个搜索的语句：_all field name字段包含”mary”或”john” date晚于2014-09-10 _all字段包含”aggregations”或”geo” 1+name:(mary john) +date:&gt;2014-09-10 +(aggregations geo) 编码后的查询字符串变得不太容易阅读1?q=%2Bname%3A(mary+john)+%2Bdate%3A%3E2014-09-10+%2B(aggregations+geo) 就像你上面看到的例子，简单查询字符串搜索惊人的强大。允许我们简洁明快的表示复杂的查询。这对于命令行下一次性查询或者开发模式下非常有用。然而，你可以看到简洁带来了隐晦和调试困难。而且它很脆弱——查询字符串中一个细小的语法错误，像-、:、/或”错位就会导致返回错误而不是结果。最后，查询字符串搜索允许任意用户在索引中任何一个字段上运行潜在的慢查询语句，可能暴露私有信息甚至使你的集群瘫痪。取而代之的，生产环境我们一般依赖全功能的请求体搜索API，它能完成前面所有的事情，甚至更多。 出处：http://www.cnblogs.com/wxw16/p/6171016.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ES-5.0.2-学习(3)——单台服务器部署多个节点]]></title>
      <url>%2F2017%2F02%2F10%2FES-5-0-2-%E5%AD%A6%E4%B9%A0-3-%E2%80%94%E2%80%94%E5%8F%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E5%A4%9A%E4%B8%AA%E8%8A%82%E7%82%B9%2F</url>
      <content type="text"><![CDATA[一般情况下单台服务器只会部署一个ElasticSearch node，但是在学习过程中，很多情况下会需要实现ElasticSearch的分布式效果，所以需要启动多个节点，但是学习开发环境（不想开多个虚拟机实现多个服务器的效果），所以就想着在一台服务器上部署多个结点（下文以2个结点作为例子），两个节点分别称为实例一、二。 1、首先将elasticsearch-5.0.2文件夹再复制一份1cp -R elasticsearch-5.0.2 elasticsearch-5.0.2-node-2 2、主要工作就是修改elasticsearch.yml配置文件。实例二：config目录下的elasticsearch.yml内容将node.name: node-1 修改为 node-2 3、分别开启两个节点1./bin/elasticsearch 4、查询是否成功浏览器访问 http://localhost:9200/_cluster/health?pretty若出现类似如下则表示成功123456789101112131415161718&#123; &quot;cluster_name&quot;: &quot;es-lzr&quot;, &quot;status&quot;: &quot;green&quot;, &quot;timed_out&quot;: false, &quot;number_of_nodes&quot;: 2, &quot;number_of_data_nodes&quot;: 2, &quot;active_primary_shards&quot;: 17, &quot;active_shards&quot;: 34, &quot;relocating_shards&quot;: 0, &quot;initializing_shards&quot;: 0, &quot;unassigned_shards&quot;: 0, &quot;delayed_unassigned_shards&quot;: 0, &quot;number_of_pending_tasks&quot;: 0, &quot;number_of_in_flight_fetch&quot;: 0, &quot;task_max_waiting_in_queue_millis&quot;: 0, &quot;active_shards_percent_as_number&quot;: 100.0&#125; 也可以通过Kibana查看节点效果 http://localhost:5601 账号 elastic 密码 changeme 踩过的坑1.如果修改了配置文件的 http.port、transport.tcp.port项，一定要将各个节点的值设置不同，否则会出现占用的情况。正常如果不修改，默认会分配值。2.示例二开启时，实例一报警告（实际操作中可以忽略）： [2016-12-11T18:06:43,678][WARN ][o.e.d.z.ElectMasterService] [node-1] value for setting “discovery.zen.minimum_master_nodes” is too low. This can result in data loss! Please set it to at least a quorum of master-eligible nodes (current value: [-1], total number of master-eligible nodes used for publishing in this round: [2])是因为默认情况下 discovery.zen.minimum_master_nodes=1 一台服务器只能有一个主节点，所以在实例二的配置文件中可以添加 node.master: false 。 3.示例二不能开启，报如下错误： [2016-12-11T16:53:02,711][INFO ][o.e.d.z.ZenDiscovery ] [node-2] failed to send join request to master [{node-1}{vP19PMOyT2ilJKRAqgn78w}{jDULCExERXGHp4VXpbyuJA}{127.0.0.1}{127.0.0.1:9300}], reason [RemoteTransportException[[node-1][127.0.0.1:9300][internal:discovery/zen/join]]; nested: IllegalArgumentException[can’t add node {node-2}{vP19PMOyT2ilJKRAqgn78w}{qhDDVzwZQ0GXZXhIMmpGKA}{127.0.0.1}{127.0.0.1:9301}, found existing node {node-1}{vP19PMOyT2ilJKRAqgn78w}{jDULCExERXGHp4VXpbyuJA}{127.0.0.1}{127.0.0.1:9300} with the same id but is a different node instance]; ][2016-12-11T16:53:02,911][INFO ][o.e.x.m.e.Exporters ] [node-2] skipping exporter [default_local] as it isn’t ready yet[2016-12-11T16:53:02,912][ERROR][o.e.x.m.AgentService ] [node-2] exception when exporting documentsorg.elasticsearch.xpack.monitoring.exporter.ExportException: exporters are either not ready or faulty at org.elasticsearch.xpack.monitoring.exporter.Exporters.export(Exporters.java:188) ~[x-pack-5.0.2.jar:5.0.2] at org.elasticsearch.xpack.monitoring.AgentService$ExportingWorker.run(AgentService.java:208) [x-pack-5.0.2.jar:5.0.2] at java.lang.Thread.run(Thread.java:745) [?:1.8.0_111] 是因为复制的elasticsearch文件夹下包含了data文件中示例一的节点数据，需要把示例二data文件下的文件清空。 出处：http://www.cnblogs.com/wxw16/p/6160186.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[为了保持逼格，不要停止写作]]></title>
      <url>%2F2017%2F02%2F10%2F%E4%B8%BA%E4%BA%86%E4%BF%9D%E6%8C%81%E9%80%BC%E6%A0%BC%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%81%9C%E6%AD%A2%E5%86%99%E4%BD%9C%2F</url>
      <content type="text"><![CDATA[“逼格”一词，网络上常见的解释是“装逼的格调”，听起来有一些嘲讽的味道。但我认为，“逼格”应该是一种大隐隐于市的淡定，一种出淤泥而不染的清高，一种观望世事变迁而不为之动容的气质，一种身处外部世界的混乱却依然能听从内部世界的召唤的能力。你觉得我这番解释是装逼也无所谓，因为我的理想一直以来就是做一个有逼格的人。 追求逼格的过程不是一蹴而就的，更不是一劳永逸的，而更像是逆水行舟，一刻都万万不可以松懈。忍不住让我想起柏邦妮说过的一句话：“哪有什么胜利可言，挺住就是一切。” 所以，追求逼格可以被看做是一种坚持不懈的抗争，一种保护内部世界的完整饱足而不被外部世界侵蚀的抗争。这种抗争，本身就足以令人肃然起敬。如此看来，逼格恰恰存在于追求逼格的过程之中。 保护内部世界之完整饱足的方法有很多，而我独爱写作。我一直信奉，虽然不是每个人都可以把写作当成自己的职业，但所有人都一定可以把写作当成自己的一种状态。 在我眼中，世间的写作不过两种，对内的和对外的。今天来聊聊我理想中的写作吧。 对内的写作，是内部世界在巩固自己的版图，是往下扎根。典型的形式包括写日记——你是作者，你也是唯一的读者。如果，你在落笔的当下决定，读者除了你自己还可以包括其他人，即使再少数的其他人都好，那都不能被归为“对内的写作”了。当然，如果你已经完成了写作的这个部分，只不过在之后的阅读过程中觉得，公布出来被他人看见也无妨，那又另当别论。这里讨论的，只是写作这个动作进行之时的内心向度。 对内的写作应该是繁杂凌乱的、忠诚于自己所念所想的，应该完完全全原汁原味地呈现一个自由的内心世界，所以没有必要进行自我审查。想起以前学摄影的时候，教授叮嘱我们拿起相机就一定要无所顾忌、疯狂地拍，把照片导出来之后才开始进行筛选，千万不要把创作和编辑的过程混在一块儿，千万不要在拍的时候就缩手缩脚，或者直接在相机上删掉所谓的不满意的照片。同理，对内的写作应该是零编辑、只关注在创作之上的，这是至关重要的资本原始积累，所以格局一定要大。 对内的写作是一个认识自己的过程，所以要诚实地面对内心的所有情感，尤其是那些不足为外人道也的阴暗的部分。比如说，跟你走得很近的人里有一个你很鄙视的人，但是你又不得不装作和ta相处起来很愉快，那你不妨可以在对内的写作过程中梳理这种情感。挖掘自己的邪恶天赋，并承认它们，是帮助自己成长为一个丰富的人的必经之路。 对内的写作也是一个用来讨好自己的过程。在我以前还很热衷于写日记的时候，我的日记本是一本红色软皮抄。我喜欢它封面的颜色，更喜欢它米色的空白内页。内页纸张的触感很好，而且不会晕墨，真的是难能可贵的品质。我喜欢用墨蓝或者深绿的墨水写日记，尤其喜欢用英雄616钢笔。偏好的场所包括图书馆的静音区和自己的房间。我尤其喜欢物理意义上的下笔，虽然有的时候也在电脑上写日记，但总感觉动笔的信息量更大，毕竟笔迹可以直白地展示当时的心理状态，而且我总喜欢看自己在不同时期的笔迹的变化。这些癖好让我觉得对内的写作是一种仪式，是一种褒奖，是一种可以独享的时光。那本红色软皮抄用完之后我仿佛丧失了写日记的兴趣，因为再也没有找到媲美它的日记本了，不得不说，很可惜。 对外的写作，是内部世界朝外部的扩张。我个人主张它必须是功利的。所谓功利，是指功效和实用性，说直白一点就是，既然你选择了对外写作，就应该对你传播的这些信息负责，让它们尽可能高效地被读者所接收。所以对外的写作应该是方便理解的、易于消化的。要呈现这种特性，在对外写作的过程中就务必有相当一部分的精力花在编辑之上。如果说对内的写作单纯需要用心，对外的写作则更需要用脑。 写到这里，不得不提写作与朗读之间的密不可分的关系。 我在上写作课的时候，教授给我们讲过这样一个有趣的故事。说是有一个写作界的大神，看人很准，曾经试过一连好几年的普利策获奖者都是他曾经相中过表扬过的新人。于是有人去问大神，他眼光为什么这么厉害。大神说，我去编辑部里面看啊，看到那些写稿子的时候嘴里在念念有词的人，我就知道他们有戏了。 教授给我们讲这个故事，意图是要让我们爱上朗读自己的作品，不但如此，更要用朗读的方式去体会其他优秀的写作。朗读，实际上是一场非常严肃的检阅。从编辑方面的效用来看，在朗读的过程中，很容易就能挑出错别字、语病、累赘用词等等小毛病，也可以发现段落间逻辑衔接有没有跳脱这样的结构上的问题。 曾经有人评价我的行文是轻松的、不费力的，大概也是因为我总是以口语化的要求来规范自己的写作吧。也有人曾经给我提意见说，你能不能不要念，专心写，因为你的文笔远胜于你的口头表达，要念出来的话等于限制了你文采的发挥。我当然承认，为了口语化理念的贯彻，不得不让渡出一部分高深的辞藻和逻辑。但口语化的理念可以让写作者更多地采用主谓宾的语序，减少繁杂的修饰语，抛弃冗长的句式结构，实际上是一种更生活、更亲近的表达方式。这种亲近可以让写作者的内部世界建立与外部世界友好的交流，而信息的顺畅流通恰好又可以维持一个更饱满鲜活的内部世界。出于这种理念，我个人也非常不喜欢故作傲慢和刻意艰涩的写作，总让人感到一种封闭和敌意。 我本科的最后一年花了整整两个学期在上写作课，但结果却是对写作像一个新朋友一样。 我并不恐慌，相反的，我对这个变化感到无比的兴奋。想到之前写作课教授给我们援引过的一句话，那是美国著名诗人、作家卡尔·桑德堡在72岁的时候说的： I’m still studying verbs and the mystery of how they connect nouns. I am more suspicious of adjectives than at any other time in all my born days. “我仍旧在学习动词，以及它们和名词连接的奥秘。现在的我比任何时候都更怀疑形容词。” 就像是一个幼儿园小朋友在堆积木的时候的有趣的发现。真是一种有美感的状态。 我希望，我也能活出那样的一天。 转自新浪微博 @恢复吃素的F小姐。 说一个我认为最有逼格的故事吧：某日跟某死党微信对话如下:]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ES-5.0.2-学习(2)——Kibana+X-Pack介绍使用]]></title>
      <url>%2F2017%2F02%2F09%2FES-5-0-2-%E5%AD%A6%E4%B9%A0-1-%E2%80%94%E2%80%94Kibana-X-Pack%E4%BB%8B%E7%BB%8D%E4%BD%BF%E7%94%A8%2F</url>
      <content type="text"><![CDATA[Kibana是一个为 ElasticSearch 提供的数据分析的 Web 接口。可使用它对日志进行高效的搜索、可视化、分析等各种操作。Kibana目前最新的版本5.0.2，回顾一下Kibana 3和Kibana 4的界面。下面的图展示的是Kibana 3的界面，所有的仪表盘直接放置主页。下面的图展示的是Kibana 4的界面，和Kibana 3最大的区别是将原来的主体分成三个部分，分别是发现页、可视化、仪表盘。下面是目前Kibana 5最新版本的界面。相比较Kibana 4除了界面的风格变化，最主要是功能栏上添加了Timeline、Management和Dev Tools选项。 Discover You can interactively explore your data from the Discover page. You have access to every document in every index that matches the selected index pattern. You can submit search queries, filter the search results, and view document data. You can also see the number of documents that match the search query and get field value statistics. If a time field is configured for the selected index pattern, the distribution of documents over time is displayed in a histogram at the top of the page. 从发现页可以交互地探索ES的数据。可以访问与所选索引模式相匹配的每一个索引中的每一个文档。您可以提交搜索查询、筛选搜索结果和查看文档数据。还可以看到匹配搜索查询和获取字段值统计的文档的数量。如果一个时间字段被配置为所选择的索引模式，则文档的分布随着时间的推移显示在页面顶部的直方图中。 Visualize Visualize enables you to create visualizations of the data in your Elasticsearch indices. You can then build dashboards that display related visualizations.Kibana visualizations are based on Elasticsearch queries. By using a series of Elasticsearch aggregations to extract and process your data, you can create charts that show you the trends, spikes, and dips you need to know about.You can create visualizations from a search saved from Discover or start with a new search query. 可视化能使你创造你的Elasticsearch指标数据的可视化。然后你可以建立仪表板显示相关的可视化。Kibana的可视化是基于Elasticsearch查询。通过一系列的Elasticsearch聚合提取和处理您的数据，您可以创建图表显示你需要知道的关于趋势，峰值和骤降。您可以从搜索保存的搜索中创建可视化或从一个新的搜索查询开始。 Dashboard A Kibana dashboard displays a collection of saved visualizations. You can arrange and resize the visualizations as needed and save dashboards so they be reloaded and shared. 一个仪表板显示Kibana保存的一系列可视化。你可以根据需要安排和调整可视化，并保存仪表盘，可以被加载和共享。 Monitoring从图中可以发现，默认Kibana是没有该选项的。其实，Monitoring是由X-Pack集成提供的。 The X-Pack monitoring components enable you to easily monitor Elasticsearch through Kibana. You can view cluster health and performance in real time as well as analyze past cluster, index, and node metrics. In addition, you can monitor the performance of Kibana itself.When you install X-Pack on your cluster, a monitoring agent runs on each node to collect and index metrics from Elasticsearch. With X-Pack installed in Kibana, you can then view the monitoring data through a set of specialized dashboards. 该X-pack监控组件使您可以通过Kibana轻松地监控ElasticSearch。您可以实时查看集群的健康和性能，以及分析过去的集群、索引和节点度量。此外，您可以监视Kibana本身性能。当你安装X-pack在群集上，监控代理运行在每个节点上收集和指数指标从Elasticsearch。安装在X-pack在Kibana上，您可以查看通过一套专门的仪表板监控数据。回顾安装过程：ES-5-0-2-学习-1-——安装Elasticsearch、Kibana和X-Pack/，可以发现，在安装X-pack的时候分别在ElasticSearch根目录和Kibana根目录下操作。 Graph The X-Pack graph capabilities enable you to discover how items in an Elasticsearch index are related. You can explore the connections between indexed terms and see which connections are the most meaningful. This can be useful in a variety of applications, from fraud detection to recommendation engines.For example, graph exploration could help you uncover website vulnerabilities that hackers are targeting so you can harden your website. Or, you might provide graph-based personalized recommendations to your e-commerce customers.X-Pack provides a simple, yet powerful graph exploration API, and an interactive graph visualization tool for Kibana. Both work with out of the box with existing Elasticsearch indices—you don’t need to store any additional data to use the X-Pack graph features. X-Pack图的能力使你发现一个Elasticsearch索引项是如何相关联的。你可以探索索引条款之间的连接，看看哪些连接是最有意义的。从欺诈检测到推荐引擎，对各种应用中这都是有用的，例如，图的探索可以帮助你发现网站上黑客的目标的漏洞，所以你可以硬化你的网站。或者，您可以为您的电子商务客户提供基于图表的个性化推荐。X-pack提供简单，但功能强大的图形开发API，和Kibana交互式图形可视化工具。使用X-pack图有工作与开销与现有Elasticsearch指标你不需要任何额外的数据存储的特征。 Timelion Timelion is a time series data visualizer that enables you to combine totally independent data sources within a single visualization. It’s driven by a simple expression language you use to retrieve time series data, perform calculations to tease out the answers to complex questions, and visualize the results. Timelion是一个时间序列数据的可视化，可以结合在一个单一的可视化完全独立的数据源。它是由一个简单的表达式语言驱动的，你用来检索时间序列数据，进行计算，找出复杂的问题的答案，并可视化的结果。这个功能由一系列的功能函数组成，同样的查询的结果，也可以通过Dashboard显示查看。 Management The Management application is where you perform your runtime configuration of Kibana, including both the initial setup and ongoing configuration of index patterns, advanced settings that tweak the behaviors of Kibana itself, and the various “objects” that you can save throughout Kibana such as searches, visualizations, and dashboards.This section is pluginable, so in addition to the out of the box capabitilies, packs such as X-Pack can add additional management capabilities to Kibana.管理中的应用是在你执行你的运行时配置kibana，包括初始设置和指标进行配置模式，高级设置，调整自己的行为和Kibana，各种“对象”，你可以查看保存在整个Kibana的内容如发现页，可视化和仪表板。这部分是pluginable，除此之外，X-pack可以给Kibana增加额外的管理能力。You can use X-Pack Security to control what Elasticsearch data users can access through Kibana.When you install X-Pack, Kibana users have to log in. They need to have the kibana_user role as well as access to the indices they will be working with in Kibana.If a user loads a Kibana dashboard that accesses data in an index that they are not authorized to view, they get an error that indicates the index does not exist. X-Pack Security does not currently provide a way to control which users can load which dashboards. 你可以使用X-pack安全控制哪些用户可以访问Elasticsearch数据通过Kibana。当你安装X-pack，Kibana用户登录。他们需要有kibana_user作用以及获得的指标，他们将在Kibana的工作。如果用户加载Kibana仪表板，访问数据的一个索引，他们未被授权查看，他们得到一个错误，表明指数不存在。X-pack安全目前并不提供一种方法来控制哪些用户可以负荷的仪表板。 Dev Tools原先的交互式控制台Sense，使用户方便的通过浏览器直接与Elasticsearch进行交互。从Kibana 5开始改名并直接内建在Kibana，就是Dev Tools选项。注意如果是Kibana 5以上，不能通过以下命令安装Sense。(踩过的坑)1./bin/kibana plugin --install elastic/sense 或者1./bin/kibana-plugin install elastic/sense instead 总结内容比较简单，主要是对Kibana工具的整体功能总结，方便接下来对ElasticSearch 5的学习，其中X-Pack主要是添加身份权限的验证，以及原先需要安装其他各种Marvel、Hand等各种功能插件添加到Kibana上使用才能使用的功能。学习链接：X-Pack：https://www.elastic.co/guide/en/x-pack/current/xpack-introduction.htmlKibana：https://www.elastic.co/guide/en/kibana/current/introduction.html 出处：http://www.cnblogs.com/wxw16/p/6156335.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Markdown——入门指南]]></title>
      <url>%2F2017%2F02%2F09%2FMarkdown%E2%80%94%E2%80%94%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%2F</url>
      <content type="text"><![CDATA[导语：Markdown 是一种轻量级的「标记语言」，它的优点很多，目前也被越来越多的写作爱好者，撰稿者广泛使用。看到这里请不要被「标记」、「语言」所迷惑，Markdown 的语法十分简单。常用的标记符号也不超过十个，这种相对于更为复杂的 HTML 标记语言来说，Markdown 可谓是十分轻量的，学习成本也不需要太多，且一旦熟悉这种语法规则，会有一劳永逸的效果。 一、认识 Markdown在刚才的导语里提到，Markdown 是一种用来写作的轻量级「标记语言」，它用简洁的语法代替排版，而不像一般我们用的字处理软件 Word 或 Pages 有大量的排版、字体设置。它使我们专心于码字，用「标记」语法，来代替常见的排版格式。例如此文从内容到格式，甚至插图，键盘就可以通通搞定了。目前来看，支持 Markdown 语法的编辑器有很多，包括很多网站（例如简书）也支持了 Markdown 的文字录入。Markdown 从写作到完成，导出格式随心所欲，你可以导出 HTML 格式的文件用来网站发布，也可以十分方便的导出 PDF 格式，这种格式写出的简历更能得到 HR 的好感。甚至可以利用 CloudApp 这种云服务工具直接上传至网页用来分享你的文章，全球最大的轻博客平台 Tumblr，也支持 Mou 这类 Markdown 工具的直接上传。 Markdown 官方文档这里可以看到官方的 Markdown 语法规则文档，当然，后文我也会用自己的方式阐述这些语法的具体用法。 创始人 John Gruber 的 Markdown 语法说明 Markdown 中文版语法说明 使用 Markdown 的优点 专注你的文字内容而不是排版样式，安心写作。 轻松的导出 HTML、PDF 和本身的 .md 文件。 纯文本内容，兼容所有的文本编辑器与字处理软件。 随时修改你的文章版本，不必像字处理软件生成若干文件版本导致混乱。 可读、直观、学习成本低。 使用 Markdown 的误区 We believe that writing is about content, about what you want to say – not about fancy formatting. 我们坚信写作写的是内容，所思所想，而不是花样格式。 — Ulysses for Mac Markdown 旨在简洁、高效，也由于 Markdown 的易读易写，人们用不同的编程语言实现了多个版本的解析器和生成器，这就导致了目前不同的 Markdown 工具集成了不同的功能（基础功能大致相同），例如流程图与时序图，复杂表格与复杂公式的呈现，虽然功能的丰富并没有什么本质的缺点，但终归有些背离初衷，何况在编写的过程中很费神，不如使用专业的工具撰写来的更有效率，所以如果你需实现复杂功能，专业的图形界面工具会更加方便。当然，如果你对折腾这些不同客户端对 Markdown 的定制所带来高阶功能感到愉悦的话，那也是无可厚非的。 二、Markdown 语法的简要规则标题标题是每篇文章都需要也是最常用的格式，在 Markdown 中，如果一段文字被定义为标题，只要在这段文字前加 # 号即可。 #一级标题 ##二级标题 ###三级标题 以此类推，总共六级标题，建议在井号后加一个空格，这是最标准的 Markdown 语法。 列表熟悉 HTML 的同学肯定知道有序列表与无序列表的区别，在 Markdown 下，列表的显示只需要在文字前加上 - 或 * 即可变为无序列表，有序列表则直接在文字前加1. 2. 3. 符号要和文字之间加上一个字符的空格。 引用如果你需要引用一小段别处的句子，那么就要用引用的格式。只需要在文本前加入 &gt; 这种尖括号（大于号）即可 图片与链接注：使用markdown写文章，插入图片的格式为图片名称，这里要说的是链接地址怎么写。对于hexo，有两种方式：使用本地路径：在hexo/source目录下新建一个img文件夹，将图片放入该文件夹下，插入图片时链接即为/img/图片名称。使用微博图床，地址http://weibotuchuang.sinaapp.com/，将图片拖入区域中，会生成图片的URL，这就是链接地址。 粗体与斜体Markdown 的粗体和斜体也非常简单，用两个 包含一段文本就是粗体的语法，用一个 包含一段文本就是斜体的语法。例如：这里是粗体 这里是斜体 表格表格是我觉得 Markdown 比较累人的地方，例子如下：这种语法生成的表格如下： 代码框如果你是个程序猿，需要在文章里优雅的引用代码框，在 Markdown下实现也非常简单，只需要用两个 把中间的代码包裹起来。this is code`使用 tab 键即可缩进。 块代码两种方式1.代码每一行的前面都加4个空格或一个tab2.第一行和最后一行都是3个，中间的行是代码12this is code block 1this is code block 2 分割线分割线的语法只需要三个 * 号，例如： 三、相关推荐:图床工具用来上传图片获取 URL 地址 Droplr Cloudapp ezShare for Mac 围脖图床修复计划]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ES-5.0.2-学习(1)——安装Elasticsearch、Kibana和X-Pack]]></title>
      <url>%2F2017%2F02%2F09%2FES-5-0-2-%E5%AD%A6%E4%B9%A0-1-%E2%80%94%E2%80%94%E5%AE%89%E8%A3%85Elasticsearch%E3%80%81Kibana%E5%92%8CX-Pack%2F</url>
      <content type="text"><![CDATA[安装准备：安装Elasticsearch唯一的要求是安装官方新版的Java，包括对应的Jdk。 安装Elasticsearch首先到官网下载最新版本的Elasticsearch压缩包。可以使用命令，注意将最新的可用的下载链接填入：123curl -L -O https://artifacts.elastic.co/downloads/elasticsearch/ elasticsearch-5.0.2.zipunzip elasticsearch-5.0.2.zipcd elasticsearch-5.0.2 运行ElasticsearchElasticsearch已经准备就绪，执行以下命令可在前台启动：1./bin/elasticsearch 如果想在后台以守护进程模式运行，添加-d参数。打开另一个终端进行测试：1curl &apos;http://localhost:9200/?pretty&apos; 你能看到以下返回信息：12345678910111213&#123;&quot;name&quot;: &quot;vP19PMO&quot;,&quot;cluster_name&quot;: &quot;elasticsearch&quot;,&quot;cluster_uuid&quot;: &quot;IMKMfkMsSrKODIYg5gxgeQ&quot;,&quot;version&quot;: &#123; &quot;number&quot;: &quot;5.0.2&quot;, &quot;build_hash&quot;: &quot;f6b4951&quot;, &quot;build_date&quot;: &quot;2016-11-24T10:07:18.101Z&quot;, &quot;build_snapshot&quot;: false, &quot;lucene_version&quot;: &quot;6.2.1&quot;&#125;,&quot;tagline&quot;: &quot;You Know, for Search&quot;&#125; 这说明你的ELasticsearch集群已经启动并且正常运行。 安装KiabnaKibana是一个为 ElasticSearch 提供的数据分析的 Web 接口。可使用它对日志进行高效的搜索、可视化、分析等各种操作。首先到官网下载最新版本的Kiabna压缩包。可以使用如下命令，注意将最新的可用的下载链接填入：1234wget https://artifacts.elastic.co/downloads/kibana/kibana-5.1.1-linux-x86_64.tar.gzsha1sum kibana-5.1.1-linux-x86_64.tar.gztar -xzf kibana-5.1.1-linux-x86_64.tar.gzcd kibana/ 注意：https://www.elastic.co/downloads/kibana 可以在该地址获取下载链接，一定要选择对于系统和版本。 按照文档的要求，一般情况下kibana的版本必须和Elasticsearch安装的版本一致。 安装X-PackX-Pack是一个Elastic Stack的扩展，将安全，警报，监视，报告和图形功能包含在一个易于安装的软件包中。在Elasticsearch 5.0.0之前，您必须安装单独的Shield，Watcher和Marvel插件才能获得在X-Pack中所有的功能。 下载前提Elasticsearch 5.0.2Kibana 5.0.2 Elasticsearch下载X-Pack在Es的根目录（每个节点），运行 bin/elasticsearch-plugin 进行安装。1bin/elasticsearch-plugin install x-pack/Users/root/Downloads/markdown/763363-20161209181135163-1294099591.png 安装过程中跳出选项现在y即可。如果你在Elasticsearch已禁用自动索引的创建，在elasticsearch.yml配置action.auto_create_index允许X-pack创造以下指标：1action.auto_create_index: .security,.monitoring*,.watches,.triggered_watches,.watcher-history* 运行Elasticsearch。1bin/elasticsearch Kibana下载X-Pack在Kibana根目录运行 bin/kibana-plugin 进行安装。1bin/kibana-plugin install x-pack/Users/root/Downloads/markdown/1.png 安装过程会比较久，耐心等待。运行Kibana。1bin/kibana 验证X-Pack在浏览器上输入：http://localhost:5601/ ，可以打开Kibana，此时需要输入用户名和密码登录，默认分别是 elastic 和 changeme。 安装参考：每个操作系统安装Elasticsearch的文件选择不同，参考：https://www.elastic.co/downloads/elasticsearch，选择对应的文件下载。 安装Kiabna需要根据操作系统做选择，参考：https://www.elastic.co/guide/en/kibana/current/install.html，选择对应的文件下载。*安装X-Pack需要根据Elasticsearch安装不同的方式提供不同的安装方法，参考：https://www.elastic.co/guide/en/x-pack/5.0/installing-xpack.html#installing-xpack。 名词解释在刚接触Elasticsearch的时候，会有很多名词不能理解，或者不知道其中的关系。其中很多是为不同版本的Elasticsearch而存在的。 MarvelMarvel插件：在簇中从每个节点汇集数据。这个插件必须每个节点都得安装。Marvel是Elasticsearch的管理和监控工具，在开发环境下免费使用。它包含了Sense。 Sense交互式控制台，使用户方便的通过浏览器直接与Elasticsearch进行交互。 Hand在学习Elasticsearch的过程中，必不可少需要通过一些工具查看es的运行状态以及数据。如果都是通过rest请求，未免太过麻烦，而且也不够人性化。此时，Head插件可以实现基本信息的查看，rest请求的模拟，数据的检索等等。 X-packx-pack是elasticsearch的一个扩展包，将安全，警告，监视，图形和报告功能捆绑在一个易于安装的软件包中，也是官方推荐的。 Kibanakibana是一个与elasticsearch一起工作的开源的分析和可视化的平台。使用kibana可以查询、查看并与存储在elasticsearch索引的数据进行交互操作。使用kibana能执行高级的数据分析，并能以图表、表格和地图的形式查看数据。kibana使得理解大容量的数据变得非常容易。它非常简单，基于浏览器的接口使我们能够快速的创建和分享显示elasticsearch查询结果实时变化的仪表盘。在Elasticsearch 5版本之前，一般都是通过安装Kibana，而后将Marvel、Hand等各种功能插件添加到Kibana上使用。在Elasticsearch 5版本之后，一般情况下只需要安装一个官方推荐的X-pack扩展包即可。 出处：http://www.cnblogs.com/wxw16/p/6150681.html]]></content>
    </entry>

    
  
  
</search>
