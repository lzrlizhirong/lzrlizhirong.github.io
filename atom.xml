<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>参差行者</title>
  <subtitle>日积跬步,志在千里</subtitle>
  <link href="//atom.xml" rel="self"/>
  
  <link href="http://lzrlizhirong.github.io/"/>
  <updated>2017-02-27T11:01:24.000Z</updated>
  <id>http://lzrlizhirong.github.io/</id>
  
  <author>
    <name>参差行者</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Spark快速大数据分析</title>
    <link href="http://lzrlizhirong.github.io/2017/02/27/Spark%E5%BF%AB%E9%80%9F%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    <id>http://lzrlizhirong.github.io/2017/02/27/Spark快速大数据分析/</id>
    <published>2017-02-27T10:59:55.000Z</published>
    <updated>2017-02-27T11:01:24.000Z</updated>
    
    <content type="html"><![CDATA[<p>原书电子版下载地址：<br><a href="http://download.csdn.net/download/wangcunlin/9547494" target="_blank" rel="external">http://download.csdn.net/download/wangcunlin/9547494</a><br><a id="more"></a><br>整本书梳理如下：<br><img src="/2017/02/27/Spark快速大数据分析/../../../../images/spark1.png" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;原书电子版下载地址：&lt;br&gt;&lt;a href=&quot;http://download.csdn.net/download/wangcunlin/9547494&quot;&gt;http://download.csdn.net/download/wangcunlin/9547494&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://lzrlizhirong.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="spark" scheme="http://lzrlizhirong.github.io/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>推荐引擎系统结构</title>
    <link href="http://lzrlizhirong.github.io/2017/02/27/%E6%8E%A8%E8%8D%90%E5%BC%95%E6%93%8E%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84/"/>
    <id>http://lzrlizhirong.github.io/2017/02/27/推荐引擎系统结构/</id>
    <published>2017-02-27T10:51:35.000Z</published>
    <updated>2017-02-27T10:56:59.000Z</updated>
    
    <content type="html"><![CDATA[<p>推荐引擎系统结构图如下：<br><img src="/2017/02/27/推荐引擎系统结构/../../../../images/tuijian1.jpeg" alt=""><br><a id="more"></a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;推荐引擎系统结构图如下：&lt;br&gt;&lt;img src=&quot;/2017/02/27/推荐引擎系统结构/../../../../images/tuijian1.jpeg&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="架构" scheme="http://lzrlizhirong.github.io/categories/%E6%9E%B6%E6%9E%84/"/>
    
    
      <category term="推荐系统" scheme="http://lzrlizhirong.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="架构" scheme="http://lzrlizhirong.github.io/tags/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>为什么这么多人认为到西藏旅游就能找到人生真谛？</title>
    <link href="http://lzrlizhirong.github.io/2017/02/24/why-do-so-many-people-think-that-travel-to-tibet-will-be-able-to-find-the-true-meaning-of-life/"/>
    <id>http://lzrlizhirong.github.io/2017/02/24/why-do-so-many-people-think-that-travel-to-tibet-will-be-able-to-find-the-true-meaning-of-life/</id>
    <published>2017-02-24T07:23:48.000Z</published>
    <updated>2017-02-24T07:27:07.000Z</updated>
    
    <content type="html"><![CDATA[<p>偶然看到的一篇短文，分享给有缘的你。</p>
<hr>
<p><strong>因为他们走过的地方还不够多。他们所谓的真谛是如此的肤浅。</strong></p>
<p>在这个信仰缺失的国度和信仰缺失的时代，一些人高喊着辞职去XX，去XX流浪，心灵的旅行之类的总总话语。奔赴某地，看到了一些日常生活中不曾见识的人文抑或自然景观，自以为心受洗礼，旅行结束回到家中，却与俗人无异。<br><a id="more"></a><br><strong>标榜旅行经历炫耀所见所闻的人多之又多，而真正因为旅行而获得真谛，改变人生的人少之又少。</strong></p>
<p>我也曾入藏，所见所闻虽然震撼，可是说到真谛，可真是无法总结无法表达。</p>
<p>回到丽江后接待沙发客，数来也有百十来个，有揣着复古交卷相机的豆瓣女青年，有日行80公里胡子拉碴的徒步者，有骑摩托环游中国的大龄未婚女青年，有浮夸牛逼旅途的背包客。</p>
<p>在众多人之中，只有一个女孩真正打动过我。</p>
<p>皮肤黝黑，穿着拖鞋，一个学生式的书包，没有任何户外设备和相机。 签证到期，她从印度回国，重游云南，除非我问到，她从不主动谈自己那些旅行的故事。</p>
<p>她在国内旅游三年，在国外七年，经费靠打工和家中支持。有一个瑞士的男友。 她不写游记，不拍照片，上上网只查查基础的信息。</p>
<p>她坐在我身旁，我完全能感受到内心的平和和宁静。 深夜，我和她坐在古城的院子里喝酒。 我问她，你去过这么多地方，哪里让你感觉最好？</p>
<p>她说，哪都好呀。 我问她，你会一直这样玩下去么？ 她说，再看吧。 我问她，你出来这么久，走过这么地方，有没有什么深刻的感悟。</p>
<p>她说，哪有那么多感悟，我只是想多走走看看，我觉得这样挺有意思的。 就是这样平和的对话，她是我至今最欣赏的旅者。</p>
<p><strong>哪有那么多真谛。</strong></p>
<p><strong>大音希声，大象无形。</strong></p>
<p><strong>心中安定的人，走到哪里都是春天。</strong></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;偶然看到的一篇短文，分享给有缘的你。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;因为他们走过的地方还不够多。他们所谓的真谛是如此的肤浅。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在这个信仰缺失的国度和信仰缺失的时代，一些人高喊着辞职去XX，去XX流浪，心灵的旅行之类的总总话语。奔赴某地，看到了一些日常生活中不曾见识的人文抑或自然景观，自以为心受洗礼，旅行结束回到家中，却与俗人无异。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="杂文" scheme="http://lzrlizhirong.github.io/categories/%E6%9D%82%E6%96%87/"/>
    
      <category term="旅行" scheme="http://lzrlizhirong.github.io/categories/%E6%9D%82%E6%96%87/%E6%97%85%E8%A1%8C/"/>
    
    
      <category term="旅行" scheme="http://lzrlizhirong.github.io/tags/%E6%97%85%E8%A1%8C/"/>
    
      <category term="杂文" scheme="http://lzrlizhirong.github.io/tags/%E6%9D%82%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>人为什么要旅行</title>
    <link href="http://lzrlizhirong.github.io/2017/02/24/why-do-people-travel/"/>
    <id>http://lzrlizhirong.github.io/2017/02/24/why-do-people-travel/</id>
    <published>2017-02-24T07:07:00.000Z</published>
    <updated>2017-02-24T07:13:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>“有些人，一辈子缩在一个角落里， 连窗外都懒得看，更别说踏出门……” 你不出去走走，真的会以为这就是世界。</p>
<p>生命不是一场赛跑，而是一次旅行。比赛在乎终点，而旅行在乎沿途风景。常人说：不登山，不知山高；不涉水，不晓水深；不赏奇景，怎知其绝妙。<br><a id="more"></a><br><img src="/2017/02/24/why-do-people-travel/../../../../images/people1.jpeg" alt=""></p>
<p>读万卷书，还须行万里路。旅行，可以使你中断每天周而复始的凡人琐事，对平凡俗气的生活，是一种暂时的解脱，让自己的胸怀得以舒展，心灵得以净化！</p>
<p>早上，迎着新一轮的朝阳，伴着晨起的钟声，开始我一天的旅程；傍晚，看着火红的夕阳西下，微笑着收获着一天的美好；晚上，看着满天繁星点点，轻轻地对自己说晚安，明天，将会是一段全新的征程。</p>
<p>趁年轻，趁还有梦想，想去的地方，现在就要去。想做的事情，现在就去做。哪怕搭车、睡沙发、住客栈，享受在路上，看风景是不变的信念！</p>
<p>人的一生需要考虑的太多太多，经历的也太多太多，得空往自己的心里书写一个坚定的“静”字，放下那些虚幻，真心实意的放松，这些年，这一生，哪有时间会留给你思考和休息？你的昨天，是多少人不曾经历过又奢求不来的；你的今天，又是多少人想尽一切方法都回不来的曾经啊。 你是否也和我一样？拥有一颗想要出走的心，却依然坐在一张不足一平的办公椅上？</p>
<p>旅行不要再等，说走就走吧。</p>
<p>爱护自己的梦想，也要善待自己！！！</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;“有些人，一辈子缩在一个角落里， 连窗外都懒得看，更别说踏出门……” 你不出去走走，真的会以为这就是世界。&lt;/p&gt;
&lt;p&gt;生命不是一场赛跑，而是一次旅行。比赛在乎终点，而旅行在乎沿途风景。常人说：不登山，不知山高；不涉水，不晓水深；不赏奇景，怎知其绝妙。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="杂文" scheme="http://lzrlizhirong.github.io/categories/%E6%9D%82%E6%96%87/"/>
    
    
      <category term="写作" scheme="http://lzrlizhirong.github.io/tags/%E5%86%99%E4%BD%9C/"/>
    
      <category term="旅行" scheme="http://lzrlizhirong.github.io/tags/%E6%97%85%E8%A1%8C/"/>
    
  </entry>
  
  <entry>
    <title>安装impala</title>
    <link href="http://lzrlizhirong.github.io/2017/02/23/%E5%AE%89%E8%A3%85impala/"/>
    <id>http://lzrlizhirong.github.io/2017/02/23/安装impala/</id>
    <published>2017-02-23T08:21:20.000Z</published>
    <updated>2017-02-24T02:52:24.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-默认安装好hadoop并且能正常启动-只需hdfs即可"><a href="#1-默认安装好hadoop并且能正常启动-只需hdfs即可" class="headerlink" title="1.默认安装好hadoop并且能正常启动(只需hdfs即可)"></a>1.默认安装好hadoop并且能正常启动(只需hdfs即可)</h1><h1 id="2-安装如下rpm包-需要root权限-注意顺序"><a href="#2-安装如下rpm包-需要root权限-注意顺序" class="headerlink" title="2.安装如下rpm包(需要root权限 注意顺序)"></a>2.安装如下rpm包(需要root权限 注意顺序)</h1><blockquote>
<p>bigtop-utils-0.7.0+cdh5.8.2+0-1.cdh5.8.2.p0.5.el6.noarch.rpm<br>impala-kudu-2.7.0+cdh5.9.0+0-1.cdh5.9.0.p0.11.el6.x86_64.rpm<br>impala-kudu-catalog-2.7.0+cdh5.9.0+0-1.cdh5.9.0.p0.11.el6.x86_64.rpm<br>impala-kudu-state-store-2.7.0+cdh5.9.0+0-1.cdh5.9.0.p0.11.el6.x86_64.rpm<br>impala-kudu-server-2.7.0+cdh5.9.0+0-1.cdh5.9.0.p0.11.el6.x86_64.rpm<br>impala-kudu-shell-2.7.0+cdh5.9.0+0-1.cdh5.9.0.p0.11.el6.x86_64.rpm<br>impala-kudu-udf-devel-2.7.0+cdh5.9.0+0-1.cdh5.9.0.p0.11.el6.x86_64.rpm</p>
</blockquote>
<a id="more"></a>
<p>　　安装命令如下:</p>
<blockquote>
<p>rpm -ivh ./bigtop-utils-0.7.0+cdh5.8.2+0-1.cdh5.8.2.p0.5.el6.noarch.rpm<br>rpm -ivh ./impala-kudu-2.7.0+cdh5.9.0+0-1.cdh5.9.0.p0.11.el6.x86_64.rpm –nodeps //需要取消依赖安装，不然安装不过<br>rpm -ivh ./impala-kudu-catalog-2.7.0+cdh5.9.0+0-1.cdh5.9.0.p0.11.el6.x86_64.rpm<br>rpm -ivh ./impala-kudu-state-store-2.7.0+cdh5.9.0+0-1.cdh5.9.0.p0.11.el6.x86_64.rpm<br>rpm -ivh ./impala-kudu-server-2.7.0+cdh5.9.0+0-1.cdh5.9.0.p0.11.el6.x86_64.rpm<br>rpm -ivh ./impala-kudu-shell-2.7.0+cdh5.9.0+0-1.cdh5.9.0.p0.11.el6.x86_64.rpm<br>rpm -ivh ./impala-kudu-udf-devel-2.7.0+cdh5.9.0+0-1.cdh5.9.0.p0.11.el6.x86_64.rpm</p>
</blockquote>
<p>其中catalog和state-store只能主节点一个(可安装于不同的主机) server和shell可以多台(可跟catalog和state-store不是同一台)</p>
<h1 id="3-配置环境"><a href="#3-配置环境" class="headerlink" title="3.配置环境"></a>3.配置环境</h1><h2 id="3-1-修改-etc-default-bigtop-utils文件"><a href="#3-1-修改-etc-default-bigtop-utils文件" class="headerlink" title="3.1.修改/etc/default/bigtop-utils文件"></a>3.1.修改/etc/default/bigtop-utils文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">export JAVA_HOME=/usr/java/jdk1.8.0_65 //设置java home</div></pre></td></tr></table></figure>
<h2 id="3-2-修改-etc-default-impala文件"><a href="#3-2-修改-etc-default-impala文件" class="headerlink" title="3.2.修改/etc/default/impala文件"></a>3.2.修改/etc/default/impala文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">IMPALA_CATALOG_SERVICE_HOST=172.16.104.120 //为catalog主机Ip 也可以主机名 注意配置hosts</div><div class="line">IMPALA_STATE_STORE_HOST=172.16.104.120 //为state-store主机Ip</div><div class="line">IMPALA_LOG_DIR=/var/log/impala //配置日志路径 默认为/var/log/impala</div></pre></td></tr></table></figure>
<h2 id="3-3-在-etc-impala-conf-dist目录下添加core-site-xml和hdfs-site-xml文件-建议从hadoop配置文件中拷贝"><a href="#3-3-在-etc-impala-conf-dist目录下添加core-site-xml和hdfs-site-xml文件-建议从hadoop配置文件中拷贝" class="headerlink" title="3.3.在/etc/impala/conf.dist目录下添加core-site.xml和hdfs-site.xml文件(建议从hadoop配置文件中拷贝)"></a>3.3.在/etc/impala/conf.dist目录下添加core-site.xml和hdfs-site.xml文件(建议从hadoop配置文件中拷贝)</h2><p>其中core-site.xml添加内容如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">&lt;!-- impala --&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;dfs.client.read.shortcircuit&lt;/name&gt;</div><div class="line">    &lt;value&gt;true&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;dfs.client.read.shortcircuit.skip.checksum&lt;/name&gt;</div><div class="line">    &lt;value&gt;false&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;dfs.datanode.hdfs-blocks-metadata.enabled&lt;/name&gt;</div><div class="line">    &lt;value&gt;true&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure></p>
<p>hdfs-site.xml添加内容如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">&lt;!--impala--&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;dfs.datanode.hdfs-blocks-metadata.enabled&lt;/name&gt;</div><div class="line">    &lt;value&gt;true&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;dfs.block.local-path-access.user&lt;/name&gt;</div><div class="line">    &lt;value&gt;impala&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;dfs.client.file-block-storage-locations.timeout.millis&lt;/name&gt;</div><div class="line">    &lt;value&gt;60000&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure></p>
<h1 id="4-启动服务"><a href="#4-启动服务" class="headerlink" title="4.启动服务"></a>4.启动服务</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">　　service impala-catalog start</div><div class="line">　　service impala-state-store start</div><div class="line">　　service impala-server start</div></pre></td></tr></table></figure>
<h1 id="5-验证"><a href="#5-验证" class="headerlink" title="5.验证"></a>5.验证</h1><p>第一种方式:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">ps -aux|grep impala-catalog</div><div class="line">ps -aux|grep impala-state</div><div class="line">ps -aux|grep impalad</div></pre></td></tr></table></figure></p>
<p>第二种方式:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">impala-shell(默认连接本机的server)</div><div class="line">impala-shell -i 172.16.104.120 //连接指定ip的server impala-shell 如果是no connect状态 可以输入connect 172.16.104.120进行连接</div></pre></td></tr></table></figure></p>
<p>第三种方式(webUI):<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">172.16.104.120:25000</div><div class="line">172.16.104.120:25010</div><div class="line">172.16.104.120:25020</div></pre></td></tr></table></figure></p>
<h1 id="6-其他"><a href="#6-其他" class="headerlink" title="6.其他"></a>6.其他</h1><p>Impala Daemon(Impala 守护进程前端端口):21000 &gt;&gt; impala-shell, Beeswax, Cloudera ODBC 1.2 驱动 用于传递命令和接收结果<br>　　<br>Impala Daemon(Impala 守护进程前端端口):21050 &gt;&gt; 被使用 JDBC 或 Cloudera ODBC 2.0 及以上驱动的诸如 BI 工具之类的应用用来传递命令和接收结果<br>　　<br>Impala Daemon(Impala 守护进程后端端口):22000 &gt;&gt; Impala 守护进程用该端口互相通讯<br>　　<br>Impala Daemon(StateStore订阅服务端口):23000 &gt;&gt; Impala 守护进程监听该端口接收来源于 state store 的更新<br>　　<br>StateStore Daemon(StateStore 服务端口):24000 &gt;&gt; State store 监听该端口的registration/unregistration 请求</p>
<p>Catalog Daemon(StateStore 服务端口):26000 &gt;&gt; 目录服务使用该端口与Imp</p>
<p>Impala Daemon(HTTP 服务器端口):25000 &gt;&gt; Impala web 接口，管理员用于监控和故障排除</p>
<p>StateStore Daemon(HTTP 服务器端口):25010 &gt;&gt; StateStore web 接口，管理员用于监控和故障排除</p>
<p>Catalog Daemon(HTTP 服务器端口):25020 &gt;&gt; 目录服务 web 接口，管理员用于监控和故障排除，Impala 1.2 开始使用</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-默认安装好hadoop并且能正常启动-只需hdfs即可&quot;&gt;&lt;a href=&quot;#1-默认安装好hadoop并且能正常启动-只需hdfs即可&quot; class=&quot;headerlink&quot; title=&quot;1.默认安装好hadoop并且能正常启动(只需hdfs即可)&quot;&gt;&lt;/a&gt;1.默认安装好hadoop并且能正常启动(只需hdfs即可)&lt;/h1&gt;&lt;h1 id=&quot;2-安装如下rpm包-需要root权限-注意顺序&quot;&gt;&lt;a href=&quot;#2-安装如下rpm包-需要root权限-注意顺序&quot; class=&quot;headerlink&quot; title=&quot;2.安装如下rpm包(需要root权限 注意顺序)&quot;&gt;&lt;/a&gt;2.安装如下rpm包(需要root权限 注意顺序)&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;bigtop-utils-0.7.0+cdh5.8.2+0-1.cdh5.8.2.p0.5.el6.noarch.rpm&lt;br&gt;impala-kudu-2.7.0+cdh5.9.0+0-1.cdh5.9.0.p0.11.el6.x86_64.rpm&lt;br&gt;impala-kudu-catalog-2.7.0+cdh5.9.0+0-1.cdh5.9.0.p0.11.el6.x86_64.rpm&lt;br&gt;impala-kudu-state-store-2.7.0+cdh5.9.0+0-1.cdh5.9.0.p0.11.el6.x86_64.rpm&lt;br&gt;impala-kudu-server-2.7.0+cdh5.9.0+0-1.cdh5.9.0.p0.11.el6.x86_64.rpm&lt;br&gt;impala-kudu-shell-2.7.0+cdh5.9.0+0-1.cdh5.9.0.p0.11.el6.x86_64.rpm&lt;br&gt;impala-kudu-udf-devel-2.7.0+cdh5.9.0+0-1.cdh5.9.0.p0.11.el6.x86_64.rpm&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="impala" scheme="http://lzrlizhirong.github.io/categories/impala/"/>
    
    
      <category term="impala" scheme="http://lzrlizhirong.github.io/tags/impala/"/>
    
  </entry>
  
  <entry>
    <title>安装kudu</title>
    <link href="http://lzrlizhirong.github.io/2017/02/23/%E5%AE%89%E8%A3%85kudu/"/>
    <id>http://lzrlizhirong.github.io/2017/02/23/安装kudu/</id>
    <published>2017-02-23T02:17:55.000Z</published>
    <updated>2017-02-23T08:40:56.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>1.默认安装好yum</strong><br><strong>2.需以root身份安装</strong><br><strong>3.安装ntp</strong><br>　　<code>yum install ntp -y</code><br><strong>4.启动ntp</strong><br>　　<code>/etc/init.d/ntpd start|stop|restart</code><br><a id="more"></a><br><strong>5.添加安装包yum源</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[cloudera-kudu]</div><div class="line"># Packages for Cloudera&apos;s Distribution for kudu, Version 0, on RedHat or CentOS 6 x86_64</div><div class="line">name=Cloudera&apos;s Distribution for kudu, Version 0</div><div class="line">baseurl=http://archive.cloudera.com/beta/kudu/redhat/6/x86_64/kudu/0/</div><div class="line">gpgkey=http://archive.cloudera.com/beta/kudu/redhat/6/x86_64/kudu/RPM-GPG-KEY-cloudera</div><div class="line">gpgcheck = 1</div></pre></td></tr></table></figure></p>
<p><strong>6.1安装kudu(yum 安装方式)</strong><br><code>yum install kudu kudu-master kudu-tserver kudu-client0 kudu-client-devel -y</code><br>其中子节点可以不用安装kudu-master<br><strong>6.2安装kudu(rpm安装方式)</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">rpm -ivh kudu-0.9.1+cdh5.4.0+0-1.kudu0.9.1.p0.32.el6.x86_64.rpm</div><div class="line">rpm -ivh kudu-master-0.9.1+cdh5.4.0+0-1.kudu0.9.1.p0.32.el6.x86_64.rpm</div><div class="line">rpm -ivh kudu-tserver-0.9.1+cdh5.4.0+0-1.kudu0.9.1.p0.32.el6.x86_64.rpm</div><div class="line">rpm -ivh kudu-client0-0.9.1+cdh5.4.0+0-1.kudu0.9.1.p0.32.el6.x86_64.rpm</div><div class="line">rpm -ivh kudu-client-devel-0.9.1+cdh5.4.0+0-1.kudu0.9.1.p0.32.el6.x86_64.rpm</div></pre></td></tr></table></figure></p>
<p><strong>7.配置参数(需要创建好相应目录)</strong><br>master:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">1./etc/default/kudu-master</div><div class="line">    export FLAGS_log_dir=/opt/kudu-0.9.1/log //日志目录</div><div class="line">    export FLAGS_rpc_bind_addresses=dsj01:7051</div><div class="line">2./etc/kudu/conf.dist/master.gflagfile</div><div class="line">    --fs_wal_dir=/opt/kudu-0.9.1/data/master</div><div class="line">    --fs_data_dirs=/opt/kudu-0.9.1/data/master</div><div class="line">    --default_num_replicas=1 //设置备份数 不设置默认为3</div></pre></td></tr></table></figure></p>
<p>tserver:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">1./etc/default/kudu-tserver</div><div class="line">    export FLAGS_log_dir=/opt/kudu-0.9.1/log</div><div class="line">    export FLAGS_rpc_bind_addresses=dsj02:7050</div><div class="line">2./etc/kudu/conf.dist/tserver.gflagfile</div><div class="line">    --fs_wal_dir=/opt/kudu-0.9.1/data/tserver</div><div class="line">    --fs_data_dirs=/opt/kudu-0.9.1/data/tserver</div><div class="line">    --tserver_master_addrs=dsj01:7051 //绑定master节点</div></pre></td></tr></table></figure></p>
<p><strong>8.启动kudu</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">service kudu-master start|stop</div><div class="line">service kudu-tserver start|stop</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;1.默认安装好yum&lt;/strong&gt;&lt;br&gt;&lt;strong&gt;2.需以root身份安装&lt;/strong&gt;&lt;br&gt;&lt;strong&gt;3.安装ntp&lt;/strong&gt;&lt;br&gt;　　&lt;code&gt;yum install ntp -y&lt;/code&gt;&lt;br&gt;&lt;strong&gt;4.启动ntp&lt;/strong&gt;&lt;br&gt;　　&lt;code&gt;/etc/init.d/ntpd start|stop|restart&lt;/code&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="数据库" scheme="http://lzrlizhirong.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="NoSQL" scheme="http://lzrlizhirong.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/NoSQL/"/>
    
    
      <category term="kudu" scheme="http://lzrlizhirong.github.io/tags/kudu/"/>
    
      <category term="NoSQL" scheme="http://lzrlizhirong.github.io/tags/NoSQL/"/>
    
  </entry>
  
  <entry>
    <title>flume+kafka+spark streaming整合</title>
    <link href="http://lzrlizhirong.github.io/2017/02/22/flume-kafka-spark-streaming%E6%95%B4%E5%90%88/"/>
    <id>http://lzrlizhirong.github.io/2017/02/22/flume-kafka-spark-streaming整合/</id>
    <published>2017-02-22T14:24:04.000Z</published>
    <updated>2017-02-23T08:47:48.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>1.安装好flume；</strong><br><strong>2.安装好kafka；</strong><br><strong>3.安装好spark；</strong><br><strong>4.流程说明:</strong><br><code>日志文件-&gt;flume-&gt;kafka-&gt;spark streaming</code><br>flume输入:文件<br>flume输出:kafka的输入<br>kafka输出:spark 输入<br><a id="more"></a><br><strong>5.整合步骤:</strong><br><strong>(1).将插件jar拷贝到flume的lib目录下</strong><br>a. flumeng-kafka-plugin.jar<br>b. metrics-annotation-2.2.0.jar</p>
<p><strong>(2).将配置文件producer.properties拷贝到flume的conf目录下</strong><br>配置文件内容如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">#agentsection</div><div class="line">producer.sources=s</div><div class="line">producer.channels=c</div><div class="line">producer.sinks=r</div><div class="line"></div><div class="line">#sourcesection</div><div class="line">producer.sources.s.type=exec</div><div class="line">producer.sources.s.command=tail -f -n+1 /opt/apache-flume-1.6.0/data/testFlumeKafka.txt</div><div class="line">producer.sources.s.channels=c</div><div class="line"></div><div class="line"># Eachsink&apos;s type must be defined</div><div class="line">producer.sinks.r.type=org.apache.flume.plugins.KafkaSink</div><div class="line">producer.sinks.r.metadata.broker.list=namenode:19092,datanode1:19092,datanode2:19092</div><div class="line">producer.sinks.r.partition.key=0</div><div class="line">　　　　　　producer.sinks.r.partitioner.class=org.apache.flume.plugins.SinglePartition</div><div class="line">producer.sinks.r.serializer.class=kafka.serializer.StringEncoder</div><div class="line">producer.sinks.r.request.required.acks=0</div><div class="line">producer.sinks.r.max.message.size=1000000</div><div class="line">producer.sinks.r.producer.type=sync</div><div class="line">producer.sinks.r.custom.encoding=UTF-8</div><div class="line">producer.sinks.r.custom.topic.name=test //需建好对应topic</div><div class="line"></div><div class="line">#Specifythe channel the sink should use</div><div class="line">producer.sinks.r.channel=c</div><div class="line"></div><div class="line"># Eachchannel&apos;s type is defined.</div><div class="line">producer.channels.c.type=memory</div><div class="line">producer.channels.c.capacity=1000</div><div class="line">producer.channels.c.transactionCapacity=100</div></pre></td></tr></table></figure></p>
<p><strong>(3).启动flume-ng</strong><br><code>flume-ng agent -c . -f /opt/apache-flume-1.6.0/conf/producer.conf -n producer</code></p>
<p><strong>(4).启动kafka-server</strong><br><code>bin/kafka-server-start.sh config/server.properties</code></p>
<p><strong>(5).启动kafka-consumer(默认已经创建了test topic)</strong><br><code>bin/kafka-console-consumer.sh --zookeeper namenode:12181,datanode1:12181,datanode2:12181 --topic test --from-beginning</code></p>
<p><strong>(6).启动spark</strong><br><code>sbin/start-all.sh</code></p>
<p><strong>(7).运行spark streaming Demo</strong><br><code>run-example org.apache.spark.examples.streaming.JavaKafkaWordCount namenode:12181 test-consumer-group test 3 &gt;&gt; test.log</code></p>
<p><strong>(8).在对应的日志文件中输入内容,则可以在test.log文件看到单词计数的结果</strong></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;1.安装好flume；&lt;/strong&gt;&lt;br&gt;&lt;strong&gt;2.安装好kafka；&lt;/strong&gt;&lt;br&gt;&lt;strong&gt;3.安装好spark；&lt;/strong&gt;&lt;br&gt;&lt;strong&gt;4.流程说明:&lt;/strong&gt;&lt;br&gt;&lt;code&gt;日志文件-&amp;gt;flume-&amp;gt;kafka-&amp;gt;spark streaming&lt;/code&gt;&lt;br&gt;flume输入:文件&lt;br&gt;flume输出:kafka的输入&lt;br&gt;kafka输出:spark 输入&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="大数据" scheme="http://lzrlizhirong.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="flume" scheme="http://lzrlizhirong.github.io/tags/flume/"/>
    
      <category term="kafka" scheme="http://lzrlizhirong.github.io/tags/kafka/"/>
    
      <category term="spark streaming" scheme="http://lzrlizhirong.github.io/tags/spark-streaming/"/>
    
  </entry>
  
  <entry>
    <title>经验贴--kudu在小米的实践应用</title>
    <link href="http://lzrlizhirong.github.io/2017/02/22/%E7%BB%8F%E9%AA%8C%E8%B4%B4-kudu%E5%9C%A8%E5%B0%8F%E7%B1%B3%E7%9A%84%E5%AE%9E%E8%B7%B5%E5%BA%94%E7%94%A8/"/>
    <id>http://lzrlizhirong.github.io/2017/02/22/经验贴-kudu在小米的实践应用/</id>
    <published>2017-02-22T10:06:45.000Z</published>
    <updated>2017-02-22T10:24:27.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-前言"><a href="#1-前言" class="headerlink" title="1.前言"></a>1.前言</h1><p>本文是小米工程师常冰琳于2016年10月25日晚10点在“大数据产业联合会”微信群分享的内容，整理分享给大家。</p>
<h1 id="2-小米使用kudu的背景"><a href="#2-小米使用kudu的背景" class="headerlink" title="2.小米使用kudu的背景"></a>2.小米使用kudu的背景</h1><p>小米大概在14年中开始和cloudera合作，作为kudu小白鼠用户，帮cloudera在生产环境验证kudu。kudu+Impala可以帮助我们解决实时数据的ad-hoc查询需求。<br><a id="more"></a><br>在kudu之前，我们的大数据分析pipeline大概是有这几种：</p>
<blockquote>
<ol>
<li>数据源-&gt; scribe打日志到HDFS -&gt; MR/Hive/Spark -&gt; HDFS Parquet -&gt; Impala -&gt; 结果service<br>这个数据流一般用来分析各种日志。</li>
<li>数据源 -&gt; 实时更新HBase/Mysql -&gt; 每天批量导出Parquet-&gt; Impala -&gt; 结果serve<br>这个数据流一般用来分析状态数据，也就是一般需要随机更新的数据，比如用户profile之类。</li>
</ol>
</blockquote>
<p>这两条数据流主要由几个问题：</p>
<blockquote>
<ol>
<li>数据从生成到能够被高效查询的列存储，整个数据流延迟比较大，一般是小时级别到一天；</li>
<li>很多数据的日志到达时间和逻辑时间是不一致的，一般存在一些随机延迟。</li>
</ol>
</blockquote>
<p>比如很多mobile app统计应用，这些tracing event发生后，很可能过一段时间才被后端tracing server收集到。</p>
<p>我们经常看到一些hive查询，分析一天或者一小时的数据，但是要读2-3天或者多个小时的日志，然后过滤出实际想要的记录。</p>
<p>对于一些实时分析需求，有一些可以通过流处理来解决，不过他肯定没用SQL方便，另外流式处理只能做固定的数据分析，对ad-hoc查询无能为力</p>
<p>kudu的特点正好可以来配合impala搭建实时ad-hoc分析应用。</p>
<p>改进后的数据流大概是这个样子：</p>
<blockquote>
<ol>
<li>数据源 -&gt; kafka -&gt; ETL(Storm) -&gt; kudu -&gt; Impala</li>
<li>数据源 -&gt; kudu -&gt; Impala</li>
</ol>
</blockquote>
<p>数据流1 主要是为需要进一步做ETL的应用使用的，另外kafka可以当做一个buffer，当写吞吐有毛刺时，kafka可以做一个缓冲。</p>
<p>如果应用有严格的实时需求，就是只要数据源写入就必须能够查到，就需要使用数据流2。</p>
<h1 id="3-引入kudu的目的"><a href="#3-引入kudu的目的" class="headerlink" title="3.引入kudu的目的"></a>3.引入kudu的目的</h1><p>引入kudu主要是用来替换 HDFS+parquet的。</p>
<h1 id="4-kudu的列存和parquet列存有啥区别？"><a href="#4-kudu的列存和parquet列存有啥区别？" class="headerlink" title="4.kudu的列存和parquet列存有啥区别？"></a>4.kudu的列存和parquet列存有啥区别？</h1><p>从功能上说，kudu的列存除了提供跟parquet接近的scan速度，还支持随机读写。支持随机写，数据就可以实时灌入存储中，达到实时查询的效果；但是parquet文件只能批量写，所以一般只能定期生成，所以增大了延迟。kudu的存储类似hbase的lsm存储。</p>
<h1 id="5-为什么说kudu的scan会比kylin快呢"><a href="#5-为什么说kudu的scan会比kylin快呢" class="headerlink" title="5.为什么说kudu的scan会比kylin快呢"></a>5.为什么说kudu的scan会比kylin快呢</h1><p>kylin是存储在hbase上的，kudu的scan为什么比hbase快，简单的说kudu是真正的列存储，hbase只是列簇存储。kudu是有schema的，每一列的数据是在文件中已数组的形式保存的，而hbase存储在hfile里面的还是sort好的(rowkey, column, timestamp, value)对，scan是开销要多很多，具体需要看kudu的paper了，在这里文字不好解释。</p>
<h1 id="6-storm-写kudu的吞吐量能到多少，和storm写hbase比呢"><a href="#6-storm-写kudu的吞吐量能到多少，和storm写hbase比呢" class="headerlink" title="6.storm 写kudu的吞吐量能到多少，和storm写hbase比呢"></a>6.storm 写kudu的吞吐量能到多少，和storm写hbase比呢</h1><p>我们在71个节点的集群做了测试，随机写性能：随机写26亿条记录：每个节点大概4W 随机写性能。</p>
<p>大概的情况如下：</p>
<blockquote>
<p><strong>71 Node cluster</strong><br><strong><em>Hardware</em></strong><br>CPU: E5-2620 2.1GHz <em> 24 core  Memory: 64GB<br>Network: 1Gb  Disk: 12 HDD<br><strong><em>Software</em></strong><br>Hadoop2.6/Impala 2.1/Kudu<br><em>*<em>3个大表，其中一个大表每天：</em></em></em><br>~2.6 Billion rows<br>~270 bytes/row<br>17 columns, 5 key columns</p>
</blockquote>
<p>storm到kudu，按照每天26亿数据来算，每秒大概30000条记录吧。<br><img src="/2017/02/22/经验贴-kudu在小米的实践应用/../../../../images/kdm1.jpeg" alt=""><br>这个是我们的应用挑出的6个查询，做的查询性能对比。同样6个查询，查询parquet和查询kudu做的对比。当时kudu的设计目标是接近parquet的scan性能，惊喜的是，目前kudu的scan性能在生产环境下有时还比parquet快一些。</p>
<h1 id="7-像hbase有coprocessor，kudu有类似的计算功能吗？"><a href="#7-像hbase有coprocessor，kudu有类似的计算功能吗？" class="headerlink" title="7.像hbase有coprocessor，kudu有类似的计算功能吗？"></a>7.像hbase有coprocessor，kudu有类似的计算功能吗？</h1><p>kudud。kudu有predicatepushdown，目前有impala使用时，scan时是把一些过滤提交给kudu去做的。</p>
<h1 id="8-你们是想用kudu替换hbase还是一起搭配用？"><a href="#8-你们是想用kudu替换hbase还是一起搭配用？" class="headerlink" title="8.你们是想用kudu替换hbase还是一起搭配用？"></a>8.你们是想用kudu替换hbase还是一起搭配用？</h1><p>感觉这两个工具目前用来解决不同的问题，hbase还是用来做OLTP类存储跟Mysql类似，kudu则用来升级我们现有的数据分析数据流，主要还是OLAP的workload。</p>
<h1 id="9-Kudu支持随机增加列吗？"><a href="#9-Kudu支持随机增加列吗？" class="headerlink" title="9.Kudu支持随机增加列吗？"></a>9.Kudu支持随机增加列吗？</h1><p>只要不是primarykey的列，是可以随时增加的，而且不像mysql增加列时影响其他操作，kudu altertable是异步的，而且对性能影响不大。hbase是无schema的，所以可以成千上万个列，kudu不行的，列的数量也不能过多。我们目前也就试过30多列的，一些300+列的表还没有测试过。</p>
<h1 id="10-Kudu目前有稳定版吗"><a href="#10-Kudu目前有稳定版吗" class="headerlink" title="10.Kudu目前有稳定版吗"></a>10.Kudu目前有稳定版吗</h1><p>目前beta版本，不推荐现在在生产环境使用。(写此篇博客时(2017.2.22)已发布1.2.0版本)<br><img src="/2017/02/22/经验贴-kudu在小米的实践应用/../../../../images/kdm2.png" alt=""></p>
<h1 id="11-能否介绍一下小米使用kudu过程中踩过的坑？"><a href="#11-能否介绍一下小米使用kudu过程中踩过的坑？" class="headerlink" title="11.能否介绍一下小米使用kudu过程中踩过的坑？"></a>11.能否介绍一下小米使用kudu过程中踩过的坑？</h1><p>目前踩的坑都还在开发阶段，其实都不算什么，而且从大方向上看，我们还是相信kudu这种方式对比之前的数据流优势很明显，对吞吐不是非常高的应用，这种方案是发展方向。其实我们在老的数据流上碰到很多问题，之前提到的数据延迟，数据无序，多个组件之间的兼容性，数据无schema导致灌入数据时缺少验证，其实都希望引入kudu后能够解决。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-前言&quot;&gt;&lt;a href=&quot;#1-前言&quot; class=&quot;headerlink&quot; title=&quot;1.前言&quot;&gt;&lt;/a&gt;1.前言&lt;/h1&gt;&lt;p&gt;本文是小米工程师常冰琳于2016年10月25日晚10点在“大数据产业联合会”微信群分享的内容，整理分享给大家。&lt;/p&gt;
&lt;h1 id=&quot;2-小米使用kudu的背景&quot;&gt;&lt;a href=&quot;#2-小米使用kudu的背景&quot; class=&quot;headerlink&quot; title=&quot;2.小米使用kudu的背景&quot;&gt;&lt;/a&gt;2.小米使用kudu的背景&lt;/h1&gt;&lt;p&gt;小米大概在14年中开始和cloudera合作，作为kudu小白鼠用户，帮cloudera在生产环境验证kudu。kudu+Impala可以帮助我们解决实时数据的ad-hoc查询需求。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="数据库" scheme="http://lzrlizhirong.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="NoSQL" scheme="http://lzrlizhirong.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/NoSQL/"/>
    
    
      <category term="kudu" scheme="http://lzrlizhirong.github.io/tags/kudu/"/>
    
      <category term="NoSQL" scheme="http://lzrlizhirong.github.io/tags/NoSQL/"/>
    
  </entry>
  
  <entry>
    <title>kudu学习资料总结</title>
    <link href="http://lzrlizhirong.github.io/2017/02/22/kudu%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99%E6%80%BB%E7%BB%93/"/>
    <id>http://lzrlizhirong.github.io/2017/02/22/kudu学习资料总结/</id>
    <published>2017-02-22T08:39:34.000Z</published>
    <updated>2017-02-22T09:51:05.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-kudu是什么-为什么要用kudu？"><a href="#1-kudu是什么-为什么要用kudu？" class="headerlink" title="1.kudu是什么,为什么要用kudu？"></a>1.kudu是什么,为什么要用kudu？</h1><p>Kudu是Todd Lipcon@Cloudera带头开发的存储系统，其整体应用模式和Hbase比较接近，即支持行级别的随机读写，并支持批量顺序检索功能。</p>
<p>Hadoop 生态系统发展到现在，存储层主要由HDFS和HBase两个系统把持着，一直没有太大突破。在追求高吞吐的批处理场景下，我们选用HDFS，在追求低延迟，有随机读写需求的场景下，我们选用HBase，那么是否存在一种系统，能结合两个系统优点，同时支持高吞吐率和低延迟呢？有人尝试修改HBase内核构造这样的系统，即保留HBase的数据模型，而将其底层存储部分改为纯列式存储（目前HBase只能算是列簇式存储引擎），但这种修改难度较大。 Kudu的出现解决这一难题。<br><a id="more"></a></p>
<p>Kudu是Cloudera开源的列式存储引擎，具有以下几个特点优势：</p>
<ul>
<li>C++语言开发</li>
<li>高效处理类OLAP负载</li>
<li>与MapReduce，Spark以及Hadoop生态系统中其他组件进行友好集成</li>
<li>可与Cloudera Impala集成，替代目前Impala常用的HDFS+Parquet组合</li>
<li>强大而灵活的一致性模型，让你选择在每个请求的基础上一致性的要求，包括严格的序列化的一致性选择</li>
<li>顺序写和随机写并存的场景下，仍能达到良好的性能</li>
<li>高可用，使用Raft协议保证数据高可靠存储，只要确保只要一半以上的副本总数可用</li>
<li>结构化数据模型</li>
<li>易于管理，Cloudera管理</li>
</ul>
<p>Kudu的出现，有望解决目前Hadoop生态系统难以解决的一大类问题，比如：</p>
<ul>
<li>流式实时计算结果的更新</li>
<li>时间序列相关应用，具体要求有：<ul>
<li>查询海量历史数据</li>
<li>查询个体数据，并要求快速返回</li>
<li>预测模型中，周期性更新模型，并根据历史数据快速做出决策</li>
</ul>
</li>
</ul>
<p>Kudu架构如下图所示：<br><img src="/2017/02/22/kudu学习资料总结/../../../../images/kd1.jpeg" alt=""></p>
<h1 id="2-kudu-的基本架构"><a href="#2-kudu-的基本架构" class="headerlink" title="2.kudu 的基本架构"></a>2.kudu 的基本架构</h1><h2 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h2><p>数据模型定义上，Kudu管理的是类似关系型数据库的结构化的表，表结构由类Sql的Schema进行定义，相比于HBase这样的NoSql类型的数据库，Kudu的行数据是由固定个数有明确类型定义的列组成，并且需要定义一个由一个或多个列组成的主键来对每行数据进行唯一索引，相比于传统的关系型数据库，kudu在索引上有更多的限制，比如暂时不支持二级索引，不支持主键的更新等等。</p>
<p>尽管表结构类似于关系型数据库，但是Kudu自身并不提供SQL类型的语法接口，而是由上层其他系统实现，比如目前通过Impala提供SQL语法支持。</p>
<p>Kudu底层API，主要面对简单的更新检索操作，Insert／Update／Delete等必须指定一个主键进行，而Scan检索类型的操作则支持条件过滤和投影等能力。</p>
<h2 id="集群架构"><a href="#集群架构" class="headerlink" title="集群架构"></a>集群架构</h2><p>Kudu的集群架构基本和HBase类似，采用主从结构，Master节点管理元数据，Tablet节点负责分片管理数据。</p>
<p>和HBase不同的是，Kudu没有借助于HDFS存储实际数据，而是自己直接在本地磁盘上管理分片数据，包括数据的Replication机制，kudu的Tablet server直接管理Master分片和Slave分片，自己通过raft协议解决一致性问题等，多个Slave可以同时提供数据读取服务，相对于HBase依托HDFS进行Region数据的管理方式，自主性会强一些，不过比如Tablet节点崩溃，数据的迁移拷贝工作等，也需要Kudu自己完成。</p>
<h2 id="存储结构"><a href="#存储结构" class="headerlink" title="存储结构"></a>存储结构</h2><p>因为数据是有严格Schema类型定义，所以Kudu底层可以使用列式存储的方案来提高存储和投影检索效率。</p>
<p>和HBase一样，Kudu也是通过Tablet的分区来支持水平扩展，与HBase不同的是，Kudu的分区策略除了支持按照Key Range来分区以外，还支持Hash based的策略，实际上，在主键上，Kudu可以混合使用这两种不同的策略。</p>
<p>Hash分区的策略在一些场合下可以更好的做到负载均衡，避免数据倾斜，但是它最大的问题就是分区数一旦确定就很难再调整，所以目前Kudu的分区数必须预先指定（对Range的分区策略也有这个要求，估计是先简单化统一处理），不支持动态分区分裂，合并等，因此表的分区一开始就需要根据负载和容量预先进行合理规划。</p>
<p>在处理随机写的效率问题方面，Kudu的基本流程和HBase的方案差不多，在内存中对每个Tablet分区维护一个MemRowSet来管理最新更新的数据，当尺寸超过一定大小后Flush到磁盘上形成DiskRowSet，多个DiskRowSet在适当的时候进行归并处理。</p>
<p>和HBase采用的LSM（LogStructured Merge）方案不同的是，Kudu对同一行的数据更新记录的合并工作，不是在查询的时候发生的（HBase会将多条更新记录先后Flush到不同的Storefile中，所以读取时需要扫描多个文件，比较rowkey，比较版本等），而是在更新的时候进行，在Kudu中一行数据只会存在于一个DiskRowSet中，避免读操作时的比较合并工作。那Kudu是怎么做到的呢？ 对于列式存储的数据文件，要原地变更一行数据是很困难的，所以在Kudu中，对于Flush到磁盘上的DiskRowSet（DRS）数据，实际上是分两种形式存在的，一种是Base的数据，按列式存储格式存在，一旦生成，就不再修改，另一种是Delta文件，存储Base数据中有变更的数据，一个Base文件可以对应多个Delta文件，这种方式意味着，插入数据时相比HBase，需要额外走一次检索流程来判定对应主键的数据是否已经存在。因此，Kudu是牺牲了写性能来换取读取性能的提升。<br><img src="/2017/02/22/kudu学习资料总结/../../../../images/kd2.png" alt=""><br>既然存在Delta数据，也就意味着数据查询时需要同时检索Base文件和Delta文件，这看起来和HBase的方案似乎又走到一起去了，不同的地方在于，Kudu的Delta文件与Base文件不同，不是按Key排序的，而是按被更新的行在Base文件中的位移来检索的，号称这样做，在定位Delta内容的时候，不需要进行字符串比较工作，因此能大大加快定位速度。但是无论如何，Delta文件的存在对检索速度的影响巨大。因此Delta文件的数量会需要控制，需要及时的和Base数据进行合并。由于Base文件是列式存储的，所以Delta文件合并时，可以有选择性的进行，比如只把变化频繁的列进行合并，变化很少的列保留在Delta文件中暂不合并，这样做也能减少不必要的IO开销。</p>
<p>除了Delta文件合并，DRS自身也会需要合并，为了保障检索延迟的可预测性（这一点是HBase的痛点之一，比如分区发生Major Compaction时，读写性能会受到很大影响），Kudu的compaction策略和HBase相比，有很大不同，kudu的DRS数据文件的compaction，本质上不是为了减少文件数量，实际上Kudu DRS默认是以32MB为单位进行拆分的，DRS的compaction并不减少文件数量，而是对内容进行排序重组，减少不同DRS之间key的overlap，进而在检索的时候减少需要参与检索的DRS的数量。<br><img src="/2017/02/22/kudu学习资料总结/../../../../images/kd3.png" alt=""><br>以32MB这样小的单位进行拆分，也是为了能够以有限的资源快速的完成compaction的任务，及时根据系统负载调整Compaction行为，而不至于像HBase一样，Major Compaction动作成为导致性能不稳定的一个重要因素。所以对于Kudu来说，IO操作可以是一个持续平缓的过程，这点对响应的可预测性至关重要。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>总体来说，个人感觉，Kudu本质上是将性能的优化，寄托在以列式存储为核心的基础上，希望通过提高存储效率，加快字段投影过滤效率，降低查询时CPU开销等来提升性能。而其他绝大多数设计，都是为了解决在列式存储的基础上支持随机读写这样一个目的而存在的。比如类Sql的元数据结构，是提高列式存储效率的一个辅助手段，唯一主键的设定也是配合列式存储引入的定制策略，至于其他如Delta存储，compaction策略等都是在这个设定下为了支持随机读写，降低latency不确定性等引入的一些Tradeoff方案</p>
<p>官方测试结果上，如果是存粹的随机读写，或者单行的检索请求这类场景，由于这些Tradeoff的存在，HBASE的性能吞吐率是要优于Kudu不少的（2倍到4倍），kudu的优势还是在支持类SQL检索这样经常需要进行投影操作的批量顺序检索分析场合。</p>
<p>目前kudu还处在Incubator阶段，并且还没有成熟的线上应用（小米走在了前面，做了一些业务应用的尝试），在数据安全，备份，系统健壮性等方面也还要打个问号，所以是否使用kudu，什么场合，什么时间点使用，是个需要好好考量的问题。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-kudu是什么-为什么要用kudu？&quot;&gt;&lt;a href=&quot;#1-kudu是什么-为什么要用kudu？&quot; class=&quot;headerlink&quot; title=&quot;1.kudu是什么,为什么要用kudu？&quot;&gt;&lt;/a&gt;1.kudu是什么,为什么要用kudu？&lt;/h1&gt;&lt;p&gt;Kudu是Todd Lipcon@Cloudera带头开发的存储系统，其整体应用模式和Hbase比较接近，即支持行级别的随机读写，并支持批量顺序检索功能。&lt;/p&gt;
&lt;p&gt;Hadoop 生态系统发展到现在，存储层主要由HDFS和HBase两个系统把持着，一直没有太大突破。在追求高吞吐的批处理场景下，我们选用HDFS，在追求低延迟，有随机读写需求的场景下，我们选用HBase，那么是否存在一种系统，能结合两个系统优点，同时支持高吞吐率和低延迟呢？有人尝试修改HBase内核构造这样的系统，即保留HBase的数据模型，而将其底层存储部分改为纯列式存储（目前HBase只能算是列簇式存储引擎），但这种修改难度较大。 Kudu的出现解决这一难题。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="数据库" scheme="http://lzrlizhirong.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="NoSQL" scheme="http://lzrlizhirong.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/NoSQL/"/>
    
    
      <category term="kudu" scheme="http://lzrlizhirong.github.io/tags/kudu/"/>
    
      <category term="NoSQL" scheme="http://lzrlizhirong.github.io/tags/NoSQL/"/>
    
  </entry>
  
  <entry>
    <title>三识SpringBoot微框架--启动器Starter详解</title>
    <link href="http://lzrlizhirong.github.io/2017/02/22/%E4%B8%89%E8%AF%86SpringBoot%E5%BE%AE%E6%A1%86%E6%9E%B6-%E5%90%AF%E5%8A%A8%E5%99%A8Starter%E8%AF%A6%E8%A7%A3/"/>
    <id>http://lzrlizhirong.github.io/2017/02/22/三识SpringBoot微框架-启动器Starter详解/</id>
    <published>2017-02-22T02:44:39.000Z</published>
    <updated>2017-02-22T03:15:59.000Z</updated>
    
    <content type="html"><![CDATA[<p>spring boot 配置时需要在pom文件中添加starter模块，那么starter是什么？有什么作用？分为哪几种？下面将进行详细讲解：</p>
<p>starter模块，简单的说，就是一系列的依赖包组合。例如web starter模块，就是包含了Spring Boot预定义的一些Web开发的常用依赖，如：</p>
<ul>
<li>spring-web, spring-webmvc         即Spring WebMvc框架</li>
<li>tomcat-embed-*            即内嵌Tomcat容器</li>
<li>jackson           即处理json数据</li>
<li>spring-*          即Spring框架</li>
<li>spring-boot-autoconfigure         即Spring Boot提供的自动配置功能</li>
</ul>
<p>换句话说，当你添加了相应的starter模块，就相当于添加了相应的所有必须的依赖包。<br>注：可以在引入对应的starter启动器后使用 mvn dependency:tree 查看引入的依赖关系。<br>如下图所示：<br><a id="more"></a><br><img src="/2017/02/22/三识SpringBoot微框架-启动器Starter详解/../../../../images/g112.png" alt=""></p>
<h1 id="spring-Boot应用启动器基本的一共有44种，具体如下："><a href="#spring-Boot应用启动器基本的一共有44种，具体如下：" class="headerlink" title="spring Boot应用启动器基本的一共有44种，具体如下："></a>spring Boot应用启动器基本的一共有44种，具体如下：</h1><p><strong>1）spring-boot-starter</strong><br>这是Spring Boot的核心启动器，包含了自动配置、日志和YAML。</p>
<p><strong>2）spring-boot-starter-actuator</strong><br>帮助监控和管理应用。</p>
<p><strong>3）spring-boot-starter-amqp</strong><br>通过spring-rabbit来支持AMQP协议（Advanced Message Queuing Protocol）。</p>
<p><strong>4）spring-boot-starter-aop</strong><br>支持面向切面的编程即AOP，包括spring-aop和AspectJ。</p>
<p><strong>5）spring-boot-starter-artemis</strong><br>通过Apache Artemis支持JMS的API（Java Message Service API）。</p>
<p><strong>6）spring-boot-starter-batch</strong><br>支持Spring Batch，包括HSQLDB数据库。</p>
<p><strong>7）spring-boot-starter-cache</strong><br>支持Spring的Cache抽象。</p>
<p><strong>8）spring-boot-starter-cloud-connectors</strong><br>支持Spring Cloud Connectors，简化了在像Cloud Foundry或Heroku这样的云平台上连接服务。</p>
<p><strong>9）spring-boot-starter-data-elasticsearch</strong><br>支持ElasticSearch搜索和分析引擎，包括spring-data-elasticsearch。</p>
<p><strong>10）spring-boot-starter-data-gemfire</strong><br>支持GemFire分布式数据存储，包括spring-data-gemfire。</p>
<p><strong>11）spring-boot-starter-data-jpa</strong><br>支持JPA（Java Persistence API），包括spring-data-jpa、spring-orm、hibernate。</p>
<p><strong>12）spring-boot-starter-data-MongoDB</strong><br>支持MongoDB数据，包括spring-data-mongodb。</p>
<p><strong>13）spring-boot-starter-data-rest</strong><br>通过spring-data-rest-webmvc，支持通过REST暴露Spring Data数据仓库。</p>
<p><strong>14）spring-boot-starter-data-solr</strong><br>支持Apache Solr搜索平台，包括spring-data-solr。</p>
<p><strong>15）spring-boot-starter-freemarker</strong><br>支持FreeMarker模板引擎。</p>
<p><strong>16）spring-boot-starter-groovy-templates</strong><br>支持Groovy模板引擎。</p>
<p><strong>17）spring-boot-starter-hateoas</strong><br>通过spring-hateoas支持基于HATEOAS的RESTful Web服务。</p>
<p><strong>18）spring-boot-starter-hornetq</strong><br>通过HornetQ支持JMS。</p>
<p><strong>19）spring-boot-starter-integration</strong><br>支持通用的spring-integration模块。</p>
<p><strong>20）spring-boot-starter-jdbc</strong><br>支持JDBC数据库。</p>
<p><strong>21）spring-boot-starter-jersey</strong><br>支持Jersey RESTful Web服务框架。</p>
<p><strong>22）spring-boot-starter-jta-atomikos</strong><br>通过Atomikos支持JTA分布式事务处理。</p>
<p><strong>23）spring-boot-starter-jta-bitronix</strong><br>通过Bitronix支持JTA分布式事务处理。</p>
<p><strong>24）spring-boot-starter-mail</strong><br>支持javax.mail模块。</p>
<p><strong>25）spring-boot-starter-mobile</strong><br>支持spring-mobile。</p>
<p><strong>26）spring-boot-starter-mustache</strong><br>支持Mustache模板引擎。</p>
<p><strong>27）spring-boot-starter-Redis</strong><br>支持Redis键值存储数据库，包括spring-redis。</p>
<p><strong>28）spring-boot-starter-security</strong><br>支持spring-security。</p>
<p><strong>29）spring-boot-starter-social-facebook</strong><br>支持spring-social-facebook</p>
<p><strong>30）spring-boot-starter-social-linkedin</strong><br>支持pring-social-linkedin</p>
<p><strong>31）spring-boot-starter-social-twitter</strong><br>支持pring-social-twitter</p>
<p><strong>32）spring-boot-starter-test</strong><br>支持常规的测试依赖，包括JUnit、Hamcrest、Mockito以及spring-test模块。</p>
<p><strong>33）spring-boot-starter-thymeleaf</strong><br>支持Thymeleaf模板引擎，包括与Spring的集成。</p>
<p><strong>34）spring-boot-starter-velocity</strong><br>支持Velocity模板引擎。</p>
<p><strong>35）spring-boot-starter-web</strong><br>支持全栈式Web开发，包括Tomcat和spring-webmvc。</p>
<p><strong>36）spring-boot-starter-websocket</strong><br>支持WebSocket开发。</p>
<p><strong>37）spring-boot-starter-ws</strong><br>支持Spring Web Services。</p>
<p><strong>Spring Boot应用启动器面向生产环境的还有2种，具体如下：</strong></p>
<p><strong>1）spring-boot-starter-actuator</strong><br>增加了面向产品上线相关的功能，比如测量和监控。</p>
<p><strong>2）spring-boot-starter-remote-shell</strong><br>增加了远程ssh shell的支持。</p>
<p><strong>最后，Spring Boot应用启动器还有一些替换技术的启动器，具体如下：</strong></p>
<p><strong>1）spring-boot-starter-jetty</strong><br>引入了Jetty HTTP引擎（用于替换Tomcat）。</p>
<p><strong>2）spring-boot-starter-log4j</strong><br>支持Log4J日志框架。</p>
<p><strong>3）spring-boot-starter-logging
</strong>引入了Spring Boot默认的日志框架Logback。</p>
<p><strong>4）spring-boot-starter-tomcat</strong><br>引入了Spring Boot默认的HTTP引擎Tomcat。</p>
<p><strong>5）spring-boot-starter-undertow</strong><br>引入了Undertow HTTP引擎（用于替换Tomcat）。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;spring boot 配置时需要在pom文件中添加starter模块，那么starter是什么？有什么作用？分为哪几种？下面将进行详细讲解：&lt;/p&gt;
&lt;p&gt;starter模块，简单的说，就是一系列的依赖包组合。例如web starter模块，就是包含了Spring Boot预定义的一些Web开发的常用依赖，如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;spring-web, spring-webmvc         即Spring WebMvc框架&lt;/li&gt;
&lt;li&gt;tomcat-embed-*            即内嵌Tomcat容器&lt;/li&gt;
&lt;li&gt;jackson           即处理json数据&lt;/li&gt;
&lt;li&gt;spring-*          即Spring框架&lt;/li&gt;
&lt;li&gt;spring-boot-autoconfigure         即Spring Boot提供的自动配置功能&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;换句话说，当你添加了相应的starter模块，就相当于添加了相应的所有必须的依赖包。&lt;br&gt;注：可以在引入对应的starter启动器后使用 mvn dependency:tree 查看引入的依赖关系。&lt;br&gt;如下图所示：&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="SpringBoot" scheme="http://lzrlizhirong.github.io/categories/SpringBoot/"/>
    
    
      <category term="SpringBoot" scheme="http://lzrlizhirong.github.io/tags/SpringBoot/"/>
    
      <category term="微服务" scheme="http://lzrlizhirong.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>本地新项目同步到github的详细步骤</title>
    <link href="http://lzrlizhirong.github.io/2017/02/21/%E6%9C%AC%E5%9C%B0%E6%96%B0%E9%A1%B9%E7%9B%AE%E5%90%8C%E6%AD%A5%E5%88%B0github%E7%9A%84%E8%AF%A6%E7%BB%86%E6%AD%A5%E9%AA%A4/"/>
    <id>http://lzrlizhirong.github.io/2017/02/21/本地新项目同步到github的详细步骤/</id>
    <published>2017-02-21T03:42:07.000Z</published>
    <updated>2017-02-22T02:29:33.000Z</updated>
    
    <content type="html"><![CDATA[<p>说明：本地项目分为两种情况：</p>
<ol>
<li>自己本地创建的项目，从未与github产生关联；</li>
<li>从github上clone到本地的；</li>
</ol>
<p>若是第1种情况，直接按下面的步骤操作即可；<br>若是第2种情况，又分两种情况：<br><a id="more"></a></p>
<ol>
<li>若想要保留之前的commit记录，可直接修改项目根目录下的.git/config 文件，将下图中的url改为自己的github仓库地址即可，然后直接 add、commit、push 即可；<br><img src="/2017/02/21/本地新项目同步到github的详细步骤/../../../../images/g111.png" alt=""></li>
<li>若不想保留之前的commit记录，首先要把本地项目根目录下的 .git 文件夹删掉，然后再按下面的步骤操作。</li>
</ol>
<h1 id="1-初始化项目"><a href="#1-初始化项目" class="headerlink" title="1.初始化项目"></a>1.初始化项目</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git init</div></pre></td></tr></table></figure>
<p>初始化之后会生成新的 .git 文件</p>
<h1 id="2-将代码add到本地库中"><a href="#2-将代码add到本地库中" class="headerlink" title="2.将代码add到本地库中"></a>2.将代码add到本地库中</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">git add .</div><div class="line">git commit -m &quot;初始化项目&quot;</div></pre></td></tr></table></figure>
<h1 id="3-创建github上的仓库，并与本地项目关联起来"><a href="#3-创建github上的仓库，并与本地项目关联起来" class="headerlink" title="3.创建github上的仓库，并与本地项目关联起来"></a>3.创建github上的仓库，并与本地项目关联起来</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">git remote rm origin</div><div class="line">git remote add origin https://github.com/lzrlizhirong/cmdb.git</div><div class="line">git push -u origin master</div></pre></td></tr></table></figure>
<p>然后在github上就可以看到同步上去的代码了</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;说明：本地项目分为两种情况：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;自己本地创建的项目，从未与github产生关联；&lt;/li&gt;
&lt;li&gt;从github上clone到本地的；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;若是第1种情况，直接按下面的步骤操作即可；&lt;br&gt;若是第2种情况，又分两种情况：&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="工具" scheme="http://lzrlizhirong.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="git" scheme="http://lzrlizhirong.github.io/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>一步一步教你如何解锁iPhone</title>
    <link href="http://lzrlizhirong.github.io/2017/02/21/%E4%B8%80%E6%AD%A5%E4%B8%80%E6%AD%A5%E6%95%99%E4%BD%A0%E5%A6%82%E4%BD%95%E8%A7%A3%E9%94%81iPhone/"/>
    <id>http://lzrlizhirong.github.io/2017/02/21/一步一步教你如何解锁iPhone/</id>
    <published>2017-02-21T03:05:08.000Z</published>
    <updated>2017-02-21T03:17:47.000Z</updated>
    
    <content type="html"><![CDATA[<p>即使你的iPhone 6s设置了六位数的密码，甚至还设置了touch ID，但我要告诉你的是：你的手机仍然能被犯罪分子解锁。<br><a id="more"></a></p>
<h1 id="事件背景"><a href="#事件背景" class="headerlink" title="事件背景"></a>事件背景</h1><p>几天前，一位苹果用户的iPhone6S被偷了。随后，小偷重置了该用户某些在线服务密码以及Apple ID。</p>
<p>不仅如此，小偷还伪装成该用户与银行进行了联系，并试图重置该用户的银行账户密码。不过幸运的是，这个小偷并没有取出这些钱。</p>
<p>那么问题来了，犯罪分子是如何在手机锁屏的情况下重置AppleID密码的呢？</p>
<p>为了让大家更清楚地了解此次事件，我们收集整理了一些关于此次事件的信息，具体如下：</p>
<blockquote>
<p>a）这是不是一次针对性的攻击？我的意思是，小偷是不是通过网络钓鱼等诈骗手段盗取了受害者的信息，然后再专门偷走他的手机？<br>    这不太可能。根据我们收集到的信息，小偷在偷走受害者的手机之前没干任何事。<br>    b）在手机被盗之前，受害者其它的网络账户或个人信息被盗了吗？对于小偷来说，受害者的个人信息可是很重要的呢！<br>    然而，受害者的个人信息并没有被盗，小偷偷手机纯粹只是求财。<br>    c）小偷在盗得手机多久之后就解锁了iPhone和SIM卡？<br>    大概在手机被盗2个小时左右。<br>    d）iPhone的密码能猜出来吗？<br>    不太现实。六位数字密码并不是那么好猜的，而且受害者设置的密码与他的车牌号码或其它个人信息毫无关联。</p>
</blockquote>
<p>鉴于此次事件是如此的“不可思议”，我们决定对此进行深入分析，并让大家了解这部iPhone到底是如何被解锁的。</p>
<h1 id="事件脉络"><a href="#事件脉络" class="headerlink" title="事件脉络"></a>事件脉络</h1><p>该用户的iPhone6S是在10月14日下午被偷的，我们对此次事件的发展脉络进行了梳理，具体如下：</p>
<blockquote>
<p>a)14:00-手机被盗；<br>    b)16:03-受害者激活了手机的“丢失模式”，并通过iCloud远程清除了手机数据；<br>    c)16:28-受害者的Google账户密码被修改了；<br>    d)16:37-受害者收到了一封电子邮件，邮件中包含了重置Apple ID密码的链接；<br>    e)16:38-受害者收到了一封新邮件，这封邮件通知他，他的Apple ID密码已被修改；<br>    f)16:43-受害者再次收到邮件，被告知他手机已成功定位；<br>    g)16:43-受害者收到了最后一封邮件，被告知这台手机中的数据已被清除；</p>
</blockquote>
<p>正如我们所见，受害者的Google和Apple账户的密码都被小偷重置了。正如我们所知，在没有手机密码的情况下，要解锁这台iPhone是不太可能的。那么，小偷是如何做到的呢？</p>
<h1 id="以下是我们所做的一些假设"><a href="#以下是我们所做的一些假设" class="headerlink" title="以下是我们所做的一些假设"></a>以下是我们所做的一些假设</h1><p>1）<strong>如果你要更改Google账户的密码，首先你得要知道电子邮箱的地址。</strong>然而，犯罪分子是如何获得受害者的邮箱地址的呢？尽管手机在锁屏状态下收到的信息和通知会显示在手机屏幕上，但用户的Gmail邮箱地址并没有办法显示出来。</p>
<p>2）<strong>可以通过设备的IMEI码获取用户的Apple ID吗？</strong><br>我们在网上搜索了一下，确实发现了有些付费服务能够通过IMEI码获取Apple ID，但是得需要24-48小时才能获得你想要的信息。而犯罪分子只用了2个小时就将手机解锁了，由此可见，犯罪分子并不是通过设备的IMEI码获取到受害者的AppleID的。</p>
<p>3）<strong>犯罪分子仅根据手机号就能获取用户的Gmail邮箱账号吗？</strong><br>我们发现，只要有以下几个信息就能获取Gmail邮箱地址——与邮箱账号绑定的手机号码和用户的姓名。</p>
<p>既然手机偷到手了，手机号码自然也就知道了，通过手机号码获得用户的姓名也不是什么难事。因此，我们准备以此为切入点继续深入下去。</p>
<h1 id="情景还原"><a href="#情景还原" class="headerlink" title="情景还原"></a>情景还原</h1><p>我们决定根据上述方法找到用户姓名以验证我们的猜想。受害者为了搞清楚事情的来龙去脉也参与其中，还购买了一部新的iPhone6S，并且将新手机的设置调整成被盗手机一样。这样一来，受害者手机被盗的场景就能被最大化地还原了。</p>
<h2 id="获取关键信息"><a href="#获取关键信息" class="headerlink" title="获取关键信息"></a>获取关键信息</h2><p>为了获取手机号码，我们取出了iPhone中的SIM卡，然后把这张SIM卡插到了另一台手机中。与真实场景一样，SIM卡没有设置PIN码。所以，我们轻易地在另一台手机上获取了用户的手机号码。<br><img src="/2017/02/21/一步一步教你如何解锁iPhone/../../../../images/i1.jpeg" alt=""><br>接下来，我们将用户的号码放到网上搜索，试图获取用户的姓名，但是这个方法行不通。一定还有根据手机号码就能获取用户姓名的办法，于是我就想到了WhatsApp！</p>
<p>假如你在WhatsApp的一个群聊组中，并收到了陌生人的信息时，对方的名字和手机号就会显示在资料中（例如：9999-9999 ~MikeArnold）。所以，如果能用这个锁屏的iPhone向WhatsApp的聊天群发送一条信息，我们就能知道用户的姓名了。</p>
<p>首先，我们要确保在锁屏状态下，这台iPhone接收到的WhatsApp通知信息能在锁屏界面上显示。</p>
<p>于是我们向这台iPhone发了一条信息，这条信息果然显示在锁屏界面上了；下一步，我们需要在手机的锁屏状态下回复这条信息，只要使用3D touch功能就能实现这一步。</p>
<p>于是我们创建了一个聊天群，并把受害者手机号所绑定的WhatsApp账号加入到这个群里，由于进入新群不需要任何验证信息，所以我们便在锁屏界面上看到了这条进群的通知信息。此外，我们还在群里加了一些与受害者毫无关联的陌生人。</p>
<p>一切准备就绪，我们先在群里发了一条信息，这条信息也在锁屏界面上显示了；然后我们用3Dtouch功能回复了这条信息，果然不出所料，我们成功获取到了用户的姓名。<br><img src="/2017/02/21/一步一步教你如何解锁iPhone/../../../../images/i2.jpeg" alt=""><br>下一步，只要将用户姓名和电话填到Google的表单中，我们就能获得用户的电子邮箱地址了。</p>
<h2 id="修改Google账户的密码"><a href="#修改Google账户的密码" class="headerlink" title="修改Google账户的密码"></a>修改Google账户的密码</h2><p>现在，我们来试着还原犯罪分子修改Google账户密码的场景。</p>
<blockquote>
<ul>
<li>进入Google的登录界面；</li>
<li>选择“忘记密码”选项；</li>
<li>在“你曾经使用过的密码”选项中随便填写一些数字或字母；</li>
<li>接下来，Google会让你填写与账户绑定的手机号码；</li>
<li>输入了手机号之后，Google会给绑定的手机发送一条验证码短信；</li>
<li>输入了验证码之后，Google会要求我们设置新密码。</li>
</ul>
</blockquote>
<p><img src="/2017/02/21/一步一步教你如何解锁iPhone/../../../../images/i3.jpeg" alt=""><br>由此看来，只要别人拿到了你的手机或SIM卡以及你的姓名，他就能轻松地修改你的Google账户密码了。</p>
<h2 id="修改Apple-ID的密码"><a href="#修改Apple-ID的密码" class="headerlink" title="修改Apple ID的密码"></a>修改Apple ID的密码</h2><p>下一步就是修改Apple ID密码了。与修改Google账户密码一样，进入登录界面后选择“忘记密码”选项，然后系统会把重置密码的链接通过邮件发到你的Gmail邮箱中。剩下的操作就简单多了，我们成功地修改了用户的Apple ID密码。<br><img src="/2017/02/21/一步一步教你如何解锁iPhone/../../../../images/i4.jpeg" alt=""></p>
<h2 id="解锁新的iPhone"><a href="#解锁新的iPhone" class="headerlink" title="解锁新的iPhone"></a>解锁新的iPhone</h2><p>在iPhone手机被盗之后，大家第一时间想到的就是远程锁定手机并清除手机中的数据。但是，这几个步骤反而会帮助犯罪分子得到一台“新的”iPhone。</p>
<p>原因是，当iPhone的数据被远程清除后，iPhone会要求你输入与设备绑定的Apple ID和密码，但假如犯罪分子用我们上面所述的办法获取到了AppleID和密码的话，那么犯罪分子就能将这台iPhone当成新手机来使用了。</p>
<h1 id="温馨提示"><a href="#温馨提示" class="headerlink" title="温馨提示"></a>温馨提示</h1><p>以下是我们针对本文中涉及到的安全问题所提出来的建议：</p>
<blockquote>
<p>1、禁止手机在锁屏状态下显示短信或其它通知的内容；<br>2、为手机的SIM卡设置PIN码；<br>3、为你所使用的各种网络服务设置双因素身份验证。</p>
</blockquote>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这次的事件值得我们深思，如果我们不为自己的智能手机做好足够的安全保护措施，那么我们损失的可不仅仅只是手机了。</p>
<blockquote>
<p>来自：FreeBuf.COM<br>链接：<a href="http://www.freebuf.com/news/117369.html" target="_blank" rel="external">http://www.freebuf.com/news/117369.html</a></p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;即使你的iPhone 6s设置了六位数的密码，甚至还设置了touch ID，但我要告诉你的是：你的手机仍然能被犯罪分子解锁。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="趣闻杂谈" scheme="http://lzrlizhirong.github.io/categories/%E8%B6%A3%E9%97%BB%E6%9D%82%E8%B0%88/"/>
    
    
      <category term="趣闻杂谈" scheme="http://lzrlizhirong.github.io/tags/%E8%B6%A3%E9%97%BB%E6%9D%82%E8%B0%88/"/>
    
  </entry>
  
  <entry>
    <title>通过edu.cn邮箱申请免费试用jetbrains全套产品</title>
    <link href="http://lzrlizhirong.github.io/2017/02/20/%E9%80%9A%E8%BF%87edu-cn%E9%82%AE%E7%AE%B1%E7%94%B3%E8%AF%B7%E5%85%8D%E8%B4%B9%E8%AF%95%E7%94%A8jetbrains%E5%85%A8%E5%A5%97%E4%BA%A7%E5%93%81/"/>
    <id>http://lzrlizhirong.github.io/2017/02/20/通过edu-cn邮箱申请免费试用jetbrains全套产品/</id>
    <published>2017-02-20T09:43:48.000Z</published>
    <updated>2017-02-21T04:02:44.000Z</updated>
    
    <content type="html"><![CDATA[<p>jetbrains在IDE界鼎鼎大名，产品有：IntelliJ IDEA、WebStorm、PhpStorm等等,如下图所示：<br><img src="/2017/02/20/通过edu-cn邮箱申请免费试用jetbrains全套产品/../../../../images/idea1.png" alt=""><br><a id="more"></a><br>Intellij的正版授权，还是比较贵的，大概人民币一千多。后来听说可以通过教育邮箱申请免费试用，步骤如下：</p>
<p>首先，访问<a href="https://www.jetbrains.com/student/" target="_blank" rel="external">Jetbrains students license</a>，然后点击立即申请，按照邮件的提示即可完成。最后用你的账户登录IDE即可完成激活。从此以后，你就可以使用永久免费试用最新版的Jetbrains的所有软件了。</p>
<p>当然，当你经济条件允许的时候，我还是建议你买一波正版，支持一下~都是同行，莫坑队友。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;jetbrains在IDE界鼎鼎大名，产品有：IntelliJ IDEA、WebStorm、PhpStorm等等,如下图所示：&lt;br&gt;&lt;img src=&quot;/2017/02/20/通过edu-cn邮箱申请免费试用jetbrains全套产品/../../../../images/idea1.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="idea" scheme="http://lzrlizhirong.github.io/categories/idea/"/>
    
    
      <category term="jetbrains" scheme="http://lzrlizhirong.github.io/tags/jetbrains/"/>
    
      <category term="idea" scheme="http://lzrlizhirong.github.io/tags/idea/"/>
    
  </entry>
  
  <entry>
    <title>再识SpringBoot微框架--简单案例</title>
    <link href="http://lzrlizhirong.github.io/2017/02/20/%E5%86%8D%E8%AF%86SpringBoot%E5%BE%AE%E6%A1%86%E6%9E%B6-%E6%90%AD%E5%BB%BA%E6%A1%88%E4%BE%8B/"/>
    <id>http://lzrlizhirong.github.io/2017/02/20/再识SpringBoot微框架-搭建案例/</id>
    <published>2017-02-20T04:26:57.000Z</published>
    <updated>2017-02-20T08:02:44.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="目的："><a href="#目的：" class="headerlink" title="目的："></a>目的：</h1><p>让所有Spring开发变得更快，且让更多的人更快的进行Spring入门体验，提供“starter” POM来简化我们的Maven配置（也就是说使用Spring Boot只有配合maven/gradle等这种依赖管理工具才能发挥它的能力），不像以前，构建一个springmvc项目需要进行好多配置等。</p>
<p>提供一些非功能性的常见的大型项目类特性（如内嵌服务器、安全、度量、健康检查、外部化配置），如可以直接地内嵌Tomcat/Jetty（不需要单独去部署war包）</p>
<p>绝无代码生成，且无需XML配置<br><a id="more"></a></p>
<h1 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h1><p>首先使用Maven创建一个普通Maven应用即可，不必是web的。</p>
<h1 id="添加Spring-Boot相关POM配置"><a href="#添加Spring-Boot相关POM配置" class="headerlink" title="添加Spring Boot相关POM配置"></a>添加Spring Boot相关POM配置</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div></pre></td><td class="code"><pre><div class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</div><div class="line">&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</div><div class="line">         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt;</div><div class="line"></div><div class="line">  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;</div><div class="line"></div><div class="line">  &lt;groupId&gt;cn.com&lt;/groupId&gt;</div><div class="line">  &lt;artifactId&gt;testboot&lt;/artifactId&gt;</div><div class="line">  &lt;packaging&gt;jar&lt;/packaging&gt;</div><div class="line">  &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;</div><div class="line"></div><div class="line">  &lt;name&gt;spring-boot-demo&lt;/name&gt;</div><div class="line">  &lt;description&gt;Demo project for Spring Boot&lt;/description&gt;</div><div class="line"></div><div class="line">  &lt;parent&gt;</div><div class="line">    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;1.4.0.RELEASE&lt;/version&gt;</div><div class="line">    &lt;relativePath/&gt;</div><div class="line">  &lt;/parent&gt;</div><div class="line"></div><div class="line">  &lt;properties&gt;</div><div class="line">    &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;</div><div class="line">    &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;</div><div class="line">    &lt;java.version&gt;1.8&lt;/java.version&gt;</div><div class="line">  &lt;/properties&gt;</div><div class="line"></div><div class="line">  &lt;dependencyManagement&gt;</div><div class="line">    &lt;dependencies&gt;</div><div class="line">      &lt;!-- Camel BOM --&gt;</div><div class="line">      &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;org.apache.camel&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;camel-parent&lt;/artifactId&gt;</div><div class="line">        &lt;version&gt;2.18.2&lt;/version&gt;</div><div class="line">        &lt;scope&gt;import&lt;/scope&gt;</div><div class="line">        &lt;type&gt;pom&lt;/type&gt;</div><div class="line">      &lt;/dependency&gt;</div><div class="line">    &lt;/dependencies&gt;</div><div class="line">  &lt;/dependencyManagement&gt;</div><div class="line"></div><div class="line">  &lt;dependencies&gt;</div><div class="line"></div><div class="line">    &lt;dependency&gt;</div><div class="line">      &lt;groupId&gt;org.apache.camel&lt;/groupId&gt;</div><div class="line">      &lt;artifactId&gt;camel-core&lt;/artifactId&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line"></div><div class="line">    &lt;!-- logging --&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">      &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;</div><div class="line">      &lt;artifactId&gt;log4j-api&lt;/artifactId&gt;</div><div class="line">      &lt;scope&gt;runtime&lt;/scope&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">      &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;</div><div class="line">      &lt;artifactId&gt;log4j-core&lt;/artifactId&gt;</div><div class="line">      &lt;scope&gt;runtime&lt;/scope&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">      &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;</div><div class="line">      &lt;artifactId&gt;log4j-slf4j-impl&lt;/artifactId&gt;</div><div class="line">      &lt;scope&gt;runtime&lt;/scope&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line"></div><div class="line">    &lt;!-- testing --&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">      &lt;groupId&gt;org.apache.camel&lt;/groupId&gt;</div><div class="line">      &lt;artifactId&gt;camel-test&lt;/artifactId&gt;</div><div class="line">      &lt;scope&gt;test&lt;/scope&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line"></div><div class="line">    &lt;dependency&gt;</div><div class="line">      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">      &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line"></div><div class="line">    &lt;dependency&gt;</div><div class="line">      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">      &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;</div><div class="line">      &lt;scope&gt;test&lt;/scope&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">      &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line"></div><div class="line">  &lt;/dependencies&gt;</div><div class="line"></div><div class="line">  &lt;build&gt;</div><div class="line">    &lt;defaultGoal&gt;install&lt;/defaultGoal&gt;</div><div class="line"></div><div class="line">    &lt;plugins&gt;</div><div class="line">      &lt;plugin&gt;</div><div class="line">        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;</div><div class="line">        &lt;version&gt;3.5.1&lt;/version&gt;</div><div class="line">        &lt;configuration&gt;</div><div class="line">          &lt;source&gt;1.8&lt;/source&gt;</div><div class="line">          &lt;target&gt;1.8&lt;/target&gt;</div><div class="line">        &lt;/configuration&gt;</div><div class="line">      &lt;/plugin&gt;</div><div class="line">      &lt;plugin&gt;</div><div class="line">        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt;</div><div class="line">        &lt;version&gt;3.0.1&lt;/version&gt;</div><div class="line">        &lt;configuration&gt;</div><div class="line">          &lt;encoding&gt;UTF-8&lt;/encoding&gt;</div><div class="line">        &lt;/configuration&gt;</div><div class="line">      &lt;/plugin&gt;</div><div class="line"></div><div class="line">      &lt;!-- Allows the example to be run via &apos;mvn compile exec:java&apos; --&gt;</div><div class="line">      &lt;plugin&gt;</div><div class="line">        &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;exec-maven-plugin&lt;/artifactId&gt;</div><div class="line">        &lt;version&gt;1.5.0&lt;/version&gt;</div><div class="line">        &lt;configuration&gt;</div><div class="line">          &lt;mainClass&gt;cn.com.MainApp&lt;/mainClass&gt;</div><div class="line">          &lt;includePluginDependencies&gt;false&lt;/includePluginDependencies&gt;</div><div class="line">        &lt;/configuration&gt;</div><div class="line">      &lt;/plugin&gt;</div><div class="line"></div><div class="line">    &lt;/plugins&gt;</div><div class="line">  &lt;/build&gt;</div><div class="line"></div><div class="line">&lt;/project&gt;</div></pre></td></tr></table></figure>
<p>继承spring-boot-starter-parent后我们可以继承一些默认的依赖，这样就无需添加一堆相应的依赖，把依赖配置最小化；spring-boot-starter-web提供了对web的支持，spring-boot-maven-plugin提供了直接运行项目的插件，我们可以直接mvn spring-boot:run运行。</p>
<h1 id="实体"><a href="#实体" class="headerlink" title="实体"></a>实体</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line">package cn.com.testboot.entity;</div><div class="line"></div><div class="line">/**</div><div class="line"> * Created by lizhirong on 2017/2/20.</div><div class="line"> */</div><div class="line">public class User &#123;</div><div class="line">    private Long id;</div><div class="line">    private String name;</div><div class="line">    public Long getId() &#123;</div><div class="line">        return id;</div><div class="line">    &#125;</div><div class="line">    public void setId(Long id) &#123;</div><div class="line">        this.id = id;</div><div class="line">    &#125;</div><div class="line">    public String getName() &#123;</div><div class="line">        return name;</div><div class="line">    &#125;</div><div class="line">    public void setName(String name) &#123;</div><div class="line">        this.name = name;</div><div class="line">    &#125;</div><div class="line">    @Override</div><div class="line">    public boolean equals(Object o) &#123;</div><div class="line">        if (this == o) return true;</div><div class="line">        if (o == null || getClass() != o.getClass()) return false;</div><div class="line">        User user = (User) o;</div><div class="line">        if (id != null ? !id.equals(user.id) : user.id != null) return false;</div><div class="line">        return true;</div><div class="line">    &#125;</div><div class="line">    @Override</div><div class="line">    public int hashCode() &#123;</div><div class="line">        return id != null ? id.hashCode() : 0;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h1 id="控制器"><a href="#控制器" class="headerlink" title="控制器"></a>控制器</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">package cn.com.testboot.controller;</div><div class="line"></div><div class="line">import cn.com.testboot.entity.User;</div><div class="line">import org.springframework.web.bind.annotation.PathVariable;</div><div class="line">import org.springframework.web.bind.annotation.RequestMapping;</div><div class="line">import org.springframework.web.bind.annotation.RestController;</div><div class="line">/**</div><div class="line"> * Created by root on 2017/2/20.</div><div class="line"> */</div><div class="line"></div><div class="line">//@EnableAutoConfiguration</div><div class="line">@RestController</div><div class="line">@RequestMapping(&quot;/user&quot;)</div><div class="line">public class UserController &#123;</div><div class="line">    @RequestMapping(&quot;/&#123;id&#125;&quot;)</div><div class="line">    public User view(@PathVariable(&quot;id&quot;) Long id) &#123;</div><div class="line">        User user = new User();</div><div class="line">        user.setId(id);</div><div class="line">        user.setName(&quot;zhang&quot;);</div><div class="line">        return user;</div><div class="line">    &#125;</div><div class="line">    //public static void main(String[] args) &#123;</div><div class="line">    //    SpringApplication.run(UserController.class);</div><div class="line">    //&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h1 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h1><ol>
<li>第一种方式<br>通过在UserController中加上@EnableAutoConfiguration开启自动配置，然后通过SpringApplication.run(UserController.class);运行这个控制器；这种方式只运行一个控制器比较方便；</li>
<li>第二种方式<br>通过@Configuration+@ComponentScan开启注解扫描并自动注册相应的注解Bean</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">package cn.com.testboot;</div><div class="line"></div><div class="line"></div><div class="line">import org.springframework.boot.SpringApplication;</div><div class="line">import org.springframework.boot.autoconfigure.EnableAutoConfiguration;</div><div class="line">import org.springframework.context.annotation.ComponentScan;</div><div class="line">import org.springframework.context.annotation.Configuration;</div><div class="line"></div><div class="line">/**</div><div class="line"> * Created by root on 2017/2/20.</div><div class="line"> */</div><div class="line">@Configuration</div><div class="line">@ComponentScan</div><div class="line">@EnableAutoConfiguration</div><div class="line">public class Application &#123;</div><div class="line">    public static void main(String[] args) &#123;</div><div class="line">        SpringApplication.run(Application.class);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>到此，一个基本的REST风格的web应用就构建完成了。<br>地址栏输入 <a href="http://localhost:8080/user/1" target="_blank" rel="external">http://localhost:8080/user/1</a> 即可看到json结果。</p>
<p>如果大家查看其依赖，会发现自动添加了需要相应的依赖（不管你用or不用），但是开发一个应用确实变得非常快速，对于想学习or体验Spring的新手，快速建立项目模型等可以考虑用这种方式。当然如果不想依赖这么多的jar包，可以去掉parent，然后自己添加依赖。 </p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;目的：&quot;&gt;&lt;a href=&quot;#目的：&quot; class=&quot;headerlink&quot; title=&quot;目的：&quot;&gt;&lt;/a&gt;目的：&lt;/h1&gt;&lt;p&gt;让所有Spring开发变得更快，且让更多的人更快的进行Spring入门体验，提供“starter” POM来简化我们的Maven配置（也就是说使用Spring Boot只有配合maven/gradle等这种依赖管理工具才能发挥它的能力），不像以前，构建一个springmvc项目需要进行好多配置等。&lt;/p&gt;
&lt;p&gt;提供一些非功能性的常见的大型项目类特性（如内嵌服务器、安全、度量、健康检查、外部化配置），如可以直接地内嵌Tomcat/Jetty（不需要单独去部署war包）&lt;/p&gt;
&lt;p&gt;绝无代码生成，且无需XML配置&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="SpringBoot" scheme="http://lzrlizhirong.github.io/categories/SpringBoot/"/>
    
    
      <category term="SpringBoot" scheme="http://lzrlizhirong.github.io/tags/SpringBoot/"/>
    
      <category term="微服务" scheme="http://lzrlizhirong.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>初试SpringBoot微框架</title>
    <link href="http://lzrlizhirong.github.io/2017/02/20/SpringBoot%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://lzrlizhirong.github.io/2017/02/20/SpringBoot学习笔记/</id>
    <published>2017-02-20T03:53:22.000Z</published>
    <updated>2017-02-20T04:25:08.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-Spring-Boot是什么，解决哪些问题"><a href="#1-Spring-Boot是什么，解决哪些问题" class="headerlink" title="1. Spring Boot是什么，解决哪些问题"></a>1. Spring Boot是什么，解决哪些问题</h1><blockquote>
<p>   1) Spring Boot使编码变简单<br>     2) Spring Boot使配置变简单<br>     3) Spring Boot使部署变简单<br>     4) Spring Boot使监控变简单</p>
</blockquote>
<a id="more"></a>
<h1 id="2-Spring-Boot在平台中的定位，相关技术如何融合"><a href="#2-Spring-Boot在平台中的定位，相关技术如何融合" class="headerlink" title="2. Spring Boot在平台中的定位，相关技术如何融合"></a>2. Spring Boot在平台中的定位，相关技术如何融合</h1><blockquote>
<p>   1) SpringBoot与SEDA +MicroService + RESTful<br>     2) SpringBoot与Mock</p>
</blockquote>
<h1 id="3-采用了SpringBoot之后，技术管理应该如何进行"><a href="#3-采用了SpringBoot之后，技术管理应该如何进行" class="headerlink" title="3. 采用了SpringBoot之后，技术管理应该如何进行"></a>3. 采用了SpringBoot之后，技术管理应该如何进行</h1><p>首先，我们来看一下spring boot是什么，它帮助我们解决了哪些问题：<br><img src="/2017/02/20/SpringBoot学习笔记/../../../../images/sb1.jpeg" alt=""><br>SpringBoot是伴随着Spring4.0诞生的；</p>
<p>从字面理解，Boot是引导的意思，因此SpringBoot帮助开发者快速搭建Spring框架；</p>
<p>SpringBoot帮助开发者快速启动一个Web容器；</p>
<p>SpringBoot继承了原有Spring框架的优秀基因；</p>
<p>SpringBoot简化了使用Spring的过程。</p>
<p><img src="/2017/02/20/SpringBoot学习笔记/../../../../images/sb2.jpeg" alt=""><br>Spring由于其繁琐的配置，一度被人认为“配置地狱”，各种XML、Annotation配置，让人眼花缭乱，而且如果出错了也很难找出原因。</p>
<p>Spring Boot更多的是采用Java Config的方式，对Spring进行配置。<br><img src="/2017/02/20/SpringBoot学习笔记/../../../../images/sb3.jpeg" alt=""></p>
<p><img src="/2017/02/20/SpringBoot学习笔记/../../../../images/sb4.jpeg" alt=""></p>
<p><img src="/2017/02/20/SpringBoot学习笔记/../../../../images/sb5.jpeg" alt=""><br>可以看到，采用了spring-boot-start-actuator之后，直接以REST的方式，获取进程的运行期性能参数。</p>
<p>当然这些metrics有些是有敏感数据的，spring-boot-start-actuator为此提供了一些Basic Authentication认证的方案，这些方案在实际应用过程中也是不足的。<br><img src="/2017/02/20/SpringBoot学习笔记/../../../../images/sb6.jpeg" alt=""></p>
<p>Spring Boot作为一个微框架，离微服务的实现还是有距离的。</p>
<p>没有提供相应的服务发现和注册的配套功能，自身的acturator所提供的监控功能，也需要与现有的监控对接。没有配套的安全管控方案，对于REST的落地，还需要自行结合实际进行URI的规范化工作。</p>
<p>下面，我们研究一下Spring Boot在平台中的定位，相关技术如何融合。<br><img src="/2017/02/20/SpringBoot学习笔记/../../../../images/sb7.jpeg" alt=""></p>
<p><img src="/2017/02/20/SpringBoot学习笔记/../../../../images/sb8.jpeg" alt=""><br>上图比较复杂，整体是采用SEDA，也就是Stage-EDA。可以看到，整体是以处理顺序进行展示的，响应过程类似。在处理过程中，主要会有前置过滤，核心功能处理，后置过滤几大部分。</p>
<p>图中的过滤器都是可插拔式的，并且可以根据实际场景进行扩展开发。每个过滤器都是Stage，比如ClientInstance合法性检查、调用鉴权、解密、限流等等。</p>
<p>一个请求Stage与Stage的转换，实现上是切换不同的线程池，并以EDA的方式驱动。</p>
<p>对于业务逻辑的开发者而言，只需要关心CORE部分的业务逻辑实现，其他的非功能都由框架进行统一实现。</p>
<p><img src="/2017/02/20/SpringBoot学习笔记/../../../../images/sb9.jpeg" alt=""></p>
<p>Mock不应当再是测试的专有名词了，当然对于测试这个角色而言，mockito这样的工具，依然可以为他们提升不少效率。</p>
<p>SpringBoot为创建REST服务提供了简便的途径，相比之下，采用阿里的dubbo在做多团队、多进程联调时，mock的难度就陡增。</p>
<p>Mock是解耦并行开发的利器，在理性的情况下，软件从开发期Mock联调，到开发与开发的真实联调，只需要切换一个依赖的域名即可，比如：<br>mockURI:<a href="http://mock.service.net/v1/function?param1=value1" target="_blank" rel="external">http://mock.service.net/v1/function?param1=value1</a><br>devURI:<a href="http://dev.service.net/v1/function?param1=value1" target="_blank" rel="external">http://dev.service.net/v1/function?param1=value1</a></p>
<p>而上述的域名切换，只需要在开发期定义好一个配置项，在做环境切换的时候自动注入即可，省时、省心、省力。</p>
<p><img src="/2017/02/20/SpringBoot学习笔记/../../../../images/sb10.jpeg" alt=""><br>如上图和docker的集成可以有AB两种方案：</p>
<ul>
<li>A方案的核心是，把docker作为操作系统环境的交付基线，也就是不同的fat jar 使用相同的操作系统版本、相同的JVM环境。但对于docker image来说都是一样的。</li>
<li>B方案的核心是，不同的fat jar，独立的编译为docker image，在启动时直接启动带有特定版本的image。</li>
</ul>
<p>A相比与B方案的特点是对于docker registry（也就是docker的镜像仓库）的依赖性较低，对于前期编译过程的要求也较低。</p>
<p>采用了Spring Boot之后，技术管理应该如何进行？<br><img src="/2017/02/20/SpringBoot学习笔记/../../../../images/sb11.jpeg" alt=""><br>正因为Spring Boot是与Spring一脉相承的，所以对于广大的Java开发者而言，对于Spring的学习成本几乎为零。</p>
<p>在实践Spring Boot时学习重点，或者说思维方式改变的重点在于：</p>
<ol>
<li>对于REST的理解，这一点尤为重要，需要从设计、开发多个角色达成共识，很多时候都是对于HTTP 1.1协议以及REST的精髓不理解，导致REST被「盲用」而产生一些不好的效果。</li>
<li>对于YAML的理解和对于JavaConfig的理解，这两点相对较为简单，本质上是简化了xml文件，并提供等价的配置表述能力。</li>
</ol>
<p><img src="/2017/02/20/SpringBoot学习笔记/../../../../images/sb12.jpeg" alt=""></p>
<blockquote>
<ol>
<li>丰富的工具链为SpringBoot的推广带来了利好。</li>
<li>SpringBoot的工具链主要来自于两个方面：<br>1) 原有Spring积累的工具链；<br>2) SpringMVC或者其他REST框架使用HTTP协议，使得HTTP丰富的工具成为SpringBoot天然的资源。</li>
</ol>
</blockquote>
<p><img src="/2017/02/20/SpringBoot学习笔记/../../../../images/sb13.jpeg" alt=""></p>
<p>SpringBoot自身对于前面提到的配置文件：“application.yml”提供了多个「Profile」，可以便于开发者描述不同环境的配置，这些配置例如数据库的连接地址、用户名和密码。</p>
<p>但是对于企业用户而言，把不同环境的配置，写到同一个配置文件中，是极其不安全的，是一个非常危险的动作。</p>
<p>有一个经常被提及的例子是，随着开源的进行，很多互联网公司，都由于把相关的代码提交到github之类的开源代码社区，并且没有对代码进行严格的配置审查，导致一些”password”被公开。有些不良用心的人，就利用搜索工具，专门去挖掘这些关键字，进而导致数据库被「拖库」。</p>
<p>所以对于企业用户，更多的应该是采用集中式的配置管理系统，将不同环境的配置严格区分地存放。</p>
<p>虽然SpringBoot的actuator自身提供了基于「用户名+口令」的最简单的认证方式，但它保护的是对框架自身运行期的性能指标敏感数据的最基本的保护。这种保护在实际应用过程中，「用户名+口令」的管理是缺乏的，「用户名+口令」的安全配置过程是缺失的。</p>
<p>SpringBoot也不提供对于我们自己开发的功能的任何防护功能。</p>
<p>一般来讲，一个安全的信道（信息传输的通道），需要通信双方在进行正式的信息传输之前对对方进行身份认证，服务提供方还需要在此基础之上，对请求方的请求进行权限的校验，以确保业务安全。这些内容也需要基于SpringBoot进行外围的安全扩展，例如采用前面提到的S-EDA进行进程级别的安全管控。这些还需要配套的安全服务提供支持。</p>
<p>一般来说，只要企业与互联网对接，那么随便一个面向消费者的「市场活动」，就有可能为企业带来井喷的流量。</p>
<p>传统企业内，更多的系统是管理信息类的支撑系统，这类系统在设计时的主要用户是企业内部员工以及有限的外部供应商。这类系统存在于企业内部的时间一直很长，功能耦合也很多，在功能解耦前，是非常不适合的，或者说绝对不可以直接为互联网的用户进行服务的。</p>
<p>SpringBoot自身并没有提供这样的流控措施，所以需要结合前面提到的S-EDA进行流量的控制，并结合下层的水平扩展能力（例如，Kubernets）进行流量负载合理的动态扩容。</p>
<p>另外，在长业务流程的设计上，也尽可能地采用异步的方式，比如接口调用返回的是一个「受理号」，而不是业务的处理结果，避免井喷业务到来时，同步调用所带来的阻塞导致系统迅速崩溃，这些也都是SpringBoot自身并不解决的问题。</p>
<p>以上是我分享的主要内容，下面我们总结一下：</p>
<p><img src="/2017/02/20/SpringBoot学习笔记/../../../../images/sb14.jpeg" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-Spring-Boot是什么，解决哪些问题&quot;&gt;&lt;a href=&quot;#1-Spring-Boot是什么，解决哪些问题&quot; class=&quot;headerlink&quot; title=&quot;1. Spring Boot是什么，解决哪些问题&quot;&gt;&lt;/a&gt;1. Spring Boot是什么，解决哪些问题&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;   1) Spring Boot使编码变简单&lt;br&gt;     2) Spring Boot使配置变简单&lt;br&gt;     3) Spring Boot使部署变简单&lt;br&gt;     4) Spring Boot使监控变简单&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="SpringBoot" scheme="http://lzrlizhirong.github.io/categories/SpringBoot/"/>
    
    
      <category term="SpringBoot" scheme="http://lzrlizhirong.github.io/tags/SpringBoot/"/>
    
      <category term="微服务" scheme="http://lzrlizhirong.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>Apache Beam：一个开源的统一的分布式数据处理编程库</title>
    <link href="http://lzrlizhirong.github.io/2017/02/16/Apache-Beam%EF%BC%9A%E4%B8%80%E4%B8%AA%E5%BC%80%E6%BA%90%E7%9A%84%E7%BB%9F%E4%B8%80%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E7%BC%96%E7%A8%8B%E5%BA%93/"/>
    <id>http://lzrlizhirong.github.io/2017/02/16/Apache-Beam：一个开源的统一的分布式数据处理编程库/</id>
    <published>2017-02-16T10:55:34.000Z</published>
    <updated>2017-02-21T04:03:32.000Z</updated>
    
    <content type="html"><![CDATA[<p>Apache Beam是一个开源的数据处理编程库，由Google贡献给Apache的项目，前不久刚刚成为Apache TLP项目。它提供了一个高级的、统一的编程模型，允许我们通过构建Pipeline的方式实现批量、流数据处理，并且构建好的Pipeline能够运行在底层不同的执行引擎上。刚刚接触该开源项目时，我的第一感觉就是：在编程API的设计上，数据集及其操作的抽象有点类似Apache Crunch（MapReduce Pipeline编程库）项目；而在支持统一数据处理模型上，能够让人想到Apache Flink项目。如果深入了解Apache Beam，你会发现未来Apache Beam很可能成为数据处理领域唯一一个能够将不同的数据应用统一起来的编程库。<br><a id="more"></a></p>
<h1 id="Apache-Beam架构概览"><a href="#Apache-Beam架构概览" class="headerlink" title="Apache Beam架构概览"></a>Apache Beam架构概览</h1><p>Apache Beam目前最新版本为0.5.0-SNAPSHOT，最新的Release版本为0.4.0，很多特性还在开发中。在网上找到一个由Andrew Psaltis在2016年6月份演讲的《Apache Beam: The Case for Unifying Streaming API’s》，引用了其中一个Apache Beam的架构图，如下图所示：<br><img src="/2017/02/16/Apache-Beam：一个开源的统一的分布式数据处理编程库/../../../../images/b1.png" alt=""><br>上图中，我们可以看到，Apache Beam核心的主要有两层：</p>
<p><strong>1. Pipeline构建层</strong></p>
<p>在Pipeline构建层，针对不同的编程语言，构建一组用于定义Pipeline相关抽象，提供编程API，这一层被称为Beam SDKs。最终的用户（具有不同编程语言技能的人员）可以基于这些抽象的Beam SDK来构建数据处理Pipeline。</p>
<p><strong>2. Runner适配层</strong></p>
<p>Runner适配层，主要是用来对接底层的计算引擎，用来执行上层用户开发好的Pipeline程序。</p>
<p>我们先根据官网文档，了解一下Apache Beam的Roadmap。首先，下面的三个特性，或者说是Apache Beam的目标：</p>
<p><strong>1. 统一（UNIFIED）</strong></p>
<p>基于单一的编程模型，能够实现批处理（Batch processing）、流处理（Streaming Processing），通常的做法是把待处理的数据集（Dataset）统一，一般会把有界（Bound）数据集作为无界（Unbound）数据集的一种特殊情况来看待，比如Apache Flink便是按照这种方式处理，在差异化的API层之上构建一个统一的API层。</p>
<p><strong>2. 可移植（PORTABLE）</strong></p>
<p>在多个不同的计算环境下，都能够执行已经定义好的数据处理Pipeline。也就是说，对数据集处理的定义（即构建的Data Pipeline），与最终所要Deploy的执行环境完全无关。这对实现数据处理的企业是非常友好的，当下数据处理新技术不断涌现，企业数据处理平台也为了能够与时俱进并提高处理效率，当然希望在底层计算平台升级的过程中无需重写上层已定义的Data Pipeline。<br>目前，Apache Beam项目开发整体来看还处在初期，初步决定底层执行环境支持主流的计算平台：Apache Apex、Apache Flink、Apache Spark、Google Cloud Dataflow。实际上，Apache Beam的这种统一编程模型，可以支持任意的计算引擎，通过Data Pipeline层与执行引擎层之间开发一个类似Driver的连接器即可实现。</p>
<p><strong>3. 可扩展（EXTENSIBLE）</strong></p>
<p>实现任意可以共享的Beam SDK、IO connector、Transform库。</p>
<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><p>在使用Apache Beam构建数据处理程序，首先需要使用Beam SDK中的类创建一个Driver程序，在Driver程序中创建一个满足我们数据处理需求的Pipeline，Pipeline中包括输入（Inputs）、转换（Transformations）、输出（Outputs）三个核心的组件。然后，根据我们选择的Beam SDK来确定底层使用Pipeline Runner（执行引擎，或计算引擎），将我们定义好的Pipeline运行在Pipeline Runner上。<br>Apache Beam SDKs提供一组抽象，用来简化大规模分布式数据处理。同一个Beam抽象，能够同时适应批量处理、流处理两种数据源。下面，我们了解一下Apache Beam的一些关键抽象：</p>
<h2 id="1-Pipeline"><a href="#1-Pipeline" class="headerlink" title="1. Pipeline"></a>1. Pipeline</h2><p>一个Pipeline是对一个数据处理任务抽象，它包含了我们在对给定数据集处理的全部逻辑，主要包括从数据源读取数据（可能从多个数据源读取）、在给定的数据集上执行Transform操作（中间可能是一个DAG图，通过多个Transform连接，而Transform的输出和输出都可能是一个数据集）、将Transform的数据结果写入到指定对的存储系统中。</p>
<h2 id="2-PCollection"><a href="#2-PCollection" class="headerlink" title="2. PCollection"></a>2. PCollection</h2><p>一个PCollection是对分布式数据集的抽象，他可以是输入数据集、中间结果数据集、输出数据集。每一个由PCollection表征的数据集作为输入时，都会存在一个或多个Transform作用在其上（对数据集进行处理的逻辑）。</p>
<h2 id="3-Transform"><a href="#3-Transform" class="headerlink" title="3. Transform"></a>3. Transform</h2><p>一个Transform表示数据处理过程中一个步骤（Step），对应于Pipeline中一个操作，每一个Transform会以一个或多个PCollection作为输入，经过处理后输出一个或多个PCollection。</p>
<h2 id="4-Source-and-Sink"><a href="#4-Source-and-Sink" class="headerlink" title="4. Source and Sink"></a>4. Source and Sink</h2><p>Apache Beam提供了Source和Sink的API，用来表示读取和写入数据。Source表示从一个外部的数据源读入数据到Pipeline，而Sink表示经过Pipeline处理后将数据写入到外部存储系统</p>
<h2 id="5-PipelineRunner"><a href="#5-PipelineRunner" class="headerlink" title="5. PipelineRunner"></a>5. PipelineRunner</h2><p>PipelineRunner是实际用来处理Pipeline逻辑的底层组件，它能够将用户构建的Pipeline翻译成底层计算引擎能够处理的Job，并执行Pipeline的处理逻辑。</p>
<h1 id="API设计"><a href="#API设计" class="headerlink" title="API设计"></a>API设计</h1><p>Apache Beam还在开发之中，后续对应的API设计可能会有所变化，不过从当前版本来看，基于对数据处理领域对象的抽象，API的设计风格大量使用泛型来定义，具有很高的抽象级别。下面我们分别对感兴趣的的设计来详细说明。</p>
<h2 id="1-Source"><a href="#1-Source" class="headerlink" title="1. Source"></a>1. Source</h2><p>Source表示数据输入的抽象，在API定义上分成两大类：一类是面向数据批处理的，称为BoundedSource，它能够从输入的数据集读取有限的数据记录，知道数据具有有限性的特点，从而能够对输入数据进行切分，分成一定大小的分片，进而实现数据的并行处理；另一类是面向数据流处理的，称为UnboundedSource，它所表示的数据是连续不断地进行输入，从而能够实现支持流式数据所特有的一些操作，如Checkpointing、Watermarks等。<br>Source对应的类设计，如下类图所示：<br><img src="/2017/02/16/Apache-Beam：一个开源的统一的分布式数据处理编程库/../../../../images/b2.png" alt=""><br>目前，Apache Beam支持BoundedSource的数据源主要有：HDFS、MongoDB、Elasticsearch、File等，支持UnboundedSource的数据源主要有：Kinesis、Pubsub、Socker等。未来，任何具有Bounded或Unbounded两类特性的数据源都可以在Apache Beam的抽象基础上实现对应的Source。</p>
<h2 id="2-Sink"><a href="#2-Sink" class="headerlink" title="2. Sink"></a>2. Sink</h2><p>Sink表示任何经过Pipeline中一个或多个PTransform处理过的PCollection，最终会输出到特定的存储中。与Source对应，其实Sink主要也是具有两种类型：一种是直接写入特定存储的Bounded类型，如文件系统；另一种是写入具有Unbounded特性的存储或系统中，如Flink。在API设计上，Sink的类图如下所示：<br><img src="/2017/02/16/Apache-Beam：一个开源的统一的分布式数据处理编程库/../../../../images/b3.png" alt=""><br>可见，基于Sink的抽象，可以实现任意可以写入的存储系统。</p>
<h2 id="3-PipelineRunner"><a href="#3-PipelineRunner" class="headerlink" title="3. PipelineRunner"></a>3. PipelineRunner</h2><p>下面，我们来看一下PipelineRunner的类设计以及目前开发中的PipelineRunner，如下图所示：<br><img src="/2017/02/16/Apache-Beam：一个开源的统一的分布式数据处理编程库/../../../../images/b4.png" alt=""><br>目前，PipelineRunner有DirectRunner、DataflowRunner、SparkRunner、ApexRunner、FlinkRunner，待这些主流的PipelineRunner稳定以后，如果有其他新的计算引擎框架出现，可以在PipelineRunner这一层进行扩展实现。<br>这些PipelineRunner中，DirectRunner是最简单的PipelineRunner，它非常有用，比如我们实现了一个从HDFS读取数据，但是需要在Spark集群上运行的ETL程序，使用DirectRunner可以在本地非常容易地调试ETL程序，调试到程序的数据处理逻辑没有问题了，再最终在实际的生产环境Spark集群上运行。如果特定的PipelineRunner所对应的计算引擎没有很好的支撑调试功能，使用DirectRunner是非常方便的。</p>
<h2 id="4-PCollection"><a href="#4-PCollection" class="headerlink" title="4. PCollection"></a>4. PCollection</h2><p>PCollection是对分布式数据集的抽象，主要用作输入、输出、中间结果集。其中，在Apache Beam中对数据及其数据集的抽象有几类，我们画到一张类图上，如下图所示：<br><img src="/2017/02/16/Apache-Beam：一个开源的统一的分布式数据处理编程库/../../../../images/b5.png" alt=""><br>PCollection是对数据集的抽象，包括输入输出，而基于Window的数据处理有对应的Window相关的抽象，还有一类就是TupleTag，针对具有CoGroup操作的情况下用来标记对应数据中的Tuple数据，具体如何使用可以后面我们实现的Join的例子。</p>
<h2 id="5-PTransform"><a href="#5-PTransform" class="headerlink" title="5. PTransform"></a>5. PTransform</h2><p>一个Pipeline是由一个或多个PTransform构建而成的DAG图，其中每一个PTransform都具有输入和输出，所以PTransform是Apache Beam中非常核心的组件，我按照PTransform的做了一下分类，如下类图所示：<br><img src="/2017/02/16/Apache-Beam：一个开源的统一的分布式数据处理编程库/../../../../images/b6.png" alt=""><br>通过上图可以看出，PTransform针对不同输入或输出的数据的特征，实现了一个算子（Operator）的集合，而Apache Beam除了期望实现一些通用的PTransform实现来供数据处理的开发人员开箱即用，同时也在API的抽象级别上做的非常Open，如果你想实现自己的PTransform来处理指定数据集，只需要自定义即可。而且，随着社区的活跃及其在实际应用场景中推广和使用，会很快构建一个庞大的PTransform实现库，任何有数据处理需求的开发人员都可以共享这些组件。</p>
<h2 id="6-Combine"><a href="#6-Combine" class="headerlink" title="6. Combine"></a>6. Combine</h2><p>这里，单独把Combine这类合并数据集的实现拿出来，它的抽象很有趣，主要面向globally 和per-key这两类抽象，实现了一个非常丰富的PTransform算子库，对应的类图如下所示：<br><img src="/2017/02/16/Apache-Beam：一个开源的统一的分布式数据处理编程库/../../../../images/b7.png" alt=""><br>通过上图可以看出，作用在一个数据集上具有Combine特征的基本操作：Max、Min、Top、Mean、Sum、Count等等。</p>
<h2 id="7-Window"><a href="#7-Window" class="headerlink" title="7. Window"></a>7. Window</h2><p>Window是用来处理某一个Micro batch的数据记录可以进行Merge这种场景的需求，通常用在Streaming处理的情况下。Apache Beam也提供了对Window的抽象，其中对于某一个Window下的数据的处理，是通过WindowFn接口来定义的，与该接口相关的处理类，如下类图所示：<br><img src="/2017/02/16/Apache-Beam：一个开源的统一的分布式数据处理编程库/../../../../images/b8.png" alt=""></p>
<h1 id="编程实战"><a href="#编程实战" class="headerlink" title="编程实战"></a>编程实战</h1><p>首先说明一下，为了简单起见，我直接在代码中显式配置指定PipelineRunner，示例代码片段如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">PipelineOptions options = PipelineOptionsFactory.create();</div><div class="line">options.setRunner(DirectRunner.class);</div></pre></td></tr></table></figure></p>
<p>如果要部署到服务器上，可以通过命令行的方式指定PipelineRunner，比如要在Spark集群上运行，类似如下所示命令行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">spark-submit --class org.test.beam.examples.MinimalWordCountBasedSparkRunner 2017-01-18 --master spark://myserver:7077 target/my-beam-apps-0.0.1-SNAPSHOT-shaded.jar --runner=SparkRunner</div></pre></td></tr></table></figure></p>
<p>下面，我们从几个典型的例子来看（基于Apache Beam软件包的examples有所改动），Apache Beam如何构建Pipeline并运行在指定的PipelineRunner上：</p>
<h2 id="WordCount（Count-Source-Sink）"><a href="#WordCount（Count-Source-Sink）" class="headerlink" title="WordCount（Count/Source/Sink）"></a>WordCount（Count/Source/Sink）</h2><p>我们根据Apache Beam的MinimalWordCount示例代码开始，看如何构建一个Pipeline，并最终执行它。 MinimalWordCount的实现，代码如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div></pre></td><td class="code"><pre><div class="line">package org.test.beam.examples;</div><div class="line"></div><div class="line">import org.apache.beam.runners.direct.DirectRunner;</div><div class="line">import org.apache.beam.sdk.Pipeline;</div><div class="line">import org.apache.beam.sdk.io.TextIO;</div><div class="line">import org.apache.beam.sdk.options.PipelineOptions;</div><div class="line">import org.apache.beam.sdk.options.PipelineOptionsFactory;</div><div class="line">import org.apache.beam.sdk.transforms.Count;</div><div class="line">import org.apache.beam.sdk.transforms.DoFn;</div><div class="line">import org.apache.beam.sdk.transforms.MapElements;</div><div class="line">import org.apache.beam.sdk.transforms.ParDo;</div><div class="line">import org.apache.beam.sdk.transforms.SimpleFunction;</div><div class="line">import org.apache.beam.sdk.values.KV;</div><div class="line"></div><div class="line">public class MinimalWordCount &#123;</div><div class="line"></div><div class="line">    @SuppressWarnings(&quot;serial&quot;)</div><div class="line">    public static void main(String[] args) &#123;</div><div class="line"></div><div class="line">        PipelineOptions options = PipelineOptionsFactory.create();</div><div class="line">        options.setRunner(DirectRunner.class); // 显式指定PipelineRunner：DirectRunner（Local模式）</div><div class="line"></div><div class="line">        Pipeline pipeline = Pipeline.create(options);</div><div class="line"></div><div class="line">        pipeline.apply(TextIO.Read.from(&quot;/tmp/dataset/apache_beam.txt&quot;)) // 读取本地文件，构建第一个PTransform</div><div class="line">                .apply(&quot;ExtractWords&quot;, ParDo.of(new DoFn&lt;String, String&gt;() &#123; // 对文件中每一行进行处理（实际上Split）</div><div class="line"></div><div class="line">                    @ProcessElement</div><div class="line">                    public void processElement(ProcessContext c) &#123;</div><div class="line">                        for (String word : c.element().split(&quot;[\\s:\\,\\.\\-]+&quot;)) &#123;</div><div class="line">                            if (!word.isEmpty()) &#123;</div><div class="line">                                c.output(word);</div><div class="line">                            &#125;</div><div class="line">                        &#125;</div><div class="line">                    &#125;</div><div class="line"></div><div class="line">                &#125;))</div><div class="line">                .apply(Count.&lt;String&gt; perElement()) // 统计每一个Word的Count</div><div class="line">                .apply(&quot;ConcatResultKVs&quot;, MapElements.via( // 拼接最后的格式化输出（Key为Word，Value为Count）</div><div class="line">                        new SimpleFunction&lt;KV&lt;String, Long&gt;, String&gt;() &#123;</div><div class="line"></div><div class="line">                    @Override</div><div class="line">                    public String apply(KV&lt;String, Long&gt; input) &#123;</div><div class="line">                        return input.getKey() + &quot;: &quot; + input.getValue();</div><div class="line">                    &#125;</div><div class="line"></div><div class="line">                &#125;))</div><div class="line">                .apply(TextIO.Write.to(&quot;wordcount&quot;)); // 输出结果</div><div class="line"></div><div class="line">        pipeline.run().waitUntilFinish();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>Pipeline的具体含义，可以看上面代码的注释信息。下面，我们考虑以HDFS数据源作为Source，如何构建第一个PTransform，代码片段如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">PCollection&lt;KV&lt;LongWritable, Text&gt;&gt; resultCollection = pipeline.apply(HDFSFileSource.readFrom(</div><div class="line">        &quot;hdfs://myserver:8020/data/ds/beam.txt&quot;,</div><div class="line">        TextInputFormat.class, LongWritable.class, Text.class))</div></pre></td></tr></table></figure></p>
<p>可以看到，返回的是具有键值分别为LongWritable、Text类型的KV对象集合，后续处理和上面处理逻辑类似。如果使用Maven构建Project，需要加上如下依赖（这里beam.version的值可以为最新Release版本0.4.0）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.apache.beam&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;beam-sdks-java-io-hdfs&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;$&#123;beam.version&#125;&lt;/version&gt;</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure></p>
<h2 id="去重（Distinct）"><a href="#去重（Distinct）" class="headerlink" title="去重（Distinct）"></a>去重（Distinct）</h2><p>去重也是对数据集比较常见的操作，使用Apache Beam来实现，示例代码如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">package org.test.beam.examples;</div><div class="line"></div><div class="line">import org.apache.beam.runners.direct.DirectRunner;</div><div class="line">import org.apache.beam.sdk.Pipeline;</div><div class="line">import org.apache.beam.sdk.io.TextIO;</div><div class="line">import org.apache.beam.sdk.options.PipelineOptions;</div><div class="line">import org.apache.beam.sdk.options.PipelineOptionsFactory;</div><div class="line">import org.apache.beam.sdk.transforms.Distinct;</div><div class="line"></div><div class="line">public class DistinctExample &#123;</div><div class="line"></div><div class="line">    public static void main(String[] args) throws Exception &#123;</div><div class="line"></div><div class="line">         PipelineOptions options = PipelineOptionsFactory.create();</div><div class="line">         options.setRunner(DirectRunner.class); // 显式指定PipelineRunner：DirectRunner（Local模式）</div><div class="line"></div><div class="line">         Pipeline pipeline = Pipeline.create(options);</div><div class="line">         pipeline.apply(TextIO.Read.from(&quot;/tmp/dataset/MY_ID_FILE.txt&quot;))</div><div class="line">             .apply(Distinct.&lt;String&gt; create()) // 创建一个处理String类型的PTransform：Distinct</div><div class="line">             .apply(TextIO.Write.to(&quot;deduped.txt&quot;)); // 输出结果</div><div class="line">         pipeline.run().waitUntilFinish();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="分组（GroupByKey）"><a href="#分组（GroupByKey）" class="headerlink" title="分组（GroupByKey）"></a>分组（GroupByKey）</h2><p>对数据进行分组操作也非常普遍，我们拿一个最基础的PTransform实现GroupByKey来实现一个例子，代码如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line">package org..beam.examples;</div><div class="line"></div><div class="line">import org.apache.beam.runners.direct.DirectRunner;</div><div class="line">import org.apache.beam.runners.direct.repackaged.com.google.common.base.Joiner;</div><div class="line">import org.apache.beam.sdk.Pipeline;</div><div class="line">import org.apache.beam.sdk.io.TextIO;</div><div class="line">import org.apache.beam.sdk.options.PipelineOptions;</div><div class="line">import org.apache.beam.sdk.options.PipelineOptionsFactory;</div><div class="line">import org.apache.beam.sdk.transforms.DoFn;</div><div class="line">import org.apache.beam.sdk.transforms.GroupByKey;</div><div class="line">import org.apache.beam.sdk.transforms.MapElements;</div><div class="line">import org.apache.beam.sdk.transforms.ParDo;</div><div class="line">import org.apache.beam.sdk.transforms.SimpleFunction;</div><div class="line">import org.apache.beam.sdk.values.KV;</div><div class="line"></div><div class="line">public class GroupByKeyExample &#123;</div><div class="line"></div><div class="line">    @SuppressWarnings(&quot;serial&quot;)</div><div class="line">    public static void main(String[] args) &#123;</div><div class="line"></div><div class="line">        PipelineOptions options = PipelineOptionsFactory.create();</div><div class="line">        options.setRunner(DirectRunner.class); // 显式指定PipelineRunner：DirectRunner（Local模式）</div><div class="line"></div><div class="line">        Pipeline pipeline = Pipeline.create(options);</div><div class="line"></div><div class="line">        pipeline.apply(TextIO.Read.from(&quot;/tmp/dataset/MY_INFO_FILE.txt&quot;))</div><div class="line">            .apply(&quot;ExtractFields&quot;, ParDo.of(new DoFn&lt;String, KV&lt;String, String&gt;&gt;() &#123;</div><div class="line"></div><div class="line">                @ProcessElement</div><div class="line">                public void processElement(ProcessContext c) &#123;</div><div class="line">                    // file format example: 35451605324179    3G    CMCC</div><div class="line">                    String[] values = c.element().split(&quot;\t&quot;);</div><div class="line">                    if(values.length == 3) &#123;</div><div class="line">                        c.output(KV.of(values[1], values[0]));</div><div class="line">                    &#125;</div><div class="line">                &#125;</div><div class="line">            &#125;))</div><div class="line">            .apply(&quot;GroupByKey&quot;, GroupByKey.&lt;String, String&gt;create()) // 创建一个GroupByKey实例的PTransform</div><div class="line">            .apply(&quot;ConcatResults&quot;, MapElements.via(</div><div class="line">                    new SimpleFunction&lt;KV&lt;String, Iterable&lt;String&gt;&gt;, String&gt;() &#123;</div><div class="line"></div><div class="line">                        @Override</div><div class="line">                        public String apply(KV&lt;String, Iterable&lt;String&gt;&gt; input) &#123;</div><div class="line">                            return new StringBuffer()</div><div class="line">                                    .append(input.getKey()).append(&quot;\t&quot;)</div><div class="line">                                    .append(Joiner.on(&quot;,&quot;).join(input.getValue()))</div><div class="line">                                    .toString();</div><div class="line">                        &#125;</div><div class="line"></div><div class="line"></div><div class="line">            &#125;))</div><div class="line">            .apply(TextIO.Write.to(&quot;grouppedResults&quot;));</div><div class="line"></div><div class="line">        pipeline.run().waitUntilFinish();</div><div class="line"></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>使用DirectRunner运行，输出文件名称类似于grouppedResults-00000-of-00002、grouppedResults-00001-of-00002等等。</p>
<h2 id="连接（Join）"><a href="#连接（Join）" class="headerlink" title="连接（Join）"></a>连接（Join）</h2><p>最后，我们通过实现一个Join的例子，其中，用户的基本信息包含ID和名称，对应文件格式如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">35451605324179    Jack</div><div class="line">35236905298306    Jim</div><div class="line">35236905519469    John</div><div class="line">35237005022314    Linda</div></pre></td></tr></table></figure></p>
<p>另一个文件是用户使用手机的部分信息，文件格式如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">35451605324179    3G    中国移动</div><div class="line">35236905298306    2G    中国电信</div><div class="line">35236905519469    4G    中国移动</div></pre></td></tr></table></figure></p>
<p>我们希望通过Join操作后，能够知道用户使用的什么网络（用户名+网络），使用Apache Beam实现，具体实现代码如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div></pre></td><td class="code"><pre><div class="line">package org.test.beam.examples;</div><div class="line"></div><div class="line">import org.apache.beam.runners.direct.DirectRunner;</div><div class="line">import org.apache.beam.sdk.Pipeline;</div><div class="line">import org.apache.beam.sdk.io.TextIO;</div><div class="line">import org.apache.beam.sdk.options.PipelineOptions;</div><div class="line">import org.apache.beam.sdk.options.PipelineOptionsFactory;</div><div class="line">import org.apache.beam.sdk.transforms.DoFn;</div><div class="line">import org.apache.beam.sdk.transforms.MapElements;</div><div class="line">import org.apache.beam.sdk.transforms.ParDo;</div><div class="line">import org.apache.beam.sdk.transforms.SimpleFunction;</div><div class="line">import org.apache.beam.sdk.transforms.join.CoGbkResult;</div><div class="line">import org.apache.beam.sdk.transforms.join.CoGroupByKey;</div><div class="line">import org.apache.beam.sdk.transforms.join.KeyedPCollectionTuple;</div><div class="line">import org.apache.beam.sdk.values.KV;</div><div class="line">import org.apache.beam.sdk.values.PCollection;</div><div class="line">import org.apache.beam.sdk.values.TupleTag;</div><div class="line"></div><div class="line">public class JoinExample &#123;</div><div class="line"></div><div class="line">    @SuppressWarnings(&quot;serial&quot;)</div><div class="line">    public static void main(String[] args) &#123;</div><div class="line"></div><div class="line">        PipelineOptions options = PipelineOptionsFactory.create();</div><div class="line">        options.setRunner(DirectRunner.class);  // 显式指定PipelineRunner：DirectRunner（Local模式）</div><div class="line"></div><div class="line">        Pipeline pipeline = Pipeline.create(options);</div><div class="line"></div><div class="line">        // create ID info collection</div><div class="line">        final PCollection&lt;KV&lt;String, String&gt;&gt; idInfoCollection = pipeline</div><div class="line">                .apply(TextIO.Read.from(&quot;/tmp/dataset/MY_ID_INFO_FILE.txt&quot;))</div><div class="line">                .apply(&quot;CreateUserIdInfoPairs&quot;, MapElements.via(</div><div class="line">                        new SimpleFunction&lt;String, KV&lt;String, String&gt;&gt;() &#123;</div><div class="line"></div><div class="line">                    @Override</div><div class="line">                    public KV&lt;String, String&gt; apply(String input) &#123;</div><div class="line">                        // line format example: 35451605324179    Jack</div><div class="line">                        String[] values = input.split(&quot;\t&quot;);</div><div class="line">                        return KV.of(values[0], values[1]);</div><div class="line">                    &#125;</div><div class="line"></div><div class="line">                &#125;));</div><div class="line"></div><div class="line">        // create operation collection</div><div class="line">        final PCollection&lt;KV&lt;String, String&gt;&gt; opCollection = pipeline</div><div class="line">                .apply(TextIO.Read.from(&quot;/tmp/dataset/MY_ID_OP_INFO_FILE.txt&quot;))</div><div class="line">                .apply(&quot;CreateIdOperationPairs&quot;, MapElements.via(</div><div class="line">                        new SimpleFunction&lt;String, KV&lt;String, String&gt;&gt;() &#123;</div><div class="line"></div><div class="line">                    @Override</div><div class="line">                    public KV&lt;String, String&gt; apply(String input) &#123;</div><div class="line">                        // line format example: 35237005342309    3G    CMCC</div><div class="line">                        String[] values = input.split(&quot;\t&quot;);</div><div class="line">                        return KV.of(values[0], values[1]);</div><div class="line">                    &#125;</div><div class="line"></div><div class="line">                &#125;));</div><div class="line"></div><div class="line">        final TupleTag&lt;String&gt; idInfoTag = new TupleTag&lt;String&gt;();</div><div class="line">        final TupleTag&lt;String&gt; opInfoTag = new TupleTag&lt;String&gt;();</div><div class="line"></div><div class="line">        final PCollection&lt;KV&lt;String, CoGbkResult&gt;&gt; cogrouppedCollection = KeyedPCollectionTuple</div><div class="line">                .of(idInfoTag, idInfoCollection)</div><div class="line">                .and(opInfoTag, opCollection)</div><div class="line">                .apply(CoGroupByKey.&lt;String&gt;create());</div><div class="line"></div><div class="line">        final PCollection&lt;KV&lt;String, String&gt;&gt; finalResultCollection = cogrouppedCollection</div><div class="line">                .apply(&quot;CreateJoinedIdInfoPairs&quot;, ParDo.of(new DoFn&lt;KV&lt;String, CoGbkResult&gt;, KV&lt;String, String&gt;&gt;() &#123;</div><div class="line"></div><div class="line">                @ProcessElement</div><div class="line">                public void processElement(ProcessContext c) &#123;</div><div class="line">                    KV&lt;String, CoGbkResult&gt; e = c.element();</div><div class="line">                    String id = e.getKey();</div><div class="line">                    String name = e.getValue().getOnly(idInfoTag);</div><div class="line">                    for (String opInfo : c.element().getValue().getAll(opInfoTag)) &#123;</div><div class="line">                      // Generate a string that combines information from both collection values</div><div class="line">                      c.output(KV.of(id, &quot;\t&quot; + name + &quot;\t&quot; + opInfo));</div><div class="line">                    &#125;</div><div class="line">                &#125;</div><div class="line">        &#125;));</div><div class="line"></div><div class="line">        PCollection&lt;String&gt; formattedResults = finalResultCollection</div><div class="line">                .apply(&quot;FormatFinalResults&quot;, ParDo.of(new DoFn&lt;KV&lt;String, String&gt;, String&gt;() &#123;</div><div class="line">                  @ProcessElement</div><div class="line">                  public void processElement(ProcessContext c) &#123;</div><div class="line">                    c.output(c.element().getKey() + &quot;\t&quot; + c.element().getValue());</div><div class="line">                  &#125;</div><div class="line">                &#125;));</div><div class="line"></div><div class="line">         formattedResults.apply(TextIO.Write.to(&quot;joinedResults&quot;));</div><div class="line">         pipeline.run().waitUntilFinish();</div><div class="line"></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h1 id="参考内容"><a href="#参考内容" class="headerlink" title="参考内容"></a>参考内容</h1><ul>
<li><a href="https://beam.apache.org/" target="_blank" rel="external">https://beam.apache.org/</a></li>
<li><a href="https://beam.apache.org/get-started/quickstart/" target="_blank" rel="external">https://beam.apache.org/get-started/quickstart/</a></li>
<li><a href="https://beam.apache.org/get-started/beam-overview" target="_blank" rel="external">https://beam.apache.org/get-started/beam-overview</a></li>
<li><a href="https://beam.apache.org/documentation/programming-guide/" target="_blank" rel="external">https://beam.apache.org/documentation/programming-guide/</a></li>
<li><a href="https://www.infoq.com/presentations/apache-beam" target="_blank" rel="external">https://www.infoq.com/presentations/apache-beam</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Apache Beam是一个开源的数据处理编程库，由Google贡献给Apache的项目，前不久刚刚成为Apache TLP项目。它提供了一个高级的、统一的编程模型，允许我们通过构建Pipeline的方式实现批量、流数据处理，并且构建好的Pipeline能够运行在底层不同的执行引擎上。刚刚接触该开源项目时，我的第一感觉就是：在编程API的设计上，数据集及其操作的抽象有点类似Apache Crunch（MapReduce Pipeline编程库）项目；而在支持统一数据处理模型上，能够让人想到Apache Flink项目。如果深入了解Apache Beam，你会发现未来Apache Beam很可能成为数据处理领域唯一一个能够将不同的数据应用统一起来的编程库。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="大数据" scheme="http://lzrlizhirong.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据" scheme="http://lzrlizhirong.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="开源技术" scheme="http://lzrlizhirong.github.io/tags/%E5%BC%80%E6%BA%90%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Apache Beam" scheme="http://lzrlizhirong.github.io/tags/Apache-Beam/"/>
    
  </entry>
  
  <entry>
    <title>git常用命令总结</title>
    <link href="http://lzrlizhirong.github.io/2017/02/16/git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93/"/>
    <id>http://lzrlizhirong.github.io/2017/02/16/git常用命令总结/</id>
    <published>2017-02-16T09:57:47.000Z</published>
    <updated>2017-02-16T09:59:09.000Z</updated>
    
    <content type="html"><![CDATA[<p>git branch 不带参数：列出本地已经存在的分支，并且在当前分支的前面加“*”号标记</p>
<p>git branch -r 列出远程分支</p>
<p>git branch -a 列出本地分支和远程分支 </p>
<p>git branch 创建一个新的本地分支，需要注意，此处只是创建分支，不进行分支切换</p>
<p>git branch -m | -M oldbranch newbranch 重命名分支，如果newbranch名字分支已经存在，则需要使用-M强制重命名，否则，使用-m进行重命名。</p>
<p>git branch -d | -D branchname 删除branchname分支</p>
<p>git branch -d -r branchname 删除远程branchname分支</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;git branch 不带参数：列出本地已经存在的分支，并且在当前分支的前面加“*”号标记&lt;/p&gt;
&lt;p&gt;git branch -r 列出远程分支&lt;/p&gt;
&lt;p&gt;git branch -a 列出本地分支和远程分支 &lt;/p&gt;
&lt;p&gt;git branch 创建一个新的本地分支，
    
    </summary>
    
      <category term="工具" scheme="http://lzrlizhirong.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="git" scheme="http://lzrlizhirong.github.io/tags/git/"/>
    
      <category term="工具" scheme="http://lzrlizhirong.github.io/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>Mac Retina解决gitk模糊的问题</title>
    <link href="http://lzrlizhirong.github.io/2017/02/16/Mac-Retina%E8%A7%A3%E5%86%B3gitk%E6%A8%A1%E7%B3%8A%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <id>http://lzrlizhirong.github.io/2017/02/16/Mac-Retina解决gitk模糊的问题/</id>
    <published>2017-02-16T08:55:28.000Z</published>
    <updated>2017-02-16T09:00:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>个人是gitk和Git gui的忠实用户，但是在MAC下安装后，发现极其模糊<br>git在Mac下其实早就适配了高分辨率了，Patch如下：<br><a href="https://gist.githubusercontent.com/cynthia/5f2355a87c2f15d96dbe/raw/6727e73a007b0efabf55dd065e588467ffccc016/wish_app_info_plist.patch" target="_blank" rel="external">https://gist.githubusercontent.com/cynthia/5f2355a87c2f15d96dbe/raw/6727e73a007b0efabf55dd065e588467ffccc016/wish_app_info_plist.patch</a><br>我们只需要把这里面最为关键的<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&lt;key&gt;NSHighResolutionCapable&lt;/key&gt;</div><div class="line">&lt;true/&gt;</div></pre></td></tr></table></figure></p>
<p>复制到Info.plist文件里面就可以了<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vim /System/Library/Frameworks/Tk.framework/Versions/Current/Resources/Wish.app/Contents/Info.plist</div></pre></td></tr></table></figure></p>
<a id="more"></a>
<p>然后在前面加上上面的配置。<br>这之后，我们还需要更新一下Wish.app程序<br>我是这样做的：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">touch Wish.app</div></pre></td></tr></table></figure></p>
<p>注意，在OS X EI Capitan 版本开启了一个rootless的功能，即使是root用户也无法修改/System目录，我们需要进入安全模式后，执行如下命令关闭rootless 功能才能够修改<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">csrutil disable</div></pre></td></tr></table></figure></p>
<p><a href="http://apple.stackexchange.com/questions/193368/what-is-the-rootless-feature-in-el-capitan-really" target="_blank" rel="external">详细了解OS X的rootless</a></p>
<p>mac进入安全模式：<br>开机按住 <strong><em>shift</em></strong> 键即可</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;个人是gitk和Git gui的忠实用户，但是在MAC下安装后，发现极其模糊&lt;br&gt;git在Mac下其实早就适配了高分辨率了，Patch如下：&lt;br&gt;&lt;a href=&quot;https://gist.githubusercontent.com/cynthia/5f2355a87c2f15d96dbe/raw/6727e73a007b0efabf55dd065e588467ffccc016/wish_app_info_plist.patch&quot;&gt;https://gist.githubusercontent.com/cynthia/5f2355a87c2f15d96dbe/raw/6727e73a007b0efabf55dd065e588467ffccc016/wish_app_info_plist.patch&lt;/a&gt;&lt;br&gt;我们只需要把这里面最为关键的&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&amp;lt;key&amp;gt;NSHighResolutionCapable&amp;lt;/key&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;lt;true/&amp;gt;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;复制到Info.plist文件里面就可以了&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;vim /System/Library/Frameworks/Tk.framework/Versions/Current/Resources/Wish.app/Contents/Info.plist&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="工具" scheme="http://lzrlizhirong.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="git" scheme="http://lzrlizhirong.github.io/tags/git/"/>
    
      <category term="工具" scheme="http://lzrlizhirong.github.io/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="mac" scheme="http://lzrlizhirong.github.io/tags/mac/"/>
    
  </entry>
  
  <entry>
    <title>Mac下brew安装gitk遇到错误Error in startup script: unknown color name &#39;lime&#39;</title>
    <link href="http://lzrlizhirong.github.io/2017/02/16/Mac%E4%B8%8Bbrew%E5%AE%89%E8%A3%85gitk%E9%81%87%E5%88%B0%E9%94%99%E8%AF%AFError-in-startup-script-unknown-color-name-lime/"/>
    <id>http://lzrlizhirong.github.io/2017/02/16/Mac下brew安装gitk遇到错误Error-in-startup-script-unknown-color-name-lime/</id>
    <published>2017-02-16T07:41:56.000Z</published>
    <updated>2017-02-16T09:01:39.000Z</updated>
    
    <content type="html"><![CDATA[<p>gitk 用home-brew, brew install git 以后，如果报错误：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">Error in startup script: unknown color name &quot;lime&quot;</div><div class="line"></div><div class="line"> (processing &quot;-fore&quot; option)</div><div class="line"></div><div class="line"> invoked from within</div><div class="line"></div><div class="line">&quot;$ctext tag conf m2 -fore [lindex $mergecolors 2]&quot;</div><div class="line"></div><div class="line"> (procedure &quot;makewindow&quot; line 347)</div><div class="line"></div><div class="line"> invoked from within</div><div class="line"></div><div class="line">&quot;makewindow&quot;</div><div class="line"></div><div class="line"> (file &quot;/usr/local/bin/gitk&quot; line 12434)</div></pre></td></tr></table></figure></p>
<p>解决方法一：</p>
<p>brew cask install tcl</p>
<p>解决方法二：</p>
<p>编辑gitk文件，把相应的color删除或修改。</p>
<p>解决方法三：</p>
<p>在home目录下配一个.gitk文件，将相关color定义一下。<br><a id="more"></a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;gitk 用home-brew, brew install git 以后，如果报错误：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;Error in startup script: unknown color name &amp;quot;lime&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt; (processing &amp;quot;-fore&amp;quot; option)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt; invoked from within&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;quot;$ctext tag conf m2 -fore [lindex $mergecolors 2]&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt; (procedure &amp;quot;makewindow&amp;quot; line 347)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt; invoked from within&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;quot;makewindow&amp;quot;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt; (file &amp;quot;/usr/local/bin/gitk&amp;quot; line 12434)&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;解决方法一：&lt;/p&gt;
&lt;p&gt;brew cask install tcl&lt;/p&gt;
&lt;p&gt;解决方法二：&lt;/p&gt;
&lt;p&gt;编辑gitk文件，把相应的color删除或修改。&lt;/p&gt;
&lt;p&gt;解决方法三：&lt;/p&gt;
&lt;p&gt;在home目录下配一个.gitk文件，将相关color定义一下。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="工具" scheme="http://lzrlizhirong.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="git" scheme="http://lzrlizhirong.github.io/tags/git/"/>
    
      <category term="工具" scheme="http://lzrlizhirong.github.io/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>深入学习Git工作流</title>
    <link href="http://lzrlizhirong.github.io/2017/02/16/%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0Git%E5%B7%A5%E4%BD%9C%E6%B5%81/"/>
    <id>http://lzrlizhirong.github.io/2017/02/16/深入学习Git工作流/</id>
    <published>2017-02-16T03:07:31.000Z</published>
    <updated>2017-02-21T04:02:25.000Z</updated>
    
    <content type="html"><![CDATA[<p>个人在学习git工作流的过程中，从原有的 SVN 模式很难完全理解git的协作模式，直到有一天我看到了下面的文章，好多遗留在心中的困惑迎刃而解。于是我将这部分资料整理如下：</p>
<ul>
<li>我们以使用SVN的工作流来使用git有什么不妥？</li>
<li>git 方便的branch在哪里，团队多人如何协作？冲突了怎么办？如何进行发布控制？</li>
<li>经典的master-发布、develop-主开发、hotfix-不过修复如何避免代码不经过验证上线？</li>
<li>如何在github上面与他人一起协作，star-fork-pull request是怎样的流程？</li>
</ul>
<p>原文链接：<a href="https://www.atlassian.com/git/workflows" target="_blank" rel="external">Git Workflows and Tutorials</a><br>简体中文：由 <a href="https://github.com/oldratlee" target="_blank" rel="external">oldratlee</a> 翻译在 <a href="https://github.com/oldratlee/translations/tree/master/git-workflows-and-tutorials" target="_blank" rel="external">github 上 git-workflows-and-tutorials</a><br><a id="more"></a></p>
<h1 id="一、译序"><a href="#一、译序" class="headerlink" title="一、译序"></a>一、译序</h1><p>工作流其实不是一个初级主题，背后的本质问题其实是有效的项目流程管理和高效的开发协同约定，不仅是Git或SVN等VCS或SCM工具的使用。</p>
<p>这篇指南以大家在SVN中已经广为熟悉使用的集中式工作流作为起点，循序渐进地演进到其它高效的分布式工作流，还介绍了如何配合使用便利的Pull Request功能，体系地讲解了各种工作流的应用。</p>
<p>行文中实践原则和操作示例并重，对于Git的资深玩家可以梳理思考提升，而新接触的同学，也可以跟着step-by-step操作来操练学习并在实际工作中上手使用。</p>
<p>关于Git工作流主题，网上体系的中文资料不多，主要是零散的操作说明，希望这篇文章能让你更深入理解并在工作中灵活有效地使用起来。</p>
<p><strong>PS：</strong><br>文中Pull Request的介绍用的是Bitbucket代码托管服务，由于和GitHub基本一样，如果你用的是GitHub（我自己也主要使用GitHub托管代码），不影响理解和操作。</p>
<p><strong>PPS：</strong><br>本指南循序渐进地讲解工作流，如果Git用的不多，可以从前面的讲的工作流开始操练。操作过程去感受指南的讲解：解决什么问题、如何解决问题，这样理解就深了，也方便活用。</p>
<p>Gitflow工作流是经典模型，体现了工作流的经验和精髓。随着项目过程复杂化，会感受到这个工作流中深思熟虑和威力！</p>
<p>Forking工作流是协作的（GitHub风格）可以先看看Github的Help：Fork A Repo和Using pull requests 。照着操作，给一个Github项目贡献你的提交，有操作经验再看指南容易意会。指南中给了自己实现Fork的方法：Fork就是服务端的克隆。在指南的操练中使用代码托管服务（如GitHub、Bitbucket），可以点一下按钮就让开发者完成仓库的fork操作。</p>
<h1 id="二、Git工作流指南"><a href="#二、Git工作流指南" class="headerlink" title="二、Git工作流指南"></a>二、Git工作流指南</h1><p>工作流有各式各样的用法，但也正因此使得在实际工作中如何上手使用变得很头大。这篇指南通过总览公司团队中最常用的几种Git工作流让大家可以上手使用。</p>
<p>在阅读的过程中请记住，本文中的几种工作流是作为方案指导而不是条例规定。在展示了各种工作流可能的用法后，你可以从不同的工作流中挑选或揉合出一个满足你自己需求的工作流。<br><img src="/2017/02/16/深入学习Git工作流/../../../../images/g1.png" alt=""></p>
<h2 id="集中式工作流"><a href="#集中式工作流" class="headerlink" title="集中式工作流"></a>集中式工作流</h2><p>如果你的开发团队成员已经很熟悉Subversion，集中式工作流让你无需去适应一个全新流程就可以体验Git带来的收益。这个工作流也可以作为向更Git风格工作流迁移的友好过渡。<br><img src="/2017/02/16/深入学习Git工作流/../../../../images/g2.png" alt=""><br>转到分布式版本控制系统看起来像个令人生畏的任务，但不改变已用的工作流你也可以用上Git带来的收益。团队可以用和Subversion完全不变的方式来开发项目。</p>
<p>但使用Git加强开发的工作流，Git有相比SVN的几个优势。<br>首先，每个开发可以有属于自己的整个工程的本地拷贝。隔离的环境让各个开发者的工作和项目的其他部分修改独立开来 ——即自由地提交到自己的本地仓库，先完全忽略上游的开发，直到方便的时候再把修改反馈上去。</p>
<p>其次，Git提供了强壮的分支和合并模型。不像SVN，Git的分支设计成可以做为一种用来在仓库之间集成代码和分享修改的『失败安全』的机制。</p>
<h3 id="工作方式"><a href="#工作方式" class="headerlink" title="工作方式"></a>工作方式</h3><p>像Subversion一样，集中式工作流以中央仓库作为项目所有修改的单点实体。相比SVN缺省的开发分支trunk，Git叫做master，所有修改提交到这个分支上。本工作流只用到master这一个分支。</p>
<p>开发者开始先克隆中央仓库。在自己的项目拷贝中像SVN一样的编辑文件和提交修改；但修改是存在本地的，和中央仓库是完全隔离的。开发者可以把和上游的同步延后到一个方便时间点。</p>
<p>要发布修改到正式项目中，开发者要把本地master分支的修改『推』到中央仓库中。这相当于svn commit操作，但push操作会把所有还不在中央仓库的本地提交都推上去。<br><img src="/2017/02/16/深入学习Git工作流/../../../../images/g3.png" alt=""></p>
<h3 id="冲突解决"><a href="#冲突解决" class="headerlink" title="冲突解决"></a>冲突解决</h3><p>中央仓库代表了正式项目，所以提交历史应该被尊重且是稳定不变的。如果开发者本地的提交历史和中央仓库有分歧，Git会拒绝push提交否则会覆盖已经在中央库的正式提交。<br><img src="/2017/02/16/深入学习Git工作流/../../../../images/g4.png" alt=""><br>在开发者提交自己功能修改到中央库前，需要先fetch在中央库的新增提交，rebase自己提交到中央库提交历史之上。<br>这样做的意思是在说，『我要把自己的修改加到别人已经完成的修改上。』最终的结果是一个完美的线性历史，就像以前的SVN的工作流中一样。</p>
<p>如果本地修改和上游提交有冲突，Git会暂停rebase过程，给你手动解决冲突的机会。Git解决合并冲突，用和生成提交一样的git status和git add命令，很一致方便。还有一点，如果解决冲突时遇到麻烦，Git可以很简单中止整个rebase操作，重来一次（或者让别人来帮助解决）。</p>
<h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>让我们一起逐步分解来看看一个常见的小团队如何用这个工作流来协作的。有两个开发者小明和小红，看他们是如何开发自己的功能并提交到中央仓库上的。</p>
<h4 id="先初始化好中央仓库"><a href="#先初始化好中央仓库" class="headerlink" title="先初始化好中央仓库"></a>先初始化好中央仓库</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g6.png" alt=""><br>第一步，在服务器上创建好中央仓库。如果是新项目，你可以初始化一个空仓库；否则你要导入已有的Git或SVN仓库。</p>
<p>中央仓库应该是个裸仓库（bare repository），即没有工作目录（working directory）的仓库。可以用下面的命令创建：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ssh user@host</div><div class="line">git init --bare /path/to/repo.git</div></pre></td></tr></table></figure></p>
<p>确保写上有效的user（SSH的用户名），host（服务器的域名或IP地址），/path/to/repo.git（你想存放仓库的位置）。<br>注意，为了表示是一个裸仓库，按照约定加上.git扩展名到仓库名上。</p>
<h4 id="所有人克隆中央仓库"><a href="#所有人克隆中央仓库" class="headerlink" title="所有人克隆中央仓库"></a>所有人克隆中央仓库</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g7.png" alt=""><br>下一步，各个开发者创建整个项目的本地拷贝。通过git clone命令完成：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git clone ssh://user@host/path/to/repo.git</div></pre></td></tr></table></figure></p>
<p>基于你后续会持续和克隆的仓库做交互的假设，克隆仓库时Git会自动添加远程别名origin指回『父』仓库。</p>
<h4 id="小明开发功能"><a href="#小明开发功能" class="headerlink" title="小明开发功能"></a>小明开发功能</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g8.png" alt=""><br>在小明的本地仓库中，他使用标准的Git过程开发功能：编辑、暂存（Stage）和提交。<br>如果你不熟悉暂存区（Staging Area），这里说明一下：暂存区的用来准备一个提交，但可以不用把工作目录中所有的修改内容都包含进来。<br>这样你可以创建一个高度聚焦的提交，尽管你本地修改很多内容。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">git status # 查看本地仓库的修改状态</div><div class="line">git add # 暂存文件</div><div class="line">git commit # 提交文件</div></pre></td></tr></table></figure></p>
<p>请记住，因为这些命令生成的是本地提交，小明可以按自己需求反复操作多次，而不用担心中央仓库上有了什么操作。<br>对需要多个更简单更原子分块的大功能，这个做法是很有用的。</p>
<h4 id="小红开发功能"><a href="#小红开发功能" class="headerlink" title="小红开发功能"></a>小红开发功能</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g9.png" alt=""><br>与此同时，小红在自己的本地仓库中用相同的编辑、暂存和提交过程开发功能。和小明一样，她也不关心中央仓库有没有新提交；<br>当然更不关心小明在他的本地仓库中的操作，因为所有本地仓库都是私有的。</p>
<h4 id="小明发布功能"><a href="#小明发布功能" class="headerlink" title="小明发布功能"></a>小明发布功能</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g10.png" alt=""><br>一旦小明完成了他的功能开发，会发布他的本地提交到中央仓库中，这样其它团队成员可以看到他的修改。他可以用下面的git push命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git push origin master</div></pre></td></tr></table></figure></p>
<p>注意，origin是在小明克隆仓库时Git创建的远程中央仓库别名。master参数告诉Git推送的分支。<br>由于中央仓库自从小明克隆以来还没有被更新过，所以push操作不会有冲突，成功完成。</p>
<h4 id="小红试着发布功能"><a href="#小红试着发布功能" class="headerlink" title="小红试着发布功能"></a>小红试着发布功能</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g11.png" alt=""><br>一起来看看在小明发布修改后，小红push修改会怎么样？她使用完全一样的push命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git push origin master</div></pre></td></tr></table></figure></p>
<p>但她的本地历史已经和中央仓库有分岐了，Git拒绝操作并给出下面很长的出错消息：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">error: failed to push some refs to &apos;/path/to/repo.git&apos;</div><div class="line">hint: Updates were rejected because the tip of your current branch is behind</div><div class="line">hint: its remote counterpart. Merge the remote changes (e.g. &apos;git pull&apos;)</div><div class="line">hint: before pushing again.</div><div class="line">hint: See the &apos;Note about fast-forwards&apos; in &apos;git push --help&apos; for details.</div></pre></td></tr></table></figure></p>
<p>这避免了小红覆写正式的提交。她要先pull小明的更新到她的本地仓库合并上她的本地修改后，再重试。</p>
<h4 id="小红在小明的提交之上rebase"><a href="#小红在小明的提交之上rebase" class="headerlink" title="小红在小明的提交之上rebase"></a>小红在小明的提交之上rebase</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g12.png" alt=""><br>小红用git pull合并上游的修改到自己的仓库中。<br>这条命令类似svn update——拉取所有上游提交命令到小红的本地仓库，并尝试和她的本地修改合并：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git pull --rebase origin master</div></pre></td></tr></table></figure></p>
<p>–rebase选项告诉Git把小红的提交移到同步了中央仓库修改后的master分支的顶部，如下图所示：<br><img src="/2017/02/16/深入学习Git工作流/../../../../images/g13.png" alt=""><br>如果你忘加了这个选项，pull操作仍然可以完成，但每次pull操作要同步中央仓库中别人修改时，提交历史会以一个多余的『合并提交』结尾。<br>对于集中式工作流，最好是使用rebase而不是生成一个合并提交。</p>
<h4 id="小红解决合并冲突"><a href="#小红解决合并冲突" class="headerlink" title="小红解决合并冲突"></a>小红解决合并冲突</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g14.png" alt=""><br>rebase操作过程是把本地提交一次一个地迁移到更新了的中央仓库master分支之上。<br>这意味着可能要解决在迁移某个提交时出现的合并冲突，而不是解决包含了所有提交的大型合并时所出现的冲突。<br>这样的方式让你尽可能保持每个提交的聚焦和项目历史的整洁。反过来，简化了哪里引入Bug的分析，如果有必要，回滚修改也可以做到对项目影响最小。</p>
<p>如果小红和小明的功能是互不相关的，不大可能在rebase过程中有冲突。如果有，Git在合并有冲突的提交处暂停rebase过程，输出下面的信息并带上相关的指令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">CONFLICT (content): Merge conflict in &lt;some-file&gt;</div></pre></td></tr></table></figure></p>
<p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g15.png" alt=""><br>Git很赞的一点是，任何人可以解决他自己的冲突。在这个例子中，小红可以简单的运行git status命令来查看哪里有问题。<br>冲突文件列在Unmerged paths（未合并路径）一节中：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"># Unmerged paths:</div><div class="line"># (use &quot;git reset HEAD &lt;some-file&gt;...&quot; to unstage)</div><div class="line"># (use &quot;git add/rm &lt;some-file&gt;...&quot; as appropriate to mark resolution)</div><div class="line">#</div><div class="line"># both modified: &lt;some-file&gt;</div></pre></td></tr></table></figure></p>
<p>接着小红编辑这些文件。修改完成后，用老套路暂存这些文件，并让git rebase完成剩下的事：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">git add &lt;some-file&gt; </div><div class="line">git rebase --continue</div></pre></td></tr></table></figure></p>
<p>要做的就这些了。Git会继续一个一个地合并后面的提交，如其它的提交有冲突就重复这个过程。</p>
<p>如果你碰到了冲突，但发现搞不定，不要惊慌。只要执行下面这条命令，就可以回到你执行git pull –rebase命令前的样子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git rebase --abort</div></pre></td></tr></table></figure></p>
<h4 id="小红成功发布功能"><a href="#小红成功发布功能" class="headerlink" title="小红成功发布功能"></a>小红成功发布功能</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g16.png" alt=""><br>小红完成和中央仓库的同步后，就能成功发布她的修改了：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git push origin master</div></pre></td></tr></table></figure></p>
<p>如你所见，仅使用几个Git命令我们就可以模拟出传统Subversion开发环境。对于要从SVN迁移过来的团队来说这太好了，但没有发挥出Git分布式本质的优势。</p>
<p>如果你的团队适应了集中式工作流，但想要更流畅的协作效果，绝对值得探索一下 功能分支工作流 的收益。<br>通过为一个功能分配一个专门的分支，能够做到一个新增功能集成到正式项目之前对新功能进行深入讨论。</p>
<h2 id="功能分支工作流"><a href="#功能分支工作流" class="headerlink" title="功能分支工作流"></a>功能分支工作流</h2><p>功能分支工作流以集中式工作流为基础，不同的是为各个新功能分配一个专门的分支来开发。这样可以在把新功能集成到正式项目前，用Pull Requests的方式讨论变更。<br><img src="/2017/02/16/深入学习Git工作流/../../../../images/g17.png" alt=""><br><img src="/2017/02/16/深入学习Git工作流/../../../../images/g18.png" alt=""><br>一旦你玩转了集中式工作流，在开发过程中可以很简单地加上功能分支，用来鼓励开发者之间协作和简化交流。</p>
<p>功能分支工作流背后的核心思路是所有的功能开发应该在一个专门的分支，而不是在master分支上。<br>这个隔离可以方便多个开发者在各自的功能上开发而不会弄乱主干代码。<br>另外，也保证了master分支的代码一定不会是有问题的，极大有利于集成环境。</p>
<p>功能开发隔离也让pull requests工作流成功可能，<br>pull requests工作流能为每个分支发起一个讨论，在分支合入正式项目之前，给其它开发者有表示赞同的机会。<br>另外，如果你在功能开发中有问题卡住了，可以开一个pull requests来向同学们征求建议。<br>这些做法的重点就是，pull requests让团队成员之间互相评论工作变成非常方便！</p>
<h3 id="工作方式-1"><a href="#工作方式-1" class="headerlink" title="工作方式"></a>工作方式</h3><p>功能分支工作流仍然用中央仓库，并且master分支还是代表了正式项目的历史。<br>但不是直接提交本地历史到各自的本地master分支，开发者每次在开始新功能前先创建一个新分支。<br>功能分支应该有个有描述性的名字，比如animated-menu-items或issue-#1061，这样可以让分支有个清楚且高聚焦的用途。</p>
<p>在master分支和功能分支之间，Git是没有技术上的区别，所以开发者可以用和集中式工作流中完全一样的方式编辑、暂存和提交修改到功能分支上。</p>
<p>另外，功能分支也可以（且应该）push到中央仓库中。这样不修改正式代码就可以和其它开发者分享提交的功能。<br>由于master仅有的一个『特殊』分支，在中央仓库上存多个功能分支不会有任何问题。当然，这样做也可以很方便地备份各自的本地提交。</p>
<h3 id="Pull-Requests"><a href="#Pull-Requests" class="headerlink" title="Pull Requests"></a>Pull Requests</h3><p>功能分支除了可以隔离功能的开发，也使得通过Pull Requests讨论变更成为可能。<br>一旦某个开发完成一个功能，不是立即合并到master，而是push到中央仓库的功能分支上并发起一个Pull Request请求去合并修改到master。<br>在修改成为主干代码前，这让其它的开发者有机会先去Review变更。</p>
<p>Code Review是Pull Requests的一个重要的收益，但Pull Requests目的是讨论代码一个通用方式。<br>你可以把Pull Requests作为专门给某个分支的讨论。这意味着可以在更早的开发过程中就可以进行Code Review。<br>比如，一个开发者开发功能需要帮助时，要做的就是发起一个Pull Request，相关的人就会自动收到通知，在相关的提交旁边能看到需要帮助解决的问题。</p>
<p>一旦Pull Request被接受了，发布功能要做的就和集中式工作流就很像了。<br>首先，确定本地的master分支和上游的master分支是同步的。然后合并功能分支到本地master分支并push已经更新的本地master分支到中央仓库。</p>
<p>仓库管理的产品解决方案像Bitbucket或Stash，可以良好地支持Pull Requests。可以看看Stash的Pull Requests文档。</p>
<h3 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h3><p>下面的示例演示了如何把Pull Requests作为Code Review的方式，但注意Pull Requests可以用于很多其它的目的。</p>
<h4 id="小红开始开发一个新功能"><a href="#小红开始开发一个新功能" class="headerlink" title="小红开始开发一个新功能"></a>小红开始开发一个新功能</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g19.png" alt=""><br>在开始开发功能前，小红需要一个独立的分支。使用下面的命令新建一个分支：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git checkout -b marys-feature master</div></pre></td></tr></table></figure></p>
<p>这个命令检出一个基于master名为marys-feature的分支，Git的-b选项表示如果分支还不存在则新建分支。<br>这个新分支上，小红按老套路编辑、暂存和提交修改，按需要提交以实现功能：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">git status</div><div class="line">git add &lt;some-file&gt;</div><div class="line">git commit</div></pre></td></tr></table></figure></p>
<h4 id="小红要去吃个午饭"><a href="#小红要去吃个午饭" class="headerlink" title="小红要去吃个午饭"></a>小红要去吃个午饭</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g20.png" alt=""><br>早上小红为新功能添加一些提交。<br>去吃午饭前，push功能分支到中央仓库是很好的做法，这样可以方便地备份，如果和其它开发协作，也让他们可以看到小红的提交。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git push -u origin marys-feature</div></pre></td></tr></table></figure></p>
<p>这条命令push marys-feature分支到中央仓库（origin），-u选项设置本地分支去跟踪远程对应的分支。<br>设置好跟踪的分支后，小红就可以使用git push命令省去指定推送分支的参数。</p>
<h4 id="小红完成功能开发"><a href="#小红完成功能开发" class="headerlink" title="小红完成功能开发"></a>小红完成功能开发</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g21.png" alt=""><br>小红吃完午饭回来，完成整个功能的开发。在合并到master之前，<br>她发起一个Pull Request让团队的其它人知道功能已经完成。但首先，她要确认中央仓库中已经有她最近的提交：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git push</div></pre></td></tr></table></figure></p>
<p>然后，在她的Git GUI客户端中发起Pull Request，请求合并marys-feature到master，团队成员会自动收到通知。<br>Pull Request很酷的是可以在相关的提交旁边显示评注，所以你可以很对某个变更集提问。</p>
<h4 id="小黑收到Pull-Request"><a href="#小黑收到Pull-Request" class="headerlink" title="小黑收到Pull Request"></a>小黑收到Pull Request</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g22.png" alt=""><br>小黑收到了Pull Request后会查看marys-feature的修改。决定在合并到正式项目前是否要做些修改，且通过Pull Request和小红来回地讨论。</p>
<h4 id="小红再做修改"><a href="#小红再做修改" class="headerlink" title="小红再做修改"></a>小红再做修改</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g23.png" alt=""><br>要再做修改，小红用和功能第一个迭代完全一样的过程。编辑、暂存、提交并push更新到中央仓库。小红这些活动都会显示在Pull Request上，小黑可以断续做评注。</p>
<p>如果小黑有需要，也可以把marys-feature分支拉到本地，自己来修改，他加的提交也会一样显示在Pull Request上。</p>
<h4 id="小红发布她的功能"><a href="#小红发布她的功能" class="headerlink" title="小红发布她的功能"></a>小红发布她的功能</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g24.png" alt=""><br>一旦小黑可以的接受Pull Request，就可以合并功能到稳定项目代码中（可以由小黑或是小红来做这个操作）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">git checkout master</div><div class="line">git pull</div><div class="line">git pull origin marys-feature</div><div class="line">git push</div></pre></td></tr></table></figure></p>
<p>无论谁来做合并，首先要检出master分支并确认是它是最新的。然后执行git pull origin marys-feature合并marys-feature分支到和已经和远程一致的本地master分支。<br>你可以使用简单git merge marys-feature命令，但前面的命令可以保证总是最新的新功能分支。<br>最后更新的master分支要重新push回到origin。</p>
<p>这个过程常常会生成一个合并提交。有些开发者喜欢有合并提交，因为它像一个新功能和原来代码基线的连通符。<br>但如果你偏爱线性的提交历史，可以在执行合并时rebase新功能到master分支的顶部，这样生成一个快进（fast-forward）的合并。</p>
<p>一些GUI客户端可以只要点一下『接受』按钮执行好上面的命令来自动化Pull Request接受过程。<br>如果你的不能这样，至少在功能合并到master分支后能自动关闭Pull Request。</p>
<h4 id="与此同时，小明在做和小红一样的事"><a href="#与此同时，小明在做和小红一样的事" class="headerlink" title="与此同时，小明在做和小红一样的事"></a>与此同时，小明在做和小红一样的事</h4><p>当小红和小黑在marys-feature上工作并讨论她的Pull Request的时候，小明在自己的功能分支上做完全一样的事。</p>
<p>通过隔离功能到独立的分支上，每个人都可以自主的工作，当然必要的时候在开发者之间分享变更还是比较繁琐的。</p>
<p>到了这里，但愿你发现了功能分支可以很直接地在 集中式工作流 的仅有的master分支上完成多功能的开发。<br>另外，功能分支还使用了Pull Request，使得可以在你的版本控制GUI客户端中讨论某个提交。</p>
<p>功能分支工作流是开发项目异常灵活的方式。问题是，有时候太灵活了。对于大型团队，常常需要给不同分支分配一个更具体的角色。<br>Gitflow工作流是管理功能开发、发布准备和维护的常用模式。</p>
<h2 id="Gitflow工作流"><a href="#Gitflow工作流" class="headerlink" title="Gitflow工作流"></a>Gitflow工作流</h2><p>Gitflow工作流通过为功能开发、发布准备和维护分配独立的分支，让发布迭代过程更流畅。严格的分支模型也为大型项目提供了一些非常必要的结构。<br><img src="/2017/02/16/深入学习Git工作流/../../../../images/g25.png" alt=""><br>这节介绍的Gitflow工作流借鉴自在nvie的Vincent Driessen。</p>
<p>Gitflow工作流定义了一个围绕项目发布的严格分支模型。虽然比功能分支工作流复杂几分，但提供了用于一个健壮的用于管理大型项目的框架。</p>
<p>Gitflow工作流没有用超出功能分支工作流的概念和命令，而是为不同的分支分配一个很明确的角色，并定义分支之间如何和什么时候进行交互。<br>除了使用功能分支，在做准备、维护和记录发布也使用各自的分支。<br>当然你可以用上功能分支工作流所有的好处：Pull Requests、隔离实验性开发和更高效的协作。</p>
<h3 id="工作方式-2"><a href="#工作方式-2" class="headerlink" title="工作方式"></a>工作方式</h3><p>Gitflow工作流仍然用中央仓库作为所有开发者的交互中心。和其它的工作流一样，开发者在本地工作并push分支到要中央仓库中。</p>
<h3 id="历史分支"><a href="#历史分支" class="headerlink" title="历史分支"></a>历史分支</h3><p>相对使用仅有的一个master分支，Gitflow工作流使用2个分支来记录项目的历史。master分支存储了正式发布的历史，而develop分支作为功能的集成分支。<br>这样也方便master分支上的所有提交分配一个版本号。<br><img src="/2017/02/16/深入学习Git工作流/../../../../images/g26.png" alt=""><br>剩下要说明的问题围绕着这2个分支的区别展开。</p>
<h3 id="功能分支"><a href="#功能分支" class="headerlink" title="功能分支"></a>功能分支</h3><p>每个新功能位于一个自己的分支，这样可以push到中央仓库以备份和协作。<br>但功能分支不是从master分支上拉出新分支，而是使用develop分支作为父分支。当新功能完成时，合并回develop分支。<br>新功能提交应该从不直接与master分支交互。<br><img src="/2017/02/16/深入学习Git工作流/../../../../images/g27.png" alt=""><br>注意，从各种含义和目的上来看，功能分支加上develop分支就是功能分支工作流的用法。但Gitflow工作流没有在这里止步。</p>
<h3 id="发布分支"><a href="#发布分支" class="headerlink" title="发布分支"></a>发布分支</h3><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g28.png" alt=""><br>一旦develop分支上有了做一次发布（或者说快到了既定的发布日）的足够功能，就从develop分支上fork一个发布分支。<br>新建的分支用于开始发布循环，所以从这个时间点开始之后新的功能不能再加到这个分支上——<br>这个分支只应该做Bug修复、文档生成和其它面向发布任务。<br>一旦对外发布的工作都完成了，发布分支合并到master分支并分配一个版本号打好Tag。<br>另外，这些从新建发布分支以来的做的修改要合并回develop分支。</p>
<p>使用一个用于发布准备的专门分支，使得一个团队可以在完善当前的发布版本的同时，另一个团队可以继续开发下个版本的功能。<br>这也打造定义良好的开发阶段（比如，可以很轻松地说，『这周我们要做准备发布版本4.0』，并且在仓库的目录结构中可以实际看到）。</p>
<p>常用的分支约定：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">用于新建发布分支的分支: develop</div><div class="line">用于合并的分支: master</div><div class="line">分支命名: release-* 或 release/*</div></pre></td></tr></table></figure></p>
<h3 id="维护分支"><a href="#维护分支" class="headerlink" title="维护分支"></a>维护分支</h3><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g29.png" alt=""><br>维护分支或说是热修复（hotfix）分支用于生成快速给产品发布版本（production releases）打补丁，这是唯一可以直接从master分支fork出来的分支。<br>修复完成，修改应该马上合并回master分支和develop分支（当前的发布分支），master分支应该用新的版本号打好Tag。</p>
<p>为Bug修复使用专门分支，让团队可以处理掉问题而不用打断其它工作或是等待下一个发布循环。<br>你可以把维护分支想成是一个直接在master分支上处理的临时发布。</p>
<h3 id="示例-2"><a href="#示例-2" class="headerlink" title="示例"></a>示例</h3><p>下面的示例演示本工作流如何用于管理单个发布循环。假设你已经创建了一个中央仓库。</p>
<h4 id="创建开发分支"><a href="#创建开发分支" class="headerlink" title="创建开发分支"></a>创建开发分支</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g30.png" alt=""><br>第一步为master分支配套一个develop分支。简单来做可以本地创建一个空的develop分支，push到服务器上：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">git branch develop</div><div class="line">git push -u origin develop</div></pre></td></tr></table></figure></p>
<p>以后这个分支将会包含了项目的全部历史，而master分支将只包含了部分历史。其它开发者这时应该克隆中央仓库，建好develop分支的跟踪分支：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">git clone ssh://user@host/path/to/repo.git</div><div class="line">git checkout -b develop origin/develop</div></pre></td></tr></table></figure></p>
<p>现在每个开发都有了这些历史分支的本地拷贝。</p>
<h4 id="小红和小明开始开发新功能"><a href="#小红和小明开始开发新功能" class="headerlink" title="小红和小明开始开发新功能"></a>小红和小明开始开发新功能</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g31.png" alt=""><br>这个示例中，小红和小明开始各自的功能开发。他们需要为各自的功能创建相应的分支。新分支不是基于master分支，而是应该基于develop分支：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git checkout -b some-feature develop</div></pre></td></tr></table></figure></p>
<p>他们用老套路添加提交到各自功能分支上：编辑、暂存、提交：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">git status</div><div class="line">git add &lt;some-file&gt;</div><div class="line">git commit</div></pre></td></tr></table></figure></p>
<h4 id="小红完成功能开发-1"><a href="#小红完成功能开发-1" class="headerlink" title="小红完成功能开发"></a>小红完成功能开发</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g32.png" alt=""><br>添加了提交后，小红觉得她的功能OK了。如果团队使用Pull Requests，这时候可以发起一个用于合并到develop分支。<br>否则她可以直接合并到她本地的develop分支后push到中央仓库：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">git pull origin develop</div><div class="line">git checkout develop</div><div class="line">git merge some-feature</div><div class="line">git push</div><div class="line">git branch -d some-feature</div></pre></td></tr></table></figure></p>
<p>第一条命令在合并功能前确保develop分支是最新的。注意，功能决不应该直接合并到master分支。<br>冲突解决方法和集中式工作流一样。</p>
<h4 id="小红开始准备发布"><a href="#小红开始准备发布" class="headerlink" title="小红开始准备发布"></a>小红开始准备发布</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g33.png" alt=""><br>这个时候小明正在实现他的功能，小红开始准备她的第一个项目正式发布。<br>像功能开发一样，她用一个新的分支来做发布准备。这一步也确定了发布的版本号：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git checkout -b release-0.1 develop</div></pre></td></tr></table></figure></p>
<p>这个分支是清理发布、执行所有测试、更新文档和其它为下个发布做准备操作的地方，像是一个专门用于改善发布的功能分支。</p>
<p>只要小红创建这个分支并push到中央仓库，这个发布就是功能冻结的。任何不在develop分支中的新功能都推到下个发布循环中。</p>
<h4 id="小红完成发布"><a href="#小红完成发布" class="headerlink" title="小红完成发布"></a>小红完成发布</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g34.png" alt=""><br>一旦准备好了对外发布，小红合并修改到master分支和develop分支上，删除发布分支。合并回develop分支很重要，因为在发布分支中已经提交的更新需要在后面的新功能中也要是可用的。<br>另外，如果小红的团队要求Code Review，这是一个发起Pull Request的理想时机。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">git checkout master</div><div class="line">git merge release-0.1</div><div class="line">git push</div><div class="line">git checkout develop</div><div class="line">git merge release-0.1</div><div class="line">git push</div><div class="line">git branch -d release-0.1</div></pre></td></tr></table></figure></p>
<p>发布分支是作为功能开发（develop分支）和对外发布（master分支）间的缓冲。只要有合并到master分支，就应该打好Tag以方便跟踪。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">git tag -a 0.1 -m &quot;Initial public release&quot; master</div><div class="line">git push --tags</div></pre></td></tr></table></figure></p>
<p>Git有提供各种勾子（hook），即仓库有事件发生时触发执行的脚本。<br>可以配置一个勾子，在你push中央仓库的master分支时，自动构建好对外发布。</p>
<h4 id="最终用户发现Bug"><a href="#最终用户发现Bug" class="headerlink" title="最终用户发现Bug"></a>最终用户发现Bug</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g35.png" alt=""><br>对外发布后，小红回去和小明一起做下个发布的新功能开发，直到有最终用户开了一个Ticket抱怨当前版本的一个Bug。<br>为了处理Bug，小红（或小明）从master分支上拉出了一个维护分支，提交修改以解决问题，然后直接合并回master分支：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">git checkout -b issue-#001 master</div><div class="line"># Fix the bug</div><div class="line">git checkout master</div><div class="line">git merge issue-#001</div><div class="line">git push</div></pre></td></tr></table></figure></p>
<p>就像发布分支，维护分支中新加这些重要修改需要包含到develop分支中，所以小红要执行一个合并操作。然后就可以安全地删除这个分支了：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">git checkout develop</div><div class="line">git merge issue-#001</div><div class="line">git push</div><div class="line">git branch -d issue-#001</div></pre></td></tr></table></figure></p>
<p>到了这里，但愿你对集中式工作流、功能分支工作流和Gitflow工作流已经感觉很舒适了。<br>你应该也牢固的掌握了本地仓库的潜能，push/pull模式和Git健壮的分支和合并模型。</p>
<p>记住，这里演示的工作流只是可能用法的例子，而不是在实际工作中使用Git不可违逆的条例。<br>所以不要畏惧按自己需要对工作流的用法做取舍。不变的目标就是让Git为你所用。</p>
<h2 id="Forking工作流"><a href="#Forking工作流" class="headerlink" title="Forking工作流"></a>Forking工作流</h2><p>Forking工作流是分布式工作流，充分利用了Git在分支和克隆上的优势。可以安全可靠地管理大团队的开发者（developer），并能接受不信任贡献者（contributor）的提交。</p>
<p>Forking工作流和前面讨论的几种工作流有根本的不同，这种工作流不是使用单个服务端仓库作为『中央』代码基线，而让各个开发者都有一个服务端仓库。这意味着各个代码贡献者有2个Git仓库而不是1个：一个本地私有的，另一个服务端公开的。<br><img src="/2017/02/16/深入学习Git工作流/../../../../images/g36.png" alt=""><br>Forking工作流的一个主要优势是，贡献的代码可以被集成，而不需要所有人都能push代码到仅有的中央仓库中。<br>开发者push到自己的服务端仓库，而只有项目维护者才能push到正式仓库。<br>这样项目维护者可以接受任何开发者的提交，但无需给他正式代码库的写权限。</p>
<p>效果就是一个分布式的工作流，能为大型、自发性的团队（包括了不受信的第三方）提供灵活的方式来安全的协作。<br>也让这个工作流成为开源项目的理想工作流。</p>
<h3 id="工作方式-3"><a href="#工作方式-3" class="headerlink" title="工作方式"></a>工作方式</h3><p>和其它的Git工作流一样，Forking工作流要先有一个公开的正式仓库存储在服务器上。<br>但一个新的开发者想要在项目上工作时，不是直接从正式仓库克隆，而是fork正式项目在服务器上创建一个拷贝。</p>
<p>这个仓库拷贝作为他个人公开仓库 ——<br>其它开发者不允许push到这个仓库，但可以pull到修改（后面我们很快就会看这点很重要）。<br>在创建了自己服务端拷贝之后，和之前的工作流一样，开发者执行git clone命令克隆仓库到本地机器上，作为私有的开发环境。</p>
<p>要提交本地修改时，push提交到自己公开仓库中 —— 而不是正式仓库中。<br>然后，给正式仓库发起一个pull request，让项目维护者知道有更新已经准备好可以集成了。<br>对于贡献的代码，pull request也可以很方便地作为一个讨论的地方。</p>
<p>为了集成功能到正式代码库，维护者pull贡献者的变更到自己的本地仓库中，检查变更以确保不会让项目出错，<br>合并变更到自己本地的master分支，<br>然后pushmaster分支到服务器的正式仓库中。<br>到此，贡献的提交成为了项目的一部分，其它的开发者应该执行pull操作与正式仓库同步自己本地仓库。</p>
<h3 id="正式仓库"><a href="#正式仓库" class="headerlink" title="正式仓库"></a>正式仓库</h3><p>在Forking工作流中，『官方』仓库的叫法只是一个约定，理解这点很重要。<br>从技术上来看，各个开发者仓库和正式仓库在Git看来没有任何区别。<br>事实上，让正式仓库之所以正式的唯一原因是它是项目维护者的公开仓库。</p>
<h3 id="Forking工作流的分支使用方式"><a href="#Forking工作流的分支使用方式" class="headerlink" title="Forking工作流的分支使用方式"></a>Forking工作流的分支使用方式</h3><p>所有的个人公开仓库实际上只是为了方便和其它的开发者共享分支。<br>各个开发者应该用分支隔离各个功能，就像在功能分支工作流和Gitflow工作流一样。<br>唯一的区别是这些分支被共享了。在Forking工作流中这些分支会被pull到另一个开发者的本地仓库中，而在功能分支工作流和Gitflow工作流中是直接被push到正式仓库中。</p>
<h3 id="示例-3"><a href="#示例-3" class="headerlink" title="示例"></a>示例</h3><h4 id="项目维护者初始化正式仓库"><a href="#项目维护者初始化正式仓库" class="headerlink" title="项目维护者初始化正式仓库"></a>项目维护者初始化正式仓库</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g37.png" alt=""><br>和任何使用Git项目一样，第一步是创建在服务器上一个正式仓库，让所有团队成员都可以访问到。<br>通常这个仓库也会作为项目维护者的公开仓库。</p>
<p>公开仓库应该是裸仓库，不管是不是正式代码库。<br>所以项目维护者会运行像下面的命令来搭建正式仓库：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ssh user@host</div><div class="line">git init --bare /path/to/repo.git</div></pre></td></tr></table></figure></p>
<p>Bitbucket和Stash提供了一个方便的GUI客户端以完成上面命令行做的事。<br>这个搭建中央仓库的过程和前面提到的工作流完全一样。<br>如果有现存的代码库，维护者也要push到这个仓库中。</p>
<h4 id="开发者fork正式仓库"><a href="#开发者fork正式仓库" class="headerlink" title="开发者fork正式仓库"></a>开发者fork正式仓库</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g38.png" alt=""><br>其它所有的开发需要fork正式仓库。<br>可以用git clone命令用SSH协议连通到服务器，<br>拷贝仓库到服务器另一个位置 —— 是的，fork操作基本上就只是一个服务端的克隆。<br>Bitbucket和Stash上可以点一下按钮就让开发者完成仓库的fork操作。</p>
<p>这一步完成后，每个开发都在服务端有一个自己的仓库。和正式仓库一样，这些仓库应该是裸仓库。</p>
<h4 id="开发者克隆自己fork出来的仓库"><a href="#开发者克隆自己fork出来的仓库" class="headerlink" title="开发者克隆自己fork出来的仓库"></a>开发者克隆自己fork出来的仓库</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g39.png" alt=""><br>下一步，各个开发者要克隆自己的公开仓库，用熟悉的git clone命令。</p>
<p>在这个示例中，假定用Bitbucket托管了仓库。记住，如果这样的话各个开发者需要有各自的Bitbucket账号，<br>使用下面命令克隆服务端自己的仓库：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git clone https://user@bitbucket.org/user/repo.git</div></pre></td></tr></table></figure></p>
<p>相比前面介绍的工作流只用了一个origin远程别名指向中央仓库，Forking工作流需要2个远程别名 ——<br>一个指向正式仓库，另一个指向开发者自己的服务端仓库。别名的名字可以任意命名，常见的约定是使用origin作为远程克隆的仓库的别名<br>（这个别名会在运行git clone自动创建），upstream（上游）作为正式仓库的别名。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git remote add upstream https://bitbucket.org/maintainer/repo</div></pre></td></tr></table></figure></p>
<p>需要自己用上面的命令创建upstream别名。这样可以简单地保持本地仓库和正式仓库的同步更新。<br>注意，如果上游仓库需要认证（比如不是开源的），你需要提供用户：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git remote add upstream https://user@bitbucket.org/maintainer/repo.git</div></pre></td></tr></table></figure></p>
<p>这时在克隆和pull正式仓库时，需要提供用户的密码。</p>
<h4 id="开发者开发自己的功能"><a href="#开发者开发自己的功能" class="headerlink" title="开发者开发自己的功能"></a>开发者开发自己的功能</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g40.png" alt=""><br>在刚克隆的本地仓库中，开发者可以像其它工作流一样的编辑代码、提交修改和新建分支：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">git checkout -b some-feature</div><div class="line"># Edit some code</div><div class="line">git commit -a -m &quot;Add first draft of some feature&quot;</div></pre></td></tr></table></figure></p>
<p>所有的修改都是私有的直到push到自己公开仓库中。如果正式项目已经往前走了，可以用git pull命令获得新的提交：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git pull upstream master</div></pre></td></tr></table></figure></p>
<p>由于开发者应该都在专门的功能分支上工作，pull操作结果会都是快进合并。</p>
<h4 id="开发者发布自己的功能"><a href="#开发者发布自己的功能" class="headerlink" title="开发者发布自己的功能"></a>开发者发布自己的功能</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g41.png" alt=""><br>一旦开发者准备好了分享新功能，需要做二件事。<br>首先，通过push他的贡献代码到自己的公开仓库中，让其它的开发者都可以访问到。<br>他的origin远程别名应该已经有了，所以要做的就是：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git push origin feature-branch</div></pre></td></tr></table></figure></p>
<p>这里和之前的工作流的差异是，origin远程别名指向开发者自己的服务端仓库，而不是正式仓库。</p>
<p>第二件事，开发者要通知项目维护者，想要合并他的新功能到正式库中。<br>Bitbucket和Stash提供了Pull Request按钮，弹出表单让你指定哪个分支要合并到正式仓库。<br>一般你会想集成你的功能分支到上游远程仓库的master分支中。</p>
<h4 id="项目维护者集成开发者的功能"><a href="#项目维护者集成开发者的功能" class="headerlink" title="项目维护者集成开发者的功能"></a>项目维护者集成开发者的功能</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g42.png" alt=""><br>当项目维护者收到pull request，他要做的是决定是否集成它到正式代码库中。有二种方式来做：</p>
<ol>
<li>直接在pull request中查看代码</li>
<li>pull代码到他自己的本地仓库，再手动合并<br>第一种做法更简单，维护者可以在GUI中查看变更的差异，做评注和执行合并。<br>但如果出现了合并冲突，需要第二种做法来解决。这种情况下，维护者需要从开发者的服务端仓库中fetch功能分支，<br>合并到他本地的master分支，解决冲突：<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">git fetch https://bitbucket.org/user/repo feature-branch</div><div class="line"># 查看变更</div><div class="line">git checkout master</div><div class="line">git merge FETCH_HEAD</div></pre></td></tr></table></figure>
</li>
</ol>
<p>变更集成到本地的master分支后，维护者要push变更到服务器上的正式仓库，这样其它的开发者都能访问到：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git push origin master</div></pre></td></tr></table></figure></p>
<p>注意，维护者的origin是指向他自己公开仓库的，即是项目的正式代码库。到此，开发者的贡献完全集成到了项目中。</p>
<h4 id="开发者和正式仓库做同步"><a href="#开发者和正式仓库做同步" class="headerlink" title="开发者和正式仓库做同步"></a>开发者和正式仓库做同步</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g43.png" alt=""><br>由于正式代码库往前走了，其它的开发需要和正式仓库做同步：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git pull upstream master</div></pre></td></tr></table></figure></p>
<p>如果你之前是使用SVN，Forking工作流可能看起来像是一个激进的范式切换（paradigm shift）。<br>但不要害怕，这个工作流实际上就是在功能分支工作流之上引入另一个抽象层。<br>不是直接通过单个中央仓库来分享分支，而是把贡献代码发布到开发者自己的服务端仓库中。</p>
<p>示例中解释了，一个贡献如何从一个开发者流到正式的master分支中，但同样的方法可以把贡献集成到任一个仓库中。<br>比如，如果团队的几个人协作实现一个功能，可以在开发之间用相同的方法分享变更，完全不涉及正式仓库。</p>
<p>这使得Forking工作流对于松散组织的团队来说是个非常强大的工具。任一开发者可以方便地和另一开发者分享变更，任何分支都能有效地合并到正式代码库中。</p>
<h2 id="Pull-Requests-1"><a href="#Pull-Requests-1" class="headerlink" title="Pull Requests"></a>Pull Requests</h2><p>Pull requests是Bitbucket提供的让开发者更方便地进行协作的功能，提供了友好的Web界面可以在提议的修改合并到正式项目之前对修改进行讨论。<br><img src="/2017/02/16/深入学习Git工作流/../../../../images/g44.png" alt=""><br>开发者向团队成员通知功能开发已经完成，Pull Requests是最简单的用法。<br>开发者完成功能开发后，通过Bitbucket账号发起一个Pull Request。<br>这样让涉及这个功能的所有人知道要去做Code Review和合并到master分支。</p>
<p>但是，Pull Request远不止一个简单的通知，而是为讨论提交的功能的一个专门论坛。<br>如果变更有任何问题，团队成员反馈在Pull Request中，甚至push新的提交微调功能。<br>所有的这些活动都直接跟踪在Pull Request中。<br><img src="/2017/02/16/深入学习Git工作流/../../../../images/g45.png" alt=""><br>相比其它的协作模型，这种分享提交的形式有助于打造一个更流畅的工作流。<br>SVN和Git都能通过一个简单的脚本收到通知邮件；但是，讨论变更时，开发者通常只能去回复邮件。<br>这样做会变得杂乱，尤其还要涉及后面的几个提交时。<br>Pull Requests把所有相关功能整合到一个和Bitbucket仓库界面集成的用户友好Web界面中。</p>
<h3 id="解析Pull-Request"><a href="#解析Pull-Request" class="headerlink" title="解析Pull Request"></a>解析Pull Request</h3><p>当要发起一个Pull Request，你所要做的就是请求（Request）另一个开发者（比如项目的维护者）<br>来pull你仓库中一个分支到他的仓库中。这意味着你要提供4个信息以发起Pull Request：<br>源仓库、源分支、目的仓库、目的分支。<br><img src="/2017/02/16/深入学习Git工作流/../../../../images/g46.png" alt=""><br>这几值多数Bitbucket都会设置上合适的缺省值。但取决你用的协作工作流，你的团队可能会要指定不同的值。<br>上图显示了一个Pull Request请求合并一个功能分支到正式的master分支上，但可以有多种不同的Pull Request用法。</p>
<h3 id="工作方式-4"><a href="#工作方式-4" class="headerlink" title="工作方式"></a>工作方式</h3><p>Pull Request可以和功能分支工作流、Gitflow工作流或Forking工作流一起使用。<br>但一个Pull Request要求要么分支不同要么仓库不同，所以不能用于集中式工作流。<br>在不同的工作流中使用Pull Request会有一些不同，但基本的过程是这样的：</p>
<ol>
<li>开发者在本地仓库中新建一个专门的分支开发功能。</li>
<li>开发者push分支修改到公开的Bitbucket仓库中。</li>
<li>开发者通过Bitbucket发起一个Pull Request。</li>
<li>团队的其它成员review code，讨论并修改。</li>
<li>项目维护者合并功能到官方仓库中并关闭Pull Request。</li>
</ol>
<p>本文后面内容说明，Pull Request在不同协作工作流中如何应用。</p>
<h3 id="在功能分支工作流中使用Pull-Request"><a href="#在功能分支工作流中使用Pull-Request" class="headerlink" title="在功能分支工作流中使用Pull Request"></a>在功能分支工作流中使用Pull Request</h3><p>功能分支工作流用一个共享的Bitbucket仓库来管理协作，开发者在专门的分支上开发功能。<br>但不是立即合并到master分支上，而是在合并到主代码库之前开发者应该开一个Pull Request发起功能的讨论。<br><img src="/2017/02/16/深入学习Git工作流/../../../../images/g47.png" alt=""><br>功能分支工作流只有一个公开的仓库，所以Pull Request的目的仓库和源仓库总是同一个。<br>通常开发者会指定他的功能分支作为源分支，master分支作为目的分支。</p>
<p>收到Pull Request后，项目维护者要决定如何做。如果功能没问题，就简单地合并到master分支，关闭Pull Request。<br>但如果提交的变更有问题，他可以在Pull Request中反馈。之后新加的提交也会评论之后接着显示出来。</p>
<p>在功能还没有完全开发完的时候，也可能发起一个Pull Request。<br>比如开发者在实现某个需求时碰到了麻烦，他可以发一个包含正在进行中工作的Pull Request。<br>其它的开发者可以在Pull Request提供建议，或者甚至直接添加提交来解决问题。</p>
<h3 id="在Gitflow工作流中使用Pull-Request"><a href="#在Gitflow工作流中使用Pull-Request" class="headerlink" title="在Gitflow工作流中使用Pull Request"></a>在Gitflow工作流中使用Pull Request</h3><p>Gitflow工作流和功能分支工作流类似，但围绕项目发布定义一个严格的分支模型。<br>在Gitflow工作流中使用Pull Request让开发者在发布分支或是维护分支上工作时，<br>可以有个方便的地方对关于发布分支或是维护分支的问题进行交流。<br><img src="/2017/02/16/深入学习Git工作流/../../../../images/g48.png" alt=""><br>Gitflow工作流中Pull Request的使用过程和上一节中完全一致：<br>当一个功能、发布或是热修复分支需要Review时，开发者简单发起一个Pull Request，<br>团队的其它成员会通过Bitbucket收到通知。</p>
<p>新功能一般合并到develop分支，而发布和热修复则要同时合并到develop分支和master分支上。<br>Pull Request可能用做所有合并的正式管理。</p>
<h3 id="在Forking工作流中使用Pull-Request"><a href="#在Forking工作流中使用Pull-Request" class="headerlink" title="在Forking工作流中使用Pull Request"></a>在Forking工作流中使用Pull Request</h3><p>在Forking工作流中，开发者push完成的功能到他自己的仓库中，而不是共享仓库。<br>然后，他发起一个Pull Request，让项目维护者知道他的功能已经可以Review了。</p>
<p>在这个工作流，Pull Request的通知功能非常有用，<br>因为项目维护者不可能知道其它开发者在他们自己的仓库添加了提交。<br><img src="/2017/02/16/深入学习Git工作流/../../../../images/g49.png" alt=""><br>由于各个开发有自己的公开仓库，Pull Request的源仓库和目标仓库不是同一个。<br>源仓库是开发者的公开仓库，源分支是包含了修改的分支。<br>如果开发者要合并修改到正式代码库中，那么目标仓库是正式仓库，目标分支是master分支。</p>
<p>Pull Request也可以用于正式项目之外的其它开发者之间的协作。<br>比如，如果一个开发者和一个团队成员一起开发一个功能，他们可以发起一个Pull Request，<br>用团队成员的Bitbucket仓库作为目标，而不是正式项目的仓库。<br>然后使用相同的功能分支作为源和目标分支。<br><img src="/2017/02/16/深入学习Git工作流/../../../../images/g50.png" alt=""><br>2个开发者之间可以在Pull Request中讨论和开发功能。<br>完成开发后，他们可以发起另一个Pull Request，请求合并功能到正式的master分支。<br>在Forking工作流中，这样的灵活性让Pull Request成为一个强有力的协作工具。</p>
<h3 id="示例-4"><a href="#示例-4" class="headerlink" title="示例"></a>示例</h3><p>下面的示例演示了Pull Request如何在在Forking工作流中使用。<br>也同样适用于小团队的开发协作和第三方开发者向开源项目的贡献。</p>
<p>在示例中，小红是个开发，小明是项目维护者。他们各自有一个公开的Bitbucket仓库，而小明的仓库包含了正式工程。</p>
<h4 id="小红fork正式项目"><a href="#小红fork正式项目" class="headerlink" title="小红fork正式项目"></a>小红fork正式项目</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g51.png" alt=""><br>小红先要fork小明的Bitbucket仓库，开始项目的开发。她登陆Bitbucket，浏览到小明的仓库页面，<br>点Fork按钮。<br><img src="/2017/02/16/深入学习Git工作流/../../../../images/g52.png" alt=""><br>然后为fork出来的仓库填写名字和描述，这样小红就有了服务端的项目拷贝了。</p>
<h4 id="小红克隆她的Bitbucket仓库"><a href="#小红克隆她的Bitbucket仓库" class="headerlink" title="小红克隆她的Bitbucket仓库"></a>小红克隆她的Bitbucket仓库</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g53.png" alt=""><br>下一步，小红克隆自己刚才fork出来的Bitbucket仓库，以在本机上准备出工作拷贝。命令如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git clone https://user@bitbucket.org/user/repo.git</div></pre></td></tr></table></figure></p>
<p>请记住，git clone会自动创建origin远程别名，是指向小红fork出来的仓库。</p>
<h4 id="小红开发新功能"><a href="#小红开发新功能" class="headerlink" title="小红开发新功能"></a>小红开发新功能</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g54.png" alt=""><br>在开始改代码前，小红要为新功能先新建一个新分支。她会用这个分支作为Pull Request的源分支。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">git checkout -b some-feature</div><div class="line"># 编辑代码</div><div class="line">git commit -a -m &quot;Add first draft of some feature&quot;</div></pre></td></tr></table></figure></p>
<p>在新功能分支上，小红按需要添加提交。甚至如果小红觉得功能分支上的提交历史太乱了，她可以用交互式rebase来删除或压制提交。<br>对于大型项目，整理功能分支的历史可以让项目维护者更容易看出在Pull Request中做了什么内容。</p>
<h4 id="小红push功能到她的Bitbucket仓库中"><a href="#小红push功能到她的Bitbucket仓库中" class="headerlink" title="小红push功能到她的Bitbucket仓库中"></a>小红push功能到她的Bitbucket仓库中</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g56.png" alt=""><br>小红完成了功能后，push功能到她自己的Bitbucket仓库中（不是正式仓库），用下面简单的命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git push origin some-branch</div></pre></td></tr></table></figure></p>
<p>这时她的变更可以让项目维护者看到了（或者任何想要看的协作者）。</p>
<h4 id="小红发起Pull-Request"><a href="#小红发起Pull-Request" class="headerlink" title="小红发起Pull Request"></a>小红发起Pull Request</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g57.png" alt=""><br>Bitbucket上有了她的功能分支后，小红可以用她的Bitbucket账号浏览到她的fork出来的仓库页面，<br>点右上角的【Pull Request】按钮，发起一个Pull Request。<br>弹出的表单自动设置小红的仓库为源仓库，询问小红以指定源分支、目标仓库和目标分支。</p>
<p>小红想要合并功能到正式仓库，所以源分支是她的功能分支，目标仓库是小明的公开仓库，<br>而目标分支是master分支。另外，小红需要提供Pull Request的标题和描述信息。<br>如果需要小明以外的人审核批准代码，她可以把这些人填在【Reviewers】文本框中。<br><img src="/2017/02/16/深入学习Git工作流/../../../../images/g58.png" alt=""><br>创建好了Pull Request，通知会通过Bitbucket系统消息或邮件（可选）发给小明。</p>
<h4 id="小明review-Pull-Request"><a href="#小明review-Pull-Request" class="headerlink" title="小明review Pull Request"></a>小明review Pull Request</h4><p><img src="/2017/02/16/深入学习Git工作流/../../../../images/g59.png" alt=""><br>在小明的Bitbucket仓库页面的【Pull Request】Tab可以看到所有人发起的Pull Request。<br>点击小红的Pull Request会显示出Pull Request的描述、功能的提交历史和每个变更的差异（diff）。</p>
<p>如果小明想要合并到项目中，只要点一下【Merge】按钮，就可以同意Pull Request并合并到master分支。</p>
<p>但如果像这个示例中一样小明发现了在小红的代码中的一个小Bug，要小红在合并前修复。<br>小明可以在整个Pull Request上加上评注，或是选择历史中的某个提交加上评注。<br><img src="/2017/02/16/深入学习Git工作流/../../../../images/g60.png" alt=""></p>
<h4 id="小红补加提交"><a href="#小红补加提交" class="headerlink" title="小红补加提交"></a>小红补加提交</h4><p>如果小红对反馈有任何疑问，可以在Pull Request中响应，把Pull Request当作是她功能讨论的论坛。</p>
<p>小红在她的功能分支新加提交以解决代码问题，并push到她的Bitbucket仓库中，就像前一轮中的做法一样。<br>这些提交会进入的Pull Request，小明在原来的评注旁边可以再次review变更。</p>
<h4 id="小明接受Pull-Request"><a href="#小明接受Pull-Request" class="headerlink" title="小明接受Pull Request"></a>小明接受Pull Request</h4><p>最终，小明接受变更，合并功能分支到master分支，并关闭Pull Request。<br>至此，功能集成到项目中，其它的项目开发者可以用标准的git pull命令pull这些变更到自己的本地仓库中。</p>
<p>到了这里，你应该有了所有需要的工具来集成Pull Request到你自己的工作流。<br>请记住，Pull Request并不是为了替代任何 基于Git的协作工作流，<br>而是它们的一个便利的补充，让团队成员间的协作更轻松方便。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;个人在学习git工作流的过程中，从原有的 SVN 模式很难完全理解git的协作模式，直到有一天我看到了下面的文章，好多遗留在心中的困惑迎刃而解。于是我将这部分资料整理如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我们以使用SVN的工作流来使用git有什么不妥？&lt;/li&gt;
&lt;li&gt;git 方便的branch在哪里，团队多人如何协作？冲突了怎么办？如何进行发布控制？&lt;/li&gt;
&lt;li&gt;经典的master-发布、develop-主开发、hotfix-不过修复如何避免代码不经过验证上线？&lt;/li&gt;
&lt;li&gt;如何在github上面与他人一起协作，star-fork-pull request是怎样的流程？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;原文链接：&lt;a href=&quot;https://www.atlassian.com/git/workflows&quot;&gt;Git Workflows and Tutorials&lt;/a&gt;&lt;br&gt;简体中文：由 &lt;a href=&quot;https://github.com/oldratlee&quot;&gt;oldratlee&lt;/a&gt; 翻译在 &lt;a href=&quot;https://github.com/oldratlee/translations/tree/master/git-workflows-and-tutorials&quot;&gt;github 上 git-workflows-and-tutorials&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="工具" scheme="http://lzrlizhirong.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="git" scheme="http://lzrlizhirong.github.io/tags/git/"/>
    
  </entry>
  
</feed>
